{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d16611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Excluding: ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Longitudinal RSA Analysis: Contrast Scheme Comparison\n",
    "# \n",
    "# **Study:** VOTC Resection - Bilateral vs Unilateral Visual Category Reorganization\n",
    "# \n",
    "# **Hypothesis:** Bilateral categories (Object, House) show greater representational \n",
    "# reorganization than unilateral categories (Face, Word) in OTC patients because \n",
    "# the hemispheres work collaboratively (not redundantly), so losing one forces compensation.\n",
    "# \n",
    "# **This notebook:**\n",
    "# 1. Compares 4 contrast schemes for ROI localization and pattern extraction\n",
    "# 2. Tests hybrid approach (Liu for localization, Scramble for patterns)\n",
    "# 3. Computes all RSA measures with each approach\n",
    "# 4. Determines optimal contrast scheme based on results\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 1: Setup & Configuration\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, ttest_ind, ttest_rel\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "OUTPUT_DIR = Path('/user_data/csimmon2/git_repos/long_pt/B_analyses')\n",
    "\n",
    "# Load subject info\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Session overrides\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# Subjects to exclude\n",
    "EXCLUDE_SUBJECTS = ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
    "\n",
    "# Categories\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "BILATERAL = ['object', 'house']\n",
    "UNILATERAL = ['face', 'word']\n",
    "\n",
    "# ============================================================\n",
    "# CONTRAST SCHEME DEFINITIONS\n",
    "# ============================================================\n",
    "\n",
    "# Scheme 1: Liu's original mixed contrasts (for ROI localization)\n",
    "COPE_LIU_MIXED = {\n",
    "    'face': (1, 1),    # Face > Object\n",
    "    'word': (4, 1),    # Word > Object  \n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (2, 1)    # House > Object\n",
    "}\n",
    "\n",
    "# Scheme 2: All vs Scramble (consistent baseline)\n",
    "COPE_ALL_SCRAMBLE = {\n",
    "    'face': (10, 1),   # Face > Scramble\n",
    "    'word': (12, 1),   # Word > Scramble\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (11, 1)   # House > Scramble\n",
    "}\n",
    "\n",
    "# Scheme 3: All vs Others (category vs mean of others)\n",
    "COPE_ALL_VS_OTHERS = {\n",
    "    'face': (6, 1),    # Face > mean(House+Object+Word+Scramble)\n",
    "    'word': (9, 1),    # Word > mean(Face+House+Object+Scramble)\n",
    "    'object': (8, 1),  # Object > mean(Face+House+Word+Scramble)\n",
    "    'house': (7, 1)    # House > mean(Face+Object+Word+Scramble)\n",
    "}\n",
    "\n",
    "# Scheme 4: Current differential (what Script 1 used - problematic)\n",
    "COPE_DIFFERENTIAL = {\n",
    "    'face': (10, 1),   # Face > Scramble\n",
    "    'word': (13, -1),  # Face > Word, flipped to Word > Face\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (11, 1)   # House > Scramble\n",
    "}\n",
    "\n",
    "CONTRAST_SCHEMES = {\n",
    "    'liu_mixed': COPE_LIU_MIXED,\n",
    "    'all_scramble': COPE_ALL_SCRAMBLE,\n",
    "    'all_vs_others': COPE_ALL_VS_OTHERS,\n",
    "    'current_differential': COPE_DIFFERENTIAL\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Excluding: {EXCLUDE_SUBJECTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7529dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 20 subjects (after exclusions)\n",
      "  OTC: 6\n",
      "  nonOTC: 7\n",
      "  control: 7\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 2: Load Subjects\n",
    "\n",
    "# %%\n",
    "def load_subjects():\n",
    "    \"\"\"Load all subjects from CSV, excluding problematic ones\"\"\"\n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        \n",
    "        if subject_id in EXCLUDE_SUBJECTS:\n",
    "            continue\n",
    "            \n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        sessions = sorted([d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()], key=int)\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        \n",
    "        if len(sessions) < 2:\n",
    "            continue\n",
    "        \n",
    "        hemi = 'l' if row.get('intact_hemi', 'left') == 'left' else 'r'\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemi,\n",
    "            'group': row['group'],\n",
    "            'patient': row['patient'] == 1,\n",
    "            'surgery_side': row.get('SurgerySide', None),\n",
    "            'sex': row.get('sex', None),\n",
    "            'age_1': row.get('age_1', None),\n",
    "            'age_2': row.get('age_2', None)\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "SUBJECTS = load_subjects()\n",
    "\n",
    "# Summary\n",
    "print(f\"✓ Loaded {len(SUBJECTS)} subjects (after exclusions)\")\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    n = sum(1 for s in SUBJECTS.values() if s['group'] == group)\n",
    "    print(f\"  {group}: {n}\")\n",
    "\n",
    "# %% [markdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d393233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ROI extraction functions defined\n"
     ]
    }
   ],
   "source": [
    "# ## Cell 3: ROI Extraction Functions\n",
    "\n",
    "# %%\n",
    "def create_sphere(center_coord, affine, brain_shape, radius=6):\n",
    "    \"\"\"Create spherical mask around coordinate\"\"\"\n",
    "    grid = np.array(np.meshgrid(\n",
    "        np.arange(brain_shape[0]),\n",
    "        np.arange(brain_shape[1]),\n",
    "        np.arange(brain_shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "    \n",
    "    world = nib.affines.apply_affine(affine, grid)\n",
    "    distances = np.linalg.norm(world - center_coord, axis=1)\n",
    "    \n",
    "    mask = np.zeros(brain_shape, dtype=bool)\n",
    "    within = grid[distances <= radius]\n",
    "    for c in within:\n",
    "        mask[c[0], c[1], c[2]] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def extract_rois_single_scheme(cope_map, threshold_z=2.3, min_voxels=20):\n",
    "    \"\"\"Extract ROIs for all subjects using a single contrast scheme\"\"\"\n",
    "    \n",
    "    all_rois = {}\n",
    "    \n",
    "    for sid, info in SUBJECTS.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        \n",
    "        if not roi_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        all_rois[sid] = {}\n",
    "        \n",
    "        # For controls, extract both hemispheres\n",
    "        hemis = ['l', 'r'] if info['group'] == 'control' else [info['hemi']]\n",
    "        \n",
    "        for hemi in hemis:\n",
    "            for category in CATEGORIES:\n",
    "                cope_num, mult = cope_map[category]\n",
    "                \n",
    "                # Load search mask\n",
    "                mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "                if not mask_file.exists():\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mask_img = nib.load(mask_file)\n",
    "                    search_mask = mask_img.get_fdata() > 0\n",
    "                    affine = mask_img.affine\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                roi_key = f'{hemi}_{category}'\n",
    "                all_rois[sid][roi_key] = {}\n",
    "                \n",
    "                for session in info['sessions']:\n",
    "                    feat_dir = BASE_DIR / sid / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                    z_name = 'zstat1.nii.gz' if session == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        z_data = nib.load(cope_file).get_fdata() * mult\n",
    "                        suprathresh = (z_data > threshold_z) & search_mask\n",
    "                        \n",
    "                        if suprathresh.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        labeled, n_clusters = label(suprathresh)\n",
    "                        if n_clusters == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        # Largest cluster\n",
    "                        sizes = [(labeled == i).sum() for i in range(1, n_clusters + 1)]\n",
    "                        best_idx = np.argmax(sizes) + 1\n",
    "                        roi_mask = (labeled == best_idx)\n",
    "                        \n",
    "                        if roi_mask.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        peak_idx = np.unravel_index(np.argmax(z_data * roi_mask), z_data.shape)\n",
    "                        \n",
    "                        all_rois[sid][roi_key][session] = {\n",
    "                            'n_voxels': int(roi_mask.sum()),\n",
    "                            'peak_z': z_data[peak_idx],\n",
    "                            'centroid': nib.affines.apply_affine(affine, center_of_mass(roi_mask)),\n",
    "                            'peak_coord': nib.affines.apply_affine(affine, peak_idx),\n",
    "                            'roi_mask': roi_mask,\n",
    "                            'affine': affine,\n",
    "                            'shape': z_data.shape\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "    \n",
    "    return all_rois\n",
    "\n",
    "print(\"✓ ROI extraction functions defined\")\n",
    "\n",
    "# %% [markdown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8874e778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RSA metric functions defined\n"
     ]
    }
   ],
   "source": [
    "# ## Cell 4: RSA Metric Functions\n",
    "\n",
    "# %%\n",
    "def compute_rdm(patterns):\n",
    "    \"\"\"Compute RDM from pattern matrix (categories x voxels)\"\"\"\n",
    "    corr = np.corrcoef(patterns)\n",
    "    rdm = 1 - corr\n",
    "    return rdm, corr\n",
    "\n",
    "\n",
    "def compute_geometry_preservation(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    Geometry Preservation: RDM stability across sessions\n",
    "    - Extract patterns from sphere at each session's centroid\n",
    "    - Correlate T1 and T2 RDMs\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            # Get reference for sphere creation\n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    rdm, _ = compute_rdm(np.array(patterns))\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                triu = np.triu_indices(4, k=1)\n",
    "                r, _ = pearsonr(rdms[sessions[0]][triu], rdms[sessions[-1]][triu])\n",
    "                \n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'geometry_preservation': r\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_mds_shift(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    MDS Shift: Procrustes-aligned embedding distance\n",
    "    - MDS embed RDMs to 2D\n",
    "    - Align with Procrustes\n",
    "    - Measure movement of each category\n",
    "    \"\"\"\n",
    "    def mds_2d(rdm):\n",
    "        n = rdm.shape[0]\n",
    "        H = np.eye(n) - np.ones((n, n)) / n\n",
    "        B = -0.5 * H @ (rdm ** 2) @ H\n",
    "        eigvals, eigvecs = np.linalg.eigh(B)\n",
    "        idx = np.argsort(eigvals)[::-1]\n",
    "        coords = eigvecs[:, idx[:2]] * np.sqrt(np.maximum(eigvals[idx[:2]], 0))\n",
    "        return coords\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            roi_category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    rdm, _ = compute_rdm(np.array(patterns))\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                try:\n",
    "                    coords_t1 = mds_2d(rdms[sessions[0]])\n",
    "                    coords_t2 = mds_2d(rdms[sessions[-1]])\n",
    "                    \n",
    "                    R, _ = orthogonal_procrustes(coords_t1, coords_t2)\n",
    "                    coords_t1_aligned = coords_t1 @ R\n",
    "                    \n",
    "                    for i, cat in enumerate(CATEGORIES):\n",
    "                        dist = np.linalg.norm(coords_t1_aligned[i] - coords_t2[i])\n",
    "                        results.append({\n",
    "                            'subject': sid,\n",
    "                            'code': info['code'],\n",
    "                            'group': info['group'],\n",
    "                            'hemi': hemi,\n",
    "                            'roi_category': roi_category,\n",
    "                            'measured_category': cat,\n",
    "                            'mds_shift': dist\n",
    "                        })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_spatial_drift(rois):\n",
    "    \"\"\"\n",
    "    Spatial Drift: Euclidean distance between T1 and T2 peak centroids\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            c1 = sessions_data[sessions[0]]['centroid']\n",
    "            c2 = sessions_data[sessions[-1]]['centroid']\n",
    "            drift = np.linalg.norm(np.array(c2) - np.array(c1))\n",
    "            \n",
    "            results.append({\n",
    "                'subject': sid,\n",
    "                'code': info['code'],\n",
    "                'group': info['group'],\n",
    "                'hemi': hemi,\n",
    "                'category': category,\n",
    "                'spatial_drift_mm': drift,\n",
    "                't1_peak_z': sessions_data[sessions[0]]['peak_z']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_selectivity_change(rois, pattern_cope_map):\n",
    "    \"\"\"\n",
    "    Selectivity Change (Liu Distinctiveness):\n",
    "    - Correlation of preferred category with non-preferred categories\n",
    "    - Change from T1 to T2\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            distinctiveness = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius=6)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = {}\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns[cat] = pattern\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    # Compute correlation of preferred with non-preferred\n",
    "                    pref_pattern = patterns[category]\n",
    "                    nonpref_corrs = []\n",
    "                    for other_cat in CATEGORIES:\n",
    "                        if other_cat != category:\n",
    "                            r, _ = pearsonr(pref_pattern, patterns[other_cat])\n",
    "                            nonpref_corrs.append(np.arctanh(np.clip(r, -0.999, 0.999)))\n",
    "                    \n",
    "                    distinctiveness[ses] = np.mean(nonpref_corrs)\n",
    "            \n",
    "            if len(distinctiveness) == 2:\n",
    "                change = abs(distinctiveness[sessions[-1]] - distinctiveness[sessions[0]])\n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'selectivity_change': change,\n",
    "                    't1_distinctiveness': distinctiveness[sessions[0]],\n",
    "                    't2_distinctiveness': distinctiveness[sessions[-1]]\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ RSA metric functions defined\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d9947da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXTRACTING ROIs WITH ALL CONTRAST SCHEMES\n",
      "======================================================================\n",
      "\n",
      "liu_mixed...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scheme_name, cope_map \u001b[38;5;129;01min\u001b[39;00m CONTRAST_SCHEMES\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mscheme_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m     all_rois[scheme_name] \u001b[38;5;241m=\u001b[39m \u001b[43mextract_rois_single_scheme\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcope_map\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Count ROIs\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     n_rois \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mlen\u001b[39m(roi_data) \u001b[38;5;28;01mfor\u001b[39;00m roi_data \u001b[38;5;129;01min\u001b[39;00m all_rois[scheme_name]\u001b[38;5;241m.\u001b[39mvalues())\n",
      "Cell \u001b[0;32mIn[4], line 75\u001b[0m, in \u001b[0;36mextract_rois_single_scheme\u001b[0;34m(cope_map, threshold_z, min_voxels)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m suprathresh\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m<\u001b[39m min_voxels:\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m---> 75\u001b[0m labeled, n_clusters \u001b[38;5;241m=\u001b[39m \u001b[43mlabel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msuprathresh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_clusters \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/scipy/ndimage/_measurements.py:220\u001b[0m, in \u001b[0;36mlabel\u001b[0;34m(input, structure, output)\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m output, maxlabel\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 220\u001b[0m     max_label \u001b[38;5;241m=\u001b[39m \u001b[43m_ni_label\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_label\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _ni_label\u001b[38;5;241m.\u001b[39mNeedMoreBits \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m# Make another attempt with enough bits, then try to cast to the\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m# new type.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m     tmp_output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39mintp \u001b[38;5;28;01mif\u001b[39;00m need_64bits \u001b[38;5;28;01melse\u001b[39;00m np\u001b[38;5;241m.\u001b[39mint32)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 5: Extract ROIs with All Contrast Schemes\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING ROIs WITH ALL CONTRAST SCHEMES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_rois = {}\n",
    "for scheme_name, cope_map in CONTRAST_SCHEMES.items():\n",
    "    print(f\"\\n{scheme_name}...\")\n",
    "    all_rois[scheme_name] = extract_rois_single_scheme(cope_map)\n",
    "    \n",
    "    # Count ROIs\n",
    "    n_rois = sum(len(roi_data) for roi_data in all_rois[scheme_name].values())\n",
    "    n_subjects = len([s for s in all_rois[scheme_name] if all_rois[scheme_name][s]])\n",
    "    print(f\"  ✓ {n_subjects} subjects, {n_rois} ROIs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888005c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "# ## Cell 6: Compare ROI Yields Across Schemes\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"ROI YIELD COMPARISON BY CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count ROIs per category per scheme\n",
    "yield_data = []\n",
    "for scheme_name, rois in all_rois.items():\n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            if len(sessions_data) >= 2:  # Has both timepoints\n",
    "                hemi = roi_key.split('_')[0]\n",
    "                category = roi_key.split('_')[1]\n",
    "                n_voxels_t1 = sessions_data[sorted(sessions_data.keys())[0]]['n_voxels']\n",
    "                \n",
    "                yield_data.append({\n",
    "                    'scheme': scheme_name,\n",
    "                    'subject': sid,\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'n_voxels': n_voxels_t1\n",
    "                })\n",
    "\n",
    "yield_df = pd.DataFrame(yield_data)\n",
    "\n",
    "print(\"\\nROI counts by scheme and category:\")\n",
    "print(\"-\"*60)\n",
    "pivot = yield_df.groupby(['scheme', 'category']).size().unstack(fill_value=0)\n",
    "print(pivot)\n",
    "\n",
    "print(\"\\n\\nMean voxel count by scheme and category:\")\n",
    "print(\"-\"*60)\n",
    "pivot_vox = yield_df.groupby(['scheme', 'category'])['n_voxels'].mean().unstack()\n",
    "print(pivot_vox.round(0))\n",
    "\n",
    "# Word ROI problem visualization\n",
    "print(\"\\n\\nWORD ROI VOXEL COUNTS (the problematic category):\")\n",
    "print(\"-\"*60)\n",
    "word_data = yield_df[yield_df['category'] == 'word']\n",
    "for scheme in CONTRAST_SCHEMES.keys():\n",
    "    scheme_word = word_data[word_data['scheme'] == scheme]\n",
    "    print(f\"\\n{scheme}:\")\n",
    "    print(f\"  N ROIs: {len(scheme_word)}\")\n",
    "    print(f\"  Mean voxels: {scheme_word['n_voxels'].mean():.0f}\")\n",
    "    print(f\"  Min voxels: {scheme_word['n_voxels'].min()}\")\n",
    "    print(f\"  Max voxels: {scheme_word['n_voxels'].max()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 7: Compute All Metrics - Standard Approach (Same scheme for localization and patterns)\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"COMPUTING METRICS: STANDARD APPROACH\")\n",
    "print(\"(Same contrast scheme for ROI localization AND pattern extraction)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "standard_results = {}\n",
    "\n",
    "for scheme_name in CONTRAST_SCHEMES.keys():\n",
    "    print(f\"\\n{scheme_name}...\")\n",
    "    \n",
    "    rois = all_rois[scheme_name]\n",
    "    cope_map = CONTRAST_SCHEMES[scheme_name]\n",
    "    \n",
    "    # Compute all metrics\n",
    "    geom = compute_geometry_preservation(rois, cope_map)\n",
    "    mds = compute_mds_shift(rois, cope_map)\n",
    "    drift = compute_spatial_drift(rois)\n",
    "    select = compute_selectivity_change(rois, cope_map)\n",
    "    \n",
    "    standard_results[scheme_name] = {\n",
    "        'geometry': geom,\n",
    "        'mds': mds,\n",
    "        'drift': drift,\n",
    "        'selectivity': select\n",
    "    }\n",
    "    \n",
    "    print(f\"  Geometry: {len(geom)} ROIs\")\n",
    "    print(f\"  MDS: {len(mds)} measurements\")\n",
    "    print(f\"  Drift: {len(drift)} ROIs\")\n",
    "    print(f\"  Selectivity: {len(select)} ROIs\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 8: Compute Metrics - Hybrid Approach\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"COMPUTING METRICS: HYBRID APPROACH\")\n",
    "print(\"(Liu mixed for localization, All Scramble for patterns)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use Liu mixed ROIs, but All Scramble patterns\n",
    "hybrid_rois = all_rois['liu_mixed']\n",
    "pattern_cope = COPE_ALL_SCRAMBLE\n",
    "\n",
    "print(\"\\nUsing ROIs from: liu_mixed\")\n",
    "print(\"Using patterns from: all_scramble\")\n",
    "\n",
    "hybrid_results = {\n",
    "    'geometry': compute_geometry_preservation(hybrid_rois, pattern_cope),\n",
    "    'mds': compute_mds_shift(hybrid_rois, pattern_cope),\n",
    "    'drift': compute_spatial_drift(hybrid_rois),\n",
    "    'selectivity': compute_selectivity_change(hybrid_rois, pattern_cope)\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Geometry: {len(hybrid_results['geometry'])} ROIs\")\n",
    "print(f\"✓ MDS: {len(hybrid_results['mds'])} measurements\")\n",
    "print(f\"✓ Drift: {len(hybrid_results['drift'])} ROIs\")\n",
    "print(f\"✓ Selectivity: {len(hybrid_results['selectivity'])} ROIs\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 9: Compare Results Across Approaches\n",
    "\n",
    "# %%\n",
    "def summarize_by_category(df, metric_col, groups=['OTC', 'nonOTC', 'control']):\n",
    "    \"\"\"Summarize metric by group and category\"\"\"\n",
    "    summary = []\n",
    "    for group in groups:\n",
    "        group_data = df[df['group'] == group]\n",
    "        for cat in CATEGORIES:\n",
    "            cat_data = group_data[group_data['category'] == cat][metric_col]\n",
    "            if len(cat_data) > 0:\n",
    "                summary.append({\n",
    "                    'group': group,\n",
    "                    'category': cat,\n",
    "                    'mean': cat_data.mean(),\n",
    "                    'std': cat_data.std(),\n",
    "                    'n': len(cat_data)\n",
    "                })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS COMPARISON: GEOMETRY PRESERVATION\")\n",
    "print(\"(Higher = more stable, lower in bilateral = MORE reorganization)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for approach_name, results in [('liu_mixed (standard)', standard_results['liu_mixed']),\n",
    "                                ('all_scramble (standard)', standard_results['all_scramble']),\n",
    "                                ('hybrid (liu ROI + scramble pattern)', {'geometry': hybrid_results['geometry']})]:\n",
    "    print(f\"\\n--- {approach_name} ---\")\n",
    "    geom_df = results['geometry'] if 'geometry' in results else results.get('geometry')\n",
    "    \n",
    "    if geom_df is None or len(geom_df) == 0:\n",
    "        print(\"  No data\")\n",
    "        continue\n",
    "    \n",
    "    # Filter to intact hemisphere for patients\n",
    "    filtered = []\n",
    "    for _, row in geom_df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    \n",
    "    print(f\"\\n{'Group':<10} {'Face':<12} {'Word':<12} {'Object':<12} {'House':<12}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['geometry_preservation']\n",
    "            if len(cd) > 0:\n",
    "                vals.append(f\"{cd.mean():.3f}\")\n",
    "            else:\n",
    "                vals.append(\"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<12} {vals[1]:<12} {vals[2]:<12} {vals[3]:<12}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 10: Statistical Tests - Compare Bilateral vs Unilateral Effect\n",
    "\n",
    "# %%\n",
    "def test_bilateral_effect(df, metric_col, metric_name):\n",
    "    \"\"\"Test if bilateral > unilateral change (or < for stability metrics)\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BILATERAL vs UNILATERAL: {metric_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Filter to intact hemisphere for patients\n",
    "    filtered = []\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'Group':<12} {'Bilateral':<15} {'Unilateral':<15} {'Diff':<10} {'t':<8} {'p':<8}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    results = []\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        bil = gd[gd['cat_type'] == 'Bilateral'][metric_col]\n",
    "        uni = gd[gd['cat_type'] == 'Unilateral'][metric_col]\n",
    "        \n",
    "        if len(bil) > 1 and len(uni) > 1:\n",
    "            t, p = ttest_ind(bil, uni)\n",
    "            diff = bil.mean() - uni.mean()\n",
    "            sig = '*' if p < 0.05 else ''\n",
    "            print(f\"{group:<12} {bil.mean():.3f}±{bil.std():.3f}   {uni.mean():.3f}±{uni.std():.3f}   {diff:+.3f}     {t:.2f}    {p:.4f} {sig}\")\n",
    "            \n",
    "            results.append({\n",
    "                'group': group,\n",
    "                'bilateral_mean': bil.mean(),\n",
    "                'unilateral_mean': uni.mean(),\n",
    "                'difference': diff,\n",
    "                't': t,\n",
    "                'p': p\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING BILATERAL vs UNILATERAL EFFECTS ACROSS APPROACHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test each approach\n",
    "approach_tests = {}\n",
    "\n",
    "for scheme_name in ['liu_mixed', 'all_scramble', 'current_differential']:\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"APPROACH: {scheme_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    results = standard_results[scheme_name]\n",
    "    \n",
    "    approach_tests[scheme_name] = {}\n",
    "    \n",
    "    # Geometry Preservation (lower bilateral = more change)\n",
    "    if len(results['geometry']) > 0:\n",
    "        approach_tests[scheme_name]['geometry'] = test_bilateral_effect(\n",
    "            results['geometry'], 'geometry_preservation', 'Geometry Preservation'\n",
    "        )\n",
    "    \n",
    "    # Selectivity Change (higher bilateral = more change)\n",
    "    if len(results['selectivity']) > 0:\n",
    "        approach_tests[scheme_name]['selectivity'] = test_bilateral_effect(\n",
    "            results['selectivity'], 'selectivity_change', 'Selectivity Change'\n",
    "        )\n",
    "\n",
    "# Hybrid approach\n",
    "print(f\"\\n\\n{'#'*70}\")\n",
    "print(\"APPROACH: HYBRID (liu ROI + scramble patterns)\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "approach_tests['hybrid'] = {}\n",
    "approach_tests['hybrid']['geometry'] = test_bilateral_effect(\n",
    "    hybrid_results['geometry'], 'geometry_preservation', 'Geometry Preservation'\n",
    ")\n",
    "approach_tests['hybrid']['selectivity'] = test_bilateral_effect(\n",
    "    hybrid_results['selectivity'], 'selectivity_change', 'Selectivity Change'\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 11: Summary Comparison Table\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: OTC BILATERAL vs UNILATERAL EFFECT BY APPROACH\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nKey question: Does OTC show significantly greater change in bilateral\")\n",
    "print(\"categories compared to unilateral? (This supports our hypothesis)\")\n",
    "print()\n",
    "\n",
    "print(f\"{'Approach':<25} {'Measure':<20} {'Bil-Uni Diff':<15} {'p-value':<10} {'Sig?':<5}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "for approach_name in ['liu_mixed', 'all_scramble', 'current_differential', 'hybrid']:\n",
    "    if approach_name not in approach_tests:\n",
    "        continue\n",
    "    \n",
    "    for measure in ['geometry', 'selectivity']:\n",
    "        if measure not in approach_tests[approach_name]:\n",
    "            continue\n",
    "        \n",
    "        test_df = approach_tests[approach_name][measure]\n",
    "        otc_row = test_df[test_df['group'] == 'OTC']\n",
    "        \n",
    "        if len(otc_row) == 0:\n",
    "            continue\n",
    "        \n",
    "        diff = otc_row['difference'].values[0]\n",
    "        p = otc_row['p'].values[0]\n",
    "        sig = '✓' if p < 0.05 else ''\n",
    "        \n",
    "        # For geometry, negative diff means bilateral has MORE change (lower stability)\n",
    "        # For selectivity, positive diff means bilateral has MORE change\n",
    "        measure_label = 'Geometry Pres.' if measure == 'geometry' else 'Selectivity Chg.'\n",
    "        \n",
    "        print(f\"{approach_name:<25} {measure_label:<20} {diff:+.4f}        {p:.4f}     {sig}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*75)\n",
    "print(\"Note: For Geometry Preservation, NEGATIVE diff = bilateral shows MORE change\")\n",
    "print(\"      For Selectivity Change, POSITIVE diff = bilateral shows MORE change\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 12: Detailed Category-Level Results for Best Approach\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED CATEGORY-LEVEL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine best approach based on OTC significance\n",
    "# Let's show results for multiple approaches for comparison\n",
    "\n",
    "for approach_name in ['all_scramble', 'hybrid']:\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"APPROACH: {approach_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    if approach_name == 'hybrid':\n",
    "        geom_df = hybrid_results['geometry']\n",
    "        select_df = hybrid_results['selectivity']\n",
    "        drift_df = hybrid_results['drift']\n",
    "    else:\n",
    "        geom_df = standard_results[approach_name]['geometry']\n",
    "        select_df = standard_results[approach_name]['selectivity']\n",
    "        drift_df = standard_results[approach_name]['drift']\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    def filter_intact(df):\n",
    "        filtered = []\n",
    "        for _, row in df.iterrows():\n",
    "            sid = row['subject']\n",
    "            info = SUBJECTS[sid]\n",
    "            if info['group'] == 'control':\n",
    "                filtered.append(row)\n",
    "            elif row['hemi'] == info['hemi']:\n",
    "                filtered.append(row)\n",
    "        return pd.DataFrame(filtered)\n",
    "    \n",
    "    geom_filt = filter_intact(geom_df)\n",
    "    select_filt = filter_intact(select_df)\n",
    "    drift_filt = filter_intact(drift_df)\n",
    "    \n",
    "    print(\"\\n--- GEOMETRY PRESERVATION (higher = more stable) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = geom_filt[geom_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['geometry_preservation']\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "    \n",
    "    print(\"\\n--- SELECTIVITY CHANGE (higher = more change) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = select_filt[select_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['selectivity_change']\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "    \n",
    "    print(\"\\n--- SPATIAL DRIFT (mm) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = drift_filt[drift_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['spatial_drift_mm']\n",
    "            vals.append(f\"{cd.mean():.1f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 13: Bootstrap Analysis for Robust Inference\n",
    "\n",
    "# %%\n",
    "def bootstrap_group_comparison(df, metric_col, n_boot=10000, seed=42):\n",
    "    \"\"\"Bootstrap test for OTC bilateral advantage vs other groups\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    filtered = []\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    # Calculate subject-level bilateral advantage (gap)\n",
    "    subject_gaps = {}\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        gaps = []\n",
    "        for sid in gd['subject'].unique():\n",
    "            sd = gd[gd['subject'] == sid]\n",
    "            bil = sd[sd['cat_type'] == 'Bilateral'][metric_col].mean()\n",
    "            uni = sd[sd['cat_type'] == 'Unilateral'][metric_col].mean()\n",
    "            if pd.notna(bil) and pd.notna(uni):\n",
    "                gaps.append(bil - uni)\n",
    "        subject_gaps[group] = np.array(gaps)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Compare OTC vs each other group\n",
    "    for comp_group in ['nonOTC', 'control']:\n",
    "        g1 = subject_gaps['OTC']\n",
    "        g2 = subject_gaps[comp_group]\n",
    "        \n",
    "        if len(g1) < 2 or len(g2) < 2:\n",
    "            continue\n",
    "        \n",
    "        observed_diff = np.mean(g1) - np.mean(g2)\n",
    "        \n",
    "        boot_diffs = []\n",
    "        for _ in range(n_boot):\n",
    "            s1 = np.random.choice(g1, size=len(g1), replace=True)\n",
    "            s2 = np.random.choice(g2, size=len(g2), replace=True)\n",
    "            boot_diffs.append(np.mean(s1) - np.mean(s2))\n",
    "        \n",
    "        boot_diffs = np.array(boot_diffs)\n",
    "        ci_low = np.percentile(boot_diffs, 2.5)\n",
    "        ci_high = np.percentile(boot_diffs, 97.5)\n",
    "        \n",
    "        # Two-sided p-value\n",
    "        if observed_diff > 0:\n",
    "            p_val = 2 * np.mean(boot_diffs <= 0)\n",
    "        else:\n",
    "            p_val = 2 * np.mean(boot_diffs >= 0)\n",
    "        \n",
    "        results.append({\n",
    "            'comparison': f'OTC vs {comp_group}',\n",
    "            'observed_diff': observed_diff,\n",
    "            'ci_low': ci_low,\n",
    "            'ci_high': ci_high,\n",
    "            'p_value': p_val\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results), subject_gaps\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BOOTSTRAP ANALYSIS: OTC BILATERAL ADVANTAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for approach_name in ['all_scramble', 'hybrid']:\n",
    "    print(f\"\\n--- {approach_name.upper()} ---\")\n",
    "    \n",
    "    if approach_name == 'hybrid':\n",
    "        select_df = hybrid_results['selectivity']\n",
    "        geom_df = hybrid_results['geometry']\n",
    "    else:\n",
    "        select_df = standard_results[approach_name]['selectivity']\n",
    "        geom_df = standard_results[approach_name]['geometry']\n",
    "    \n",
    "    print(\"\\nSelectivity Change (bilateral advantage = more reorganization):\")\n",
    "    boot_results, gaps = bootstrap_group_comparison(select_df, 'selectivity_change')\n",
    "    print(f\"  Subject gaps - OTC: {gaps['OTC'].mean():.3f}, nonOTC: {gaps['nonOTC'].mean():.3f}, control: {gaps['control'].mean():.3f}\")\n",
    "    for _, row in boot_results.iterrows():\n",
    "        sig = '***' if row['p_value'] < 0.001 else '**' if row['p_value'] < 0.01 else '*' if row['p_value'] < 0.05 else ''\n",
    "        print(f\"  {row['comparison']}: diff={row['observed_diff']:.3f}, 95%CI=[{row['ci_low']:.3f}, {row['ci_high']:.3f}], p={row['p_value']:.4f} {sig}\")\n",
    "    \n",
    "    print(\"\\nGeometry Preservation (bilateral disadvantage = more reorganization):\")\n",
    "    boot_results, gaps = bootstrap_group_comparison(geom_df, 'geometry_preservation')\n",
    "    print(f\"  Subject gaps - OTC: {gaps['OTC'].mean():.3f}, nonOTC: {gaps['nonOTC'].mean():.3f}, control: {gaps['control'].mean():.3f}\")\n",
    "    for _, row in boot_results.iterrows():\n",
    "        sig = '***' if row['p_value'] < 0.001 else '**' if row['p_value'] < 0.01 else '*' if row['p_value'] < 0.05 else ''\n",
    "        print(f\"  {row['comparison']}: diff={row['observed_diff']:.3f}, 95%CI=[{row['ci_low']:.3f}, {row['ci_high']:.3f}], p={row['p_value']:.4f} {sig}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 14: Decision and Final Export\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"DECISION: WHICH CONTRAST SCHEME TO USE?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the comparisons above, evaluate:\n",
    "\n",
    "1. ROI YIELD: Does the scheme find meaningful ROIs for all categories?\n",
    "   - Check Word ROI voxel counts (liu_mixed may have very few)\n",
    "   \n",
    "2. THEORETICAL CONSISTENCY: Same baseline across categories for RSA?\n",
    "   - all_scramble and all_vs_others are consistent\n",
    "   - liu_mixed and current_differential mix baselines\n",
    "   \n",
    "3. STATISTICAL POWER: Does the scheme detect the hypothesized effect?\n",
    "   - OTC bilateral > unilateral change\n",
    "\n",
    "4. HYBRID APPROACH: Does separating localization from patterns help?\n",
    "   - May get better ROI localization (liu_mixed) \n",
    "   - While maintaining RSA consistency (all_scramble patterns)\n",
    "\n",
    "RECOMMENDATION: Review the summary tables above and decide.\n",
    "\"\"\")\n",
    "\n",
    "# Show final recommendation based on results\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"QUANTITATIVE COMPARISON:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "for approach in ['liu_mixed', 'all_scramble', 'current_differential', 'hybrid']:\n",
    "    if approach not in approach_tests:\n",
    "        continue\n",
    "    \n",
    "    row = {'approach': approach}\n",
    "    \n",
    "    # Get OTC p-values\n",
    "    if 'selectivity' in approach_tests[approach]:\n",
    "        sel_df = approach_tests[approach]['selectivity']\n",
    "        otc_sel = sel_df[sel_df['group'] == 'OTC']\n",
    "        if len(otc_sel) > 0:\n",
    "            row['selectivity_p'] = otc_sel['p'].values[0]\n",
    "            row['selectivity_diff'] = otc_sel['difference'].values[0]\n",
    "    \n",
    "    if 'geometry' in approach_tests[approach]:\n",
    "        geo_df = approach_tests[approach]['geometry']\n",
    "        otc_geo = geo_df[geo_df['group'] == 'OTC']\n",
    "        if len(otc_geo) > 0:\n",
    "            row['geometry_p'] = otc_geo['p'].values[0]\n",
    "            row['geometry_diff'] = otc_geo['difference'].values[0]\n",
    "    \n",
    "    comparison_data.append(row)\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_data)\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 15: Export Final Results with Chosen Approach\n",
    "\n",
    "# %%\n",
    "# Set the chosen approach here after reviewing results\n",
    "CHOSEN_APPROACH = 'hybrid'  # Change this based on Cell 14 analysis\n",
    "\n",
    "print(f\"=\"*70)\n",
    "print(f\"EXPORTING FINAL RESULTS: {CHOSEN_APPROACH}\")\n",
    "print(f\"=\"*70)\n",
    "\n",
    "if CHOSEN_APPROACH == 'hybrid':\n",
    "    final_results = hybrid_results\n",
    "else:\n",
    "    final_results = standard_results[CHOSEN_APPROACH]\n",
    "\n",
    "# Build comprehensive results DataFrame\n",
    "export_data = []\n",
    "\n",
    "for _, row in final_results['selectivity'].iterrows():\n",
    "    sid = row['subject']\n",
    "    info = SUBJECTS[sid]\n",
    "    \n",
    "    # Get matching geometry and drift\n",
    "    geom_match = final_results['geometry'][\n",
    "        (final_results['geometry']['subject'] == sid) & \n",
    "        (final_results['geometry']['hemi'] == row['hemi']) &\n",
    "        (final_results['geometry']['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    drift_match = final_results['drift'][\n",
    "        (final_results['drift']['subject'] == sid) & \n",
    "        (final_results['drift']['hemi'] == row['hemi']) &\n",
    "        (final_results['drift']['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    export_row = {\n",
    "        'Subject': row['code'],\n",
    "        'Group': info['group'],\n",
    "        'Surgery_Side': info.get('surgery_side', 'na'),\n",
    "        'Intact_Hemisphere': 'left' if info['hemi'] == 'l' else 'right',\n",
    "        'Sex': info.get('sex', 'na'),\n",
    "        'nonpt_hemi': row['hemi'].upper() if info['group'] == 'control' else 'na',\n",
    "        'Category': row['category'].title(),\n",
    "        'Category_Type': 'Bilateral' if row['category'] in BILATERAL else 'Unilateral',\n",
    "        'age_1': info.get('age_1', np.nan),\n",
    "        'age_2': info.get('age_2', np.nan),\n",
    "        'yr_gap': info.get('age_2', 0) - info.get('age_1', 0) if info.get('age_1') and info.get('age_2') else np.nan,\n",
    "        'Selectivity_Change': row['selectivity_change'],\n",
    "        'Spatial_Relocation_mm': drift_match['spatial_drift_mm'].values[0] if len(drift_match) > 0 else np.nan,\n",
    "        'Geometry_Preservation_6mm': geom_match['geometry_preservation'].values[0] if len(geom_match) > 0 else np.nan,\n",
    "    }\n",
    "    \n",
    "    export_data.append(export_row)\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# Add MDS shift (averaged across ROI categories for each measured category)\n",
    "mds_df = final_results['mds']\n",
    "mds_summary = mds_df.groupby(['subject', 'measured_category'])['mds_shift'].mean().reset_index()\n",
    "\n",
    "for i, row in export_df.iterrows():\n",
    "    sid = [s for s in SUBJECTS if SUBJECTS[s]['code'] == row['Subject']][0]\n",
    "    cat = row['Category'].lower()\n",
    "    \n",
    "    mds_match = mds_summary[\n",
    "        (mds_summary['subject'] == sid) & \n",
    "        (mds_summary['measured_category'] == cat)\n",
    "    ]\n",
    "    \n",
    "    if len(mds_match) > 0:\n",
    "        export_df.loc[i, 'MDS_Shift'] = mds_match['mds_shift'].values[0]\n",
    "\n",
    "# Save\n",
    "output_file = OUTPUT_DIR / 'results_final_corrected.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Saved to: {output_file}\")\n",
    "print(f\"  Shape: {export_df.shape}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"FINAL SUMMARY BY GROUP AND CATEGORY:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n{'Measure':<25} {'Group':<10} {'Face':<8} {'Word':<8} {'Object':<8} {'House':<8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for measure in ['Selectivity_Change', 'Geometry_Preservation_6mm', 'Spatial_Relocation_mm', 'MDS_Shift']:\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = export_df[export_df['Group'] == group]\n",
    "        vals = []\n",
    "        for cat in ['Face', 'Word', 'Object', 'House']:\n",
    "            cd = gd[gd['Category'] == cat][measure]\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 and cd.notna().any() else \"--\")\n",
    "        print(f\"{measure:<25} {group:<10} {vals[0]:<8} {vals[1]:<8} {vals[2]:<8} {vals[3]:<8}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220667a0",
   "metadata": {},
   "source": [
    "# new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2db32f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Excluding: ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
      "✓ Loaded 20 subjects (after exclusions)\n",
      "  OTC: 6\n",
      "  nonOTC: 7\n",
      "  control: 7\n",
      "✓ ROI extraction functions defined\n",
      "✓ RSA metric functions defined\n",
      "======================================================================\n",
      "EXTRACTING ROIs WITH ALL CONTRAST SCHEMES\n",
      "======================================================================\n",
      "\n",
      "liu_mixed...\n",
      "  ✓ 20 subjects, 108 ROIs\n",
      "\n",
      "all_scramble...\n",
      "  ✓ 20 subjects, 108 ROIs\n",
      "\n",
      "all_vs_others...\n",
      "  ✓ 20 subjects, 108 ROIs\n",
      "\n",
      "current_differential...\n",
      "  ✓ 20 subjects, 108 ROIs\n",
      "\n",
      "======================================================================\n",
      "======================================================================\n",
      "ROI YIELD COMPARISON BY CATEGORY\n",
      "======================================================================\n",
      "\n",
      "ROI counts by scheme and category:\n",
      "------------------------------------------------------------\n",
      "category              face  house  object  word\n",
      "scheme                                         \n",
      "all_scramble            27     27      27    26\n",
      "all_vs_others           27     26      27    24\n",
      "current_differential    27     27      27    25\n",
      "liu_mixed               27     27      27    21\n",
      "\n",
      "\n",
      "Mean voxel count by scheme and category:\n",
      "------------------------------------------------------------\n",
      "category                face   house  object    word\n",
      "scheme                                              \n",
      "all_scramble          3981.0  4751.0  7306.0  2432.0\n",
      "all_vs_others         2998.0  5510.0  6789.0  1035.0\n",
      "current_differential  3981.0  4751.0  7306.0  1899.0\n",
      "liu_mixed             1434.0  3508.0  7306.0   465.0\n",
      "\n",
      "\n",
      "WORD ROI VOXEL COUNTS (the problematic category):\n",
      "------------------------------------------------------------\n",
      "\n",
      "liu_mixed:\n",
      "  N ROIs: 21\n",
      "  Mean voxels: 465\n",
      "  Min voxels: 32\n",
      "  Max voxels: 1904\n",
      "\n",
      "all_scramble:\n",
      "  N ROIs: 26\n",
      "  Mean voxels: 2432\n",
      "  Min voxels: 96\n",
      "  Max voxels: 8193\n",
      "\n",
      "all_vs_others:\n",
      "  N ROIs: 24\n",
      "  Mean voxels: 1035\n",
      "  Min voxels: 21\n",
      "  Max voxels: 5188\n",
      "\n",
      "current_differential:\n",
      "  N ROIs: 25\n",
      "  Mean voxels: 1899\n",
      "  Min voxels: 117\n",
      "  Max voxels: 5396\n",
      "======================================================================\n",
      "COMPUTING METRICS: STANDARD APPROACH\n",
      "(Same contrast scheme for ROI localization AND pattern extraction)\n",
      "======================================================================\n",
      "\n",
      "liu_mixed...\n",
      "  Geometry: 102 ROIs\n",
      "  MDS: 408 measurements\n",
      "  Drift: 102 ROIs\n",
      "  Selectivity: 102 ROIs\n",
      "\n",
      "all_scramble...\n",
      "  Geometry: 107 ROIs\n",
      "  MDS: 428 measurements\n",
      "  Drift: 107 ROIs\n",
      "  Selectivity: 107 ROIs\n",
      "\n",
      "all_vs_others...\n",
      "  Geometry: 104 ROIs\n",
      "  MDS: 416 measurements\n",
      "  Drift: 104 ROIs\n",
      "  Selectivity: 104 ROIs\n",
      "\n",
      "current_differential...\n",
      "  Geometry: 106 ROIs\n",
      "  MDS: 424 measurements\n",
      "  Drift: 106 ROIs\n",
      "  Selectivity: 106 ROIs\n",
      "======================================================================\n",
      "COMPUTING METRICS: HYBRID APPROACH\n",
      "(Liu mixed for localization, All Scramble for patterns)\n",
      "======================================================================\n",
      "\n",
      "Using ROIs from: liu_mixed\n",
      "Using patterns from: all_scramble\n",
      "\n",
      "✓ Geometry: 102 ROIs\n",
      "✓ MDS: 408 measurements\n",
      "✓ Drift: 102 ROIs\n",
      "✓ Selectivity: 102 ROIs\n",
      "======================================================================\n",
      "RESULTS COMPARISON: GEOMETRY PRESERVATION\n",
      "(Higher = more stable, lower in bilateral = MORE reorganization)\n",
      "======================================================================\n",
      "\n",
      "--- liu_mixed (standard) ---\n",
      "\n",
      "Group      Face         Word         Object       House       \n",
      "------------------------------------------------------------\n",
      "OTC        0.761        0.654        0.705        0.562       \n",
      "nonOTC     0.857        0.624        0.886        0.543       \n",
      "control    0.777        0.793        0.796        0.554       \n",
      "\n",
      "--- all_scramble (standard) ---\n",
      "\n",
      "Group      Face         Word         Object       House       \n",
      "------------------------------------------------------------\n",
      "OTC        0.318        0.148        0.058        -0.107      \n",
      "nonOTC     0.549        0.593        0.687        0.604       \n",
      "control    0.635        0.301        0.550        0.489       \n",
      "\n",
      "--- hybrid (liu ROI + scramble pattern) ---\n",
      "\n",
      "Group      Face         Word         Object       House       \n",
      "------------------------------------------------------------\n",
      "OTC        0.316        0.015        0.058        -0.103      \n",
      "nonOTC     0.790        0.347        0.687        0.620       \n",
      "control    0.626        -0.081       0.550        0.462       \n",
      "\n",
      "======================================================================\n",
      "COMPARING BILATERAL vs UNILATERAL EFFECTS ACROSS APPROACHES\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: liu_mixed\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Geometry Preservation\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.634±0.310   0.712±0.307   -0.079     -0.61    0.5487 \n",
      "nonOTC       0.714±0.413   0.750±0.409   -0.035     -0.22    0.8248 \n",
      "control      0.675±0.351   0.784±0.232   -0.109     -1.30    0.2004 \n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Selectivity Change\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.378±0.291   0.188±0.189   +0.190     1.83    0.0809 \n",
      "nonOTC       0.153±0.086   0.087±0.077   +0.066     2.09    0.0467 *\n",
      "control      0.260±0.167   0.118±0.102   +0.142     3.61    0.0007 *\n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: all_scramble\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Geometry Preservation\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          -0.025±0.465   0.240±0.466   -0.265     -1.36    0.1872 \n",
      "nonOTC       0.646±0.282   0.571±0.411   +0.075     0.56    0.5799 \n",
      "control      0.519±0.455   0.468±0.426   +0.051     0.43    0.6661 \n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Selectivity Change\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.402±0.370   0.273±0.136   +0.129     1.09    0.2874 \n",
      "nonOTC       0.189±0.159   0.250±0.209   -0.061     -0.87    0.3937 \n",
      "control      0.239±0.165   0.223±0.181   +0.016     0.35    0.7287 \n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: current_differential\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Geometry Preservation\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.398±0.319   0.796±0.167   -0.398     -3.69    0.0014 *\n",
      "nonOTC       0.550±0.427   0.694±0.267   -0.143     -1.07    0.2963 \n",
      "control      0.724±0.264   0.681±0.360   +0.043     0.51    0.6141 \n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Selectivity Change\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.252±0.265   0.257±0.190   -0.005     -0.05    0.9586 \n",
      "nonOTC       0.154±0.145   0.206±0.138   -0.052     -0.97    0.3408 \n",
      "control      0.191±0.164   0.235±0.197   -0.043     -0.89    0.3774 \n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: HYBRID (liu ROI + scramble patterns)\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Geometry Preservation\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          -0.022±0.409   0.179±0.426   -0.202     -1.16    0.2591 \n",
      "nonOTC       0.653±0.275   0.586±0.488   +0.067     0.45    0.6588 \n",
      "control      0.506±0.473   0.332±0.560   +0.174     1.22    0.2290 \n",
      "\n",
      "======================================================================\n",
      "BILATERAL vs UNILATERAL: Selectivity Change\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral       Unilateral      Diff       t        p       \n",
      "----------------------------------------------------------------------\n",
      "OTC          0.379±0.314   0.403±0.344   -0.024     -0.17    0.8639 \n",
      "nonOTC       0.171±0.173   0.211±0.140   -0.040     -0.65    0.5220 \n",
      "control      0.293±0.198   0.331±0.245   -0.038     -0.62    0.5395 \n",
      "======================================================================\n",
      "SUMMARY: OTC BILATERAL vs UNILATERAL EFFECT BY APPROACH\n",
      "======================================================================\n",
      "\n",
      "Key question: Does OTC show significantly greater change in bilateral\n",
      "categories compared to unilateral? (This supports our hypothesis)\n",
      "\n",
      "Approach                  Measure              Bil-Uni Diff    p-value    Sig? \n",
      "---------------------------------------------------------------------------\n",
      "liu_mixed                 Geometry Pres.       -0.0785        0.5487     \n",
      "liu_mixed                 Selectivity Chg.     +0.1898        0.0809     \n",
      "all_scramble              Geometry Pres.       -0.2650        0.1872     \n",
      "all_scramble              Selectivity Chg.     +0.1292        0.2874     \n",
      "current_differential      Geometry Pres.       -0.3977        0.0014     ✓\n",
      "current_differential      Selectivity Chg.     -0.0051        0.9586     \n",
      "hybrid                    Geometry Pres.       -0.2019        0.2591     \n",
      "hybrid                    Selectivity Chg.     -0.0238        0.8639     \n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Note: For Geometry Preservation, NEGATIVE diff = bilateral shows MORE change\n",
      "      For Selectivity Change, POSITIVE diff = bilateral shows MORE change\n",
      "======================================================================\n",
      "DETAILED CATEGORY-LEVEL RESULTS\n",
      "======================================================================\n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: all_scramble\n",
      "######################################################################\n",
      "\n",
      "--- GEOMETRY PRESERVATION (higher = more stable) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        0.32       0.15       0.06       -0.11     \n",
      "nonOTC     0.55       0.59       0.69       0.60      \n",
      "control    0.64       0.30       0.55       0.49      \n",
      "\n",
      "--- SELECTIVITY CHANGE (higher = more change) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        0.27       0.27       0.39       0.42      \n",
      "nonOTC     0.23       0.27       0.14       0.24      \n",
      "control    0.22       0.23       0.21       0.27      \n",
      "\n",
      "--- SPATIAL DRIFT (mm) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        7.0        19.0       5.9        13.2      \n",
      "nonOTC     3.4        9.0        2.5        5.7       \n",
      "control    5.7        10.0       3.7        6.5       \n",
      "\n",
      "\n",
      "######################################################################\n",
      "APPROACH: hybrid\n",
      "######################################################################\n",
      "\n",
      "--- GEOMETRY PRESERVATION (higher = more stable) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        0.32       0.02       0.06       -0.10     \n",
      "nonOTC     0.79       0.35       0.69       0.62      \n",
      "control    0.63       -0.08      0.55       0.46      \n",
      "\n",
      "--- SELECTIVITY CHANGE (higher = more change) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        0.29       0.54       0.39       0.37      \n",
      "nonOTC     0.27       0.14       0.14       0.20      \n",
      "control    0.24       0.45       0.21       0.38      \n",
      "\n",
      "--- SPATIAL DRIFT (mm) ---\n",
      "Group      Face       Word       Object     House     \n",
      "--------------------------------------------------\n",
      "OTC        7.1        16.1       5.9        20.0      \n",
      "nonOTC     6.8        4.6        2.5        5.0       \n",
      "control    8.2        23.6       3.7        14.3      \n",
      "======================================================================\n",
      "BOOTSTRAP ANALYSIS: OTC BILATERAL ADVANTAGE\n",
      "======================================================================\n",
      "\n",
      "--- ALL_SCRAMBLE ---\n",
      "\n",
      "Selectivity Change (bilateral advantage = more reorganization):\n",
      "  Subject gaps - OTC: 0.122, nonOTC: -0.061, control: 0.016\n",
      "  OTC vs nonOTC: diff=0.183, 95%CI=[-0.094, 0.466], p=0.2040 \n",
      "  OTC vs control: diff=0.106, 95%CI=[-0.150, 0.347], p=0.4066 \n",
      "\n",
      "Geometry Preservation (bilateral disadvantage = more reorganization):\n",
      "  Subject gaps - OTC: -0.291, nonOTC: 0.075, control: 0.051\n",
      "  OTC vs nonOTC: diff=-0.366, 95%CI=[-0.816, 0.079], p=0.1104 \n",
      "  OTC vs control: diff=-0.342, 95%CI=[-0.650, -0.016], p=0.0414 *\n",
      "\n",
      "--- HYBRID ---\n",
      "\n",
      "Selectivity Change (bilateral advantage = more reorganization):\n",
      "  Subject gaps - OTC: -0.044, nonOTC: -0.055, control: -0.016\n",
      "  OTC vs nonOTC: diff=0.010, 95%CI=[-0.233, 0.275], p=0.9562 \n",
      "  OTC vs control: diff=-0.028, 95%CI=[-0.282, 0.238], p=0.8166 \n",
      "\n",
      "Geometry Preservation (bilateral disadvantage = more reorganization):\n",
      "  Subject gaps - OTC: -0.244, nonOTC: 0.061, control: 0.147\n",
      "  OTC vs nonOTC: diff=-0.305, 95%CI=[-0.689, 0.061], p=0.1102 \n",
      "  OTC vs control: diff=-0.391, 95%CI=[-0.795, 0.012], p=0.0582 \n",
      "======================================================================\n",
      "DECISION: WHICH CONTRAST SCHEME TO USE?\n",
      "======================================================================\n",
      "\n",
      "Based on the comparisons above, evaluate:\n",
      "\n",
      "1. ROI YIELD: Does the scheme find meaningful ROIs for all categories?\n",
      "   - Check Word ROI voxel counts (liu_mixed may have very few)\n",
      "   \n",
      "2. THEORETICAL CONSISTENCY: Same baseline across categories for RSA?\n",
      "   - all_scramble and all_vs_others are consistent\n",
      "   - liu_mixed and current_differential mix baselines\n",
      "   \n",
      "3. STATISTICAL POWER: Does the scheme detect the hypothesized effect?\n",
      "   - OTC bilateral > unilateral change\n",
      "\n",
      "4. HYBRID APPROACH: Does separating localization from patterns help?\n",
      "   - May get better ROI localization (liu_mixed) \n",
      "   - While maintaining RSA consistency (all_scramble patterns)\n",
      "\n",
      "RECOMMENDATION: Review the summary tables above and decide.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "QUANTITATIVE COMPARISON:\n",
      "----------------------------------------------------------------------\n",
      "            approach  selectivity_p  selectivity_diff  geometry_p  geometry_diff\n",
      "           liu_mixed       0.080902          0.189807    0.548660      -0.078523\n",
      "        all_scramble       0.287371          0.129213    0.187203      -0.264975\n",
      "current_differential       0.958608         -0.005092    0.001361      -0.397670\n",
      "              hybrid       0.863855         -0.023796    0.259117      -0.201946\n",
      "======================================================================\n",
      "EXPORTING FINAL RESULTS: hybrid\n",
      "======================================================================\n",
      "\n",
      "✓ Saved to: /user_data/csimmon2/git_repos/long_pt/B_analyses/results_final_corrected.csv\n",
      "  Shape: (102, 15)\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FINAL SUMMARY BY GROUP AND CATEGORY:\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Measure                   Group      Face     Word     Object   House   \n",
      "----------------------------------------------------------------------\n",
      "Selectivity_Change        OTC        0.29     0.54     0.39     0.37    \n",
      "Selectivity_Change        nonOTC     0.27     0.14     0.14     0.20    \n",
      "Selectivity_Change        control    0.24     0.45     0.21     0.38    \n",
      "\n",
      "Geometry_Preservation_6mm OTC        0.32     0.02     0.06     -0.10   \n",
      "Geometry_Preservation_6mm nonOTC     0.79     0.35     0.69     0.62    \n",
      "Geometry_Preservation_6mm control    0.63     -0.08    0.55     0.46    \n",
      "\n",
      "Spatial_Relocation_mm     OTC        7.11     16.13    5.93     19.99   \n",
      "Spatial_Relocation_mm     nonOTC     6.81     4.60     2.52     5.03    \n",
      "Spatial_Relocation_mm     control    8.15     23.60    3.66     14.34   \n",
      "\n",
      "MDS_Shift                 OTC        0.36     0.39     0.30     0.32    \n",
      "MDS_Shift                 nonOTC     0.21     0.26     0.24     0.25    \n",
      "MDS_Shift                 control    0.26     0.29     0.22     0.23    \n",
      "\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # Longitudinal RSA Analysis: Contrast Scheme Comparison\n",
    "# \n",
    "# **Study:** VOTC Resection - Bilateral vs Unilateral Visual Category Reorganization\n",
    "# \n",
    "# **Hypothesis:** Bilateral categories (Object, House) show greater representational \n",
    "# reorganization than unilateral categories (Face, Word) in OTC patients because \n",
    "# the hemispheres work collaboratively (not redundantly), so losing one forces compensation.\n",
    "# \n",
    "# **This notebook:**\n",
    "# 1. Compares 4 contrast schemes for ROI localization and pattern extraction\n",
    "# 2. Tests hybrid approach (Liu for localization, Scramble for patterns)\n",
    "# 3. Computes all RSA measures with each approach\n",
    "# 4. Determines optimal contrast scheme based on results\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 1: Setup & Configuration\n",
    "\n",
    "# %%\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, ttest_ind, ttest_rel\n",
    "from scipy.spatial.distance import squareform\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "OUTPUT_DIR = Path('/user_data/csimmon2/git_repos/long_pt/B_analyses')\n",
    "\n",
    "# Load subject info\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "# Session overrides\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# Subjects to exclude\n",
    "EXCLUDE_SUBJECTS = ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
    "\n",
    "# Categories\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "BILATERAL = ['object', 'house']\n",
    "UNILATERAL = ['face', 'word']\n",
    "\n",
    "# ============================================================\n",
    "# CONTRAST SCHEME DEFINITIONS\n",
    "# ============================================================\n",
    "\n",
    "# Scheme 1: Liu's original mixed contrasts (for ROI localization)\n",
    "COPE_LIU_MIXED = {\n",
    "    'face': (1, 1),    # Face > Object\n",
    "    'word': (4, 1),    # Word > Object  \n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (2, 1)    # House > Object\n",
    "}\n",
    "\n",
    "# Scheme 2: All vs Scramble (consistent baseline)\n",
    "COPE_ALL_SCRAMBLE = {\n",
    "    'face': (10, 1),   # Face > Scramble\n",
    "    'word': (12, 1),   # Word > Scramble\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (11, 1)   # House > Scramble\n",
    "}\n",
    "\n",
    "# Scheme 3: All vs Others (category vs mean of others)\n",
    "COPE_ALL_VS_OTHERS = {\n",
    "    'face': (6, 1),    # Face > mean(House+Object+Word+Scramble)\n",
    "    'word': (9, 1),    # Word > mean(Face+House+Object+Scramble)\n",
    "    'object': (8, 1),  # Object > mean(Face+House+Word+Scramble)\n",
    "    'house': (7, 1)    # House > mean(Face+Object+Word+Scramble)\n",
    "}\n",
    "\n",
    "# Scheme 4: Current differential (what Script 1 used - problematic)\n",
    "COPE_DIFFERENTIAL = {\n",
    "    'face': (10, 1),   # Face > Scramble\n",
    "    'word': (13, -1),  # Face > Word, flipped to Word > Face\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (11, 1)   # House > Scramble\n",
    "}\n",
    "\n",
    "CONTRAST_SCHEMES = {\n",
    "    'liu_mixed': COPE_LIU_MIXED,\n",
    "    'all_scramble': COPE_ALL_SCRAMBLE,\n",
    "    'all_vs_others': COPE_ALL_VS_OTHERS,\n",
    "    'current_differential': COPE_DIFFERENTIAL\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Excluding: {EXCLUDE_SUBJECTS}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 2: Load Subjects\n",
    "\n",
    "# %%\n",
    "def load_subjects():\n",
    "    \"\"\"Load all subjects from CSV, excluding problematic ones\"\"\"\n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        \n",
    "        if subject_id in EXCLUDE_SUBJECTS:\n",
    "            continue\n",
    "            \n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        sessions = sorted([d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()], key=int)\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        \n",
    "        if len(sessions) < 2:\n",
    "            continue\n",
    "        \n",
    "        hemi = 'l' if row.get('intact_hemi', 'left') == 'left' else 'r'\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemi,\n",
    "            'group': row['group'],\n",
    "            'patient': row['patient'] == 1,\n",
    "            'surgery_side': row.get('SurgerySide', None),\n",
    "            'sex': row.get('sex', None),\n",
    "            'age_1': row.get('age_1', None),\n",
    "            'age_2': row.get('age_2', None)\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "SUBJECTS = load_subjects()\n",
    "\n",
    "# Summary\n",
    "print(f\"✓ Loaded {len(SUBJECTS)} subjects (after exclusions)\")\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    n = sum(1 for s in SUBJECTS.values() if s['group'] == group)\n",
    "    print(f\"  {group}: {n}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 3: ROI Extraction Functions\n",
    "\n",
    "# %%\n",
    "def create_sphere(center_coord, affine, brain_shape, radius=6):\n",
    "    \"\"\"Create spherical mask around coordinate\"\"\"\n",
    "    grid = np.array(np.meshgrid(\n",
    "        np.arange(brain_shape[0]),\n",
    "        np.arange(brain_shape[1]),\n",
    "        np.arange(brain_shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "    \n",
    "    world = nib.affines.apply_affine(affine, grid)\n",
    "    distances = np.linalg.norm(world - center_coord, axis=1)\n",
    "    \n",
    "    mask = np.zeros(brain_shape, dtype=bool)\n",
    "    within = grid[distances <= radius]\n",
    "    for c in within:\n",
    "        mask[c[0], c[1], c[2]] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def extract_rois_single_scheme(cope_map, threshold_z=2.3, min_voxels=20):\n",
    "    \"\"\"Extract ROIs for all subjects using a single contrast scheme\"\"\"\n",
    "    \n",
    "    all_rois = {}\n",
    "    \n",
    "    for sid, info in SUBJECTS.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        \n",
    "        if not roi_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        all_rois[sid] = {}\n",
    "        \n",
    "        # For controls, extract both hemispheres\n",
    "        hemis = ['l', 'r'] if info['group'] == 'control' else [info['hemi']]\n",
    "        \n",
    "        for hemi in hemis:\n",
    "            for category in CATEGORIES:\n",
    "                cope_num, mult = cope_map[category]\n",
    "                \n",
    "                # Load search mask\n",
    "                mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "                if not mask_file.exists():\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mask_img = nib.load(mask_file)\n",
    "                    search_mask = mask_img.get_fdata() > 0\n",
    "                    affine = mask_img.affine\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                roi_key = f'{hemi}_{category}'\n",
    "                all_rois[sid][roi_key] = {}\n",
    "                \n",
    "                for session in info['sessions']:\n",
    "                    feat_dir = BASE_DIR / sid / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                    z_name = 'zstat1.nii.gz' if session == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        z_data = nib.load(cope_file).get_fdata() * mult\n",
    "                        suprathresh = (z_data > threshold_z) & search_mask\n",
    "                        \n",
    "                        if suprathresh.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        labeled, n_clusters = label(suprathresh)\n",
    "                        if n_clusters == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        # Largest cluster\n",
    "                        sizes = [(labeled == i).sum() for i in range(1, n_clusters + 1)]\n",
    "                        best_idx = np.argmax(sizes) + 1\n",
    "                        roi_mask = (labeled == best_idx)\n",
    "                        \n",
    "                        if roi_mask.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        peak_idx = np.unravel_index(np.argmax(z_data * roi_mask), z_data.shape)\n",
    "                        \n",
    "                        all_rois[sid][roi_key][session] = {\n",
    "                            'n_voxels': int(roi_mask.sum()),\n",
    "                            'peak_z': z_data[peak_idx],\n",
    "                            'centroid': nib.affines.apply_affine(affine, center_of_mass(roi_mask)),\n",
    "                            'peak_coord': nib.affines.apply_affine(affine, peak_idx),\n",
    "                            'roi_mask': roi_mask,\n",
    "                            'affine': affine,\n",
    "                            'shape': z_data.shape\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "    \n",
    "    return all_rois\n",
    "\n",
    "print(\"✓ ROI extraction functions defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 4: RSA Metric Functions\n",
    "\n",
    "# %%\n",
    "def compute_rdm(patterns):\n",
    "    \"\"\"Compute RDM from pattern matrix (categories x voxels)\"\"\"\n",
    "    corr = np.corrcoef(patterns)\n",
    "    rdm = 1 - corr\n",
    "    return rdm, corr\n",
    "\n",
    "\n",
    "def compute_geometry_preservation(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    Geometry Preservation: RDM stability across sessions\n",
    "    - Extract patterns from sphere at each session's centroid\n",
    "    - Correlate T1 and T2 RDMs\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            # Get reference for sphere creation\n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    rdm, _ = compute_rdm(np.array(patterns))\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                triu = np.triu_indices(4, k=1)\n",
    "                r, _ = pearsonr(rdms[sessions[0]][triu], rdms[sessions[-1]][triu])\n",
    "                \n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'geometry_preservation': r\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_mds_shift(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    MDS Shift: Procrustes-aligned embedding distance\n",
    "    - MDS embed RDMs to 2D\n",
    "    - Align with Procrustes\n",
    "    - Measure movement of each category\n",
    "    \"\"\"\n",
    "    def mds_2d(rdm):\n",
    "        n = rdm.shape[0]\n",
    "        H = np.eye(n) - np.ones((n, n)) / n\n",
    "        B = -0.5 * H @ (rdm ** 2) @ H\n",
    "        eigvals, eigvecs = np.linalg.eigh(B)\n",
    "        idx = np.argsort(eigvals)[::-1]\n",
    "        coords = eigvecs[:, idx[:2]] * np.sqrt(np.maximum(eigvals[idx[:2]], 0))\n",
    "        return coords\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            roi_category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    rdm, _ = compute_rdm(np.array(patterns))\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                try:\n",
    "                    coords_t1 = mds_2d(rdms[sessions[0]])\n",
    "                    coords_t2 = mds_2d(rdms[sessions[-1]])\n",
    "                    \n",
    "                    R, _ = orthogonal_procrustes(coords_t1, coords_t2)\n",
    "                    coords_t1_aligned = coords_t1 @ R\n",
    "                    \n",
    "                    for i, cat in enumerate(CATEGORIES):\n",
    "                        dist = np.linalg.norm(coords_t1_aligned[i] - coords_t2[i])\n",
    "                        results.append({\n",
    "                            'subject': sid,\n",
    "                            'code': info['code'],\n",
    "                            'group': info['group'],\n",
    "                            'hemi': hemi,\n",
    "                            'roi_category': roi_category,\n",
    "                            'measured_category': cat,\n",
    "                            'mds_shift': dist\n",
    "                        })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_spatial_drift(rois):\n",
    "    \"\"\"\n",
    "    Spatial Drift: Euclidean distance between T1 and T2 peak centroids\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            c1 = sessions_data[sessions[0]]['centroid']\n",
    "            c2 = sessions_data[sessions[-1]]['centroid']\n",
    "            drift = np.linalg.norm(np.array(c2) - np.array(c1))\n",
    "            \n",
    "            results.append({\n",
    "                'subject': sid,\n",
    "                'code': info['code'],\n",
    "                'group': info['group'],\n",
    "                'hemi': hemi,\n",
    "                'category': category,\n",
    "                'spatial_drift_mm': drift,\n",
    "                't1_peak_z': sessions_data[sessions[0]]['peak_z']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_selectivity_change(rois, pattern_cope_map):\n",
    "    \"\"\"\n",
    "    Selectivity Change (Liu Distinctiveness):\n",
    "    - Correlation of preferred category with non-preferred categories\n",
    "    - Change from T1 to T2\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            distinctiveness = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius=6)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = {}\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns[cat] = pattern\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    # Compute correlation of preferred with non-preferred\n",
    "                    pref_pattern = patterns[category]\n",
    "                    nonpref_corrs = []\n",
    "                    for other_cat in CATEGORIES:\n",
    "                        if other_cat != category:\n",
    "                            r, _ = pearsonr(pref_pattern, patterns[other_cat])\n",
    "                            nonpref_corrs.append(np.arctanh(np.clip(r, -0.999, 0.999)))\n",
    "                    \n",
    "                    distinctiveness[ses] = np.mean(nonpref_corrs)\n",
    "            \n",
    "            if len(distinctiveness) == 2:\n",
    "                change = abs(distinctiveness[sessions[-1]] - distinctiveness[sessions[0]])\n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'selectivity_change': change,\n",
    "                    't1_distinctiveness': distinctiveness[sessions[0]],\n",
    "                    't2_distinctiveness': distinctiveness[sessions[-1]]\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ RSA metric functions defined\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 5: Extract ROIs with All Contrast Schemes\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING ROIs WITH ALL CONTRAST SCHEMES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "all_rois = {}\n",
    "for scheme_name, cope_map in CONTRAST_SCHEMES.items():\n",
    "    print(f\"\\n{scheme_name}...\")\n",
    "    all_rois[scheme_name] = extract_rois_single_scheme(cope_map)\n",
    "    \n",
    "    # Count ROIs\n",
    "    n_rois = sum(len(roi_data) for roi_data in all_rois[scheme_name].values())\n",
    "    n_subjects = len([s for s in all_rois[scheme_name] if all_rois[scheme_name][s]])\n",
    "    print(f\"  ✓ {n_subjects} subjects, {n_rois} ROIs\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 6: Compare ROI Yields Across Schemes\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"ROI YIELD COMPARISON BY CATEGORY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Count ROIs per category per scheme\n",
    "yield_data = []\n",
    "for scheme_name, rois in all_rois.items():\n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            if len(sessions_data) >= 2:  # Has both timepoints\n",
    "                hemi = roi_key.split('_')[0]\n",
    "                category = roi_key.split('_')[1]\n",
    "                n_voxels_t1 = sessions_data[sorted(sessions_data.keys())[0]]['n_voxels']\n",
    "                \n",
    "                yield_data.append({\n",
    "                    'scheme': scheme_name,\n",
    "                    'subject': sid,\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'n_voxels': n_voxels_t1\n",
    "                })\n",
    "\n",
    "yield_df = pd.DataFrame(yield_data)\n",
    "\n",
    "print(\"\\nROI counts by scheme and category:\")\n",
    "print(\"-\"*60)\n",
    "pivot = yield_df.groupby(['scheme', 'category']).size().unstack(fill_value=0)\n",
    "print(pivot)\n",
    "\n",
    "print(\"\\n\\nMean voxel count by scheme and category:\")\n",
    "print(\"-\"*60)\n",
    "pivot_vox = yield_df.groupby(['scheme', 'category'])['n_voxels'].mean().unstack()\n",
    "print(pivot_vox.round(0))\n",
    "\n",
    "# Word ROI problem visualization\n",
    "print(\"\\n\\nWORD ROI VOXEL COUNTS (the problematic category):\")\n",
    "print(\"-\"*60)\n",
    "word_data = yield_df[yield_df['category'] == 'word']\n",
    "for scheme in CONTRAST_SCHEMES.keys():\n",
    "    scheme_word = word_data[word_data['scheme'] == scheme]\n",
    "    print(f\"\\n{scheme}:\")\n",
    "    print(f\"  N ROIs: {len(scheme_word)}\")\n",
    "    print(f\"  Mean voxels: {scheme_word['n_voxels'].mean():.0f}\")\n",
    "    print(f\"  Min voxels: {scheme_word['n_voxels'].min()}\")\n",
    "    print(f\"  Max voxels: {scheme_word['n_voxels'].max()}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 7: Compute All Metrics - Standard Approach (Same scheme for localization and patterns)\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"COMPUTING METRICS: STANDARD APPROACH\")\n",
    "print(\"(Same contrast scheme for ROI localization AND pattern extraction)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "standard_results = {}\n",
    "\n",
    "for scheme_name in CONTRAST_SCHEMES.keys():\n",
    "    print(f\"\\n{scheme_name}...\")\n",
    "    \n",
    "    rois = all_rois[scheme_name]\n",
    "    cope_map = CONTRAST_SCHEMES[scheme_name]\n",
    "    \n",
    "    # Compute all metrics\n",
    "    geom = compute_geometry_preservation(rois, cope_map)\n",
    "    mds = compute_mds_shift(rois, cope_map)\n",
    "    drift = compute_spatial_drift(rois)\n",
    "    select = compute_selectivity_change(rois, cope_map)\n",
    "    \n",
    "    standard_results[scheme_name] = {\n",
    "        'geometry': geom,\n",
    "        'mds': mds,\n",
    "        'drift': drift,\n",
    "        'selectivity': select\n",
    "    }\n",
    "    \n",
    "    print(f\"  Geometry: {len(geom)} ROIs\")\n",
    "    print(f\"  MDS: {len(mds)} measurements\")\n",
    "    print(f\"  Drift: {len(drift)} ROIs\")\n",
    "    print(f\"  Selectivity: {len(select)} ROIs\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 8: Compute Metrics - Hybrid Approach\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"COMPUTING METRICS: HYBRID APPROACH\")\n",
    "print(\"(Liu mixed for localization, All Scramble for patterns)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Use Liu mixed ROIs, but All Scramble patterns\n",
    "hybrid_rois = all_rois['liu_mixed']\n",
    "pattern_cope = COPE_ALL_SCRAMBLE\n",
    "\n",
    "print(\"\\nUsing ROIs from: liu_mixed\")\n",
    "print(\"Using patterns from: all_scramble\")\n",
    "\n",
    "hybrid_results = {\n",
    "    'geometry': compute_geometry_preservation(hybrid_rois, pattern_cope),\n",
    "    'mds': compute_mds_shift(hybrid_rois, pattern_cope),\n",
    "    'drift': compute_spatial_drift(hybrid_rois),\n",
    "    'selectivity': compute_selectivity_change(hybrid_rois, pattern_cope)\n",
    "}\n",
    "\n",
    "print(f\"\\n✓ Geometry: {len(hybrid_results['geometry'])} ROIs\")\n",
    "print(f\"✓ MDS: {len(hybrid_results['mds'])} measurements\")\n",
    "print(f\"✓ Drift: {len(hybrid_results['drift'])} ROIs\")\n",
    "print(f\"✓ Selectivity: {len(hybrid_results['selectivity'])} ROIs\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 9: Compare Results Across Approaches\n",
    "\n",
    "# %%\n",
    "def summarize_by_category(df, metric_col, groups=['OTC', 'nonOTC', 'control']):\n",
    "    \"\"\"Summarize metric by group and category\"\"\"\n",
    "    summary = []\n",
    "    for group in groups:\n",
    "        group_data = df[df['group'] == group]\n",
    "        for cat in CATEGORIES:\n",
    "            cat_data = group_data[group_data['category'] == cat][metric_col]\n",
    "            if len(cat_data) > 0:\n",
    "                summary.append({\n",
    "                    'group': group,\n",
    "                    'category': cat,\n",
    "                    'mean': cat_data.mean(),\n",
    "                    'std': cat_data.std(),\n",
    "                    'n': len(cat_data)\n",
    "                })\n",
    "    return pd.DataFrame(summary)\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESULTS COMPARISON: GEOMETRY PRESERVATION\")\n",
    "print(\"(Higher = more stable, lower in bilateral = MORE reorganization)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for approach_name, results in [('liu_mixed (standard)', standard_results['liu_mixed']),\n",
    "                                ('all_scramble (standard)', standard_results['all_scramble']),\n",
    "                                ('hybrid (liu ROI + scramble pattern)', {'geometry': hybrid_results['geometry']})]:\n",
    "    print(f\"\\n--- {approach_name} ---\")\n",
    "    geom_df = results['geometry'] if 'geometry' in results else results.get('geometry')\n",
    "    \n",
    "    if geom_df is None or len(geom_df) == 0:\n",
    "        print(\"  No data\")\n",
    "        continue\n",
    "    \n",
    "    # Filter to intact hemisphere for patients\n",
    "    filtered = []\n",
    "    for _, row in geom_df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    \n",
    "    print(f\"\\n{'Group':<10} {'Face':<12} {'Word':<12} {'Object':<12} {'House':<12}\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['geometry_preservation']\n",
    "            if len(cd) > 0:\n",
    "                vals.append(f\"{cd.mean():.3f}\")\n",
    "            else:\n",
    "                vals.append(\"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<12} {vals[1]:<12} {vals[2]:<12} {vals[3]:<12}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 10: Statistical Tests - Compare Bilateral vs Unilateral Effect\n",
    "\n",
    "# %%\n",
    "def test_bilateral_effect(df, metric_col, metric_name):\n",
    "    \"\"\"Test if bilateral > unilateral change (or < for stability metrics)\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"BILATERAL vs UNILATERAL: {metric_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Filter to intact hemisphere for patients\n",
    "    filtered = []\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'Group':<12} {'Bilateral':<15} {'Unilateral':<15} {'Diff':<10} {'t':<8} {'p':<8}\")\n",
    "    print(\"-\"*70)\n",
    "    \n",
    "    results = []\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        bil = gd[gd['cat_type'] == 'Bilateral'][metric_col]\n",
    "        uni = gd[gd['cat_type'] == 'Unilateral'][metric_col]\n",
    "        \n",
    "        if len(bil) > 1 and len(uni) > 1:\n",
    "            t, p = ttest_ind(bil, uni)\n",
    "            diff = bil.mean() - uni.mean()\n",
    "            sig = '*' if p < 0.05 else ''\n",
    "            print(f\"{group:<12} {bil.mean():.3f}±{bil.std():.3f}   {uni.mean():.3f}±{uni.std():.3f}   {diff:+.3f}     {t:.2f}    {p:.4f} {sig}\")\n",
    "            \n",
    "            results.append({\n",
    "                'group': group,\n",
    "                'bilateral_mean': bil.mean(),\n",
    "                'unilateral_mean': uni.mean(),\n",
    "                'difference': diff,\n",
    "                't': t,\n",
    "                'p': p\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARING BILATERAL vs UNILATERAL EFFECTS ACROSS APPROACHES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Test each approach\n",
    "approach_tests = {}\n",
    "\n",
    "for scheme_name in ['liu_mixed', 'all_scramble', 'current_differential']:\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"APPROACH: {scheme_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    results = standard_results[scheme_name]\n",
    "    \n",
    "    approach_tests[scheme_name] = {}\n",
    "    \n",
    "    # Geometry Preservation (lower bilateral = more change)\n",
    "    if len(results['geometry']) > 0:\n",
    "        approach_tests[scheme_name]['geometry'] = test_bilateral_effect(\n",
    "            results['geometry'], 'geometry_preservation', 'Geometry Preservation'\n",
    "        )\n",
    "    \n",
    "    # Selectivity Change (higher bilateral = more change)\n",
    "    if len(results['selectivity']) > 0:\n",
    "        approach_tests[scheme_name]['selectivity'] = test_bilateral_effect(\n",
    "            results['selectivity'], 'selectivity_change', 'Selectivity Change'\n",
    "        )\n",
    "\n",
    "# Hybrid approach\n",
    "print(f\"\\n\\n{'#'*70}\")\n",
    "print(\"APPROACH: HYBRID (liu ROI + scramble patterns)\")\n",
    "print(f\"{'#'*70}\")\n",
    "\n",
    "approach_tests['hybrid'] = {}\n",
    "approach_tests['hybrid']['geometry'] = test_bilateral_effect(\n",
    "    hybrid_results['geometry'], 'geometry_preservation', 'Geometry Preservation'\n",
    ")\n",
    "approach_tests['hybrid']['selectivity'] = test_bilateral_effect(\n",
    "    hybrid_results['selectivity'], 'selectivity_change', 'Selectivity Change'\n",
    ")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 11: Summary Comparison Table\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"SUMMARY: OTC BILATERAL vs UNILATERAL EFFECT BY APPROACH\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nKey question: Does OTC show significantly greater change in bilateral\")\n",
    "print(\"categories compared to unilateral? (This supports our hypothesis)\")\n",
    "print()\n",
    "\n",
    "print(f\"{'Approach':<25} {'Measure':<20} {'Bil-Uni Diff':<15} {'p-value':<10} {'Sig?':<5}\")\n",
    "print(\"-\"*75)\n",
    "\n",
    "for approach_name in ['liu_mixed', 'all_scramble', 'current_differential', 'hybrid']:\n",
    "    if approach_name not in approach_tests:\n",
    "        continue\n",
    "    \n",
    "    for measure in ['geometry', 'selectivity']:\n",
    "        if measure not in approach_tests[approach_name]:\n",
    "            continue\n",
    "        \n",
    "        test_df = approach_tests[approach_name][measure]\n",
    "        otc_row = test_df[test_df['group'] == 'OTC']\n",
    "        \n",
    "        if len(otc_row) == 0:\n",
    "            continue\n",
    "        \n",
    "        diff = otc_row['difference'].values[0]\n",
    "        p = otc_row['p'].values[0]\n",
    "        sig = '✓' if p < 0.05 else ''\n",
    "        \n",
    "        # For geometry, negative diff means bilateral has MORE change (lower stability)\n",
    "        # For selectivity, positive diff means bilateral has MORE change\n",
    "        measure_label = 'Geometry Pres.' if measure == 'geometry' else 'Selectivity Chg.'\n",
    "        \n",
    "        print(f\"{approach_name:<25} {measure_label:<20} {diff:+.4f}        {p:.4f}     {sig}\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*75)\n",
    "print(\"Note: For Geometry Preservation, NEGATIVE diff = bilateral shows MORE change\")\n",
    "print(\"      For Selectivity Change, POSITIVE diff = bilateral shows MORE change\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 12: Detailed Category-Level Results for Best Approach\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"DETAILED CATEGORY-LEVEL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine best approach based on OTC significance\n",
    "# Let's show results for multiple approaches for comparison\n",
    "\n",
    "for approach_name in ['all_scramble', 'hybrid']:\n",
    "    print(f\"\\n\\n{'#'*70}\")\n",
    "    print(f\"APPROACH: {approach_name}\")\n",
    "    print(f\"{'#'*70}\")\n",
    "    \n",
    "    if approach_name == 'hybrid':\n",
    "        geom_df = hybrid_results['geometry']\n",
    "        select_df = hybrid_results['selectivity']\n",
    "        drift_df = hybrid_results['drift']\n",
    "    else:\n",
    "        geom_df = standard_results[approach_name]['geometry']\n",
    "        select_df = standard_results[approach_name]['selectivity']\n",
    "        drift_df = standard_results[approach_name]['drift']\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    def filter_intact(df):\n",
    "        filtered = []\n",
    "        for _, row in df.iterrows():\n",
    "            sid = row['subject']\n",
    "            info = SUBJECTS[sid]\n",
    "            if info['group'] == 'control':\n",
    "                filtered.append(row)\n",
    "            elif row['hemi'] == info['hemi']:\n",
    "                filtered.append(row)\n",
    "        return pd.DataFrame(filtered)\n",
    "    \n",
    "    geom_filt = filter_intact(geom_df)\n",
    "    select_filt = filter_intact(select_df)\n",
    "    drift_filt = filter_intact(drift_df)\n",
    "    \n",
    "    print(\"\\n--- GEOMETRY PRESERVATION (higher = more stable) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = geom_filt[geom_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['geometry_preservation']\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "    \n",
    "    print(\"\\n--- SELECTIVITY CHANGE (higher = more change) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = select_filt[select_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['selectivity_change']\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "    \n",
    "    print(\"\\n--- SPATIAL DRIFT (mm) ---\")\n",
    "    print(f\"{'Group':<10} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*50)\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = drift_filt[drift_filt['group'] == group]\n",
    "        vals = []\n",
    "        for cat in CATEGORIES:\n",
    "            cd = gd[gd['category'] == cat]['spatial_drift_mm']\n",
    "            vals.append(f\"{cd.mean():.1f}\" if len(cd) > 0 else \"--\")\n",
    "        print(f\"{group:<10} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 13: Bootstrap Analysis for Robust Inference\n",
    "\n",
    "# %%\n",
    "def bootstrap_group_comparison(df, metric_col, n_boot=10000, seed=42):\n",
    "    \"\"\"Bootstrap test for OTC bilateral advantage vs other groups\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    filtered = []\n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    \n",
    "    filtered_df = pd.DataFrame(filtered)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    # Calculate subject-level bilateral advantage (gap)\n",
    "    subject_gaps = {}\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        gaps = []\n",
    "        for sid in gd['subject'].unique():\n",
    "            sd = gd[gd['subject'] == sid]\n",
    "            bil = sd[sd['cat_type'] == 'Bilateral'][metric_col].mean()\n",
    "            uni = sd[sd['cat_type'] == 'Unilateral'][metric_col].mean()\n",
    "            if pd.notna(bil) and pd.notna(uni):\n",
    "                gaps.append(bil - uni)\n",
    "        subject_gaps[group] = np.array(gaps)\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Compare OTC vs each other group\n",
    "    for comp_group in ['nonOTC', 'control']:\n",
    "        g1 = subject_gaps['OTC']\n",
    "        g2 = subject_gaps[comp_group]\n",
    "        \n",
    "        if len(g1) < 2 or len(g2) < 2:\n",
    "            continue\n",
    "        \n",
    "        observed_diff = np.mean(g1) - np.mean(g2)\n",
    "        \n",
    "        boot_diffs = []\n",
    "        for _ in range(n_boot):\n",
    "            s1 = np.random.choice(g1, size=len(g1), replace=True)\n",
    "            s2 = np.random.choice(g2, size=len(g2), replace=True)\n",
    "            boot_diffs.append(np.mean(s1) - np.mean(s2))\n",
    "        \n",
    "        boot_diffs = np.array(boot_diffs)\n",
    "        ci_low = np.percentile(boot_diffs, 2.5)\n",
    "        ci_high = np.percentile(boot_diffs, 97.5)\n",
    "        \n",
    "        # Two-sided p-value\n",
    "        if observed_diff > 0:\n",
    "            p_val = 2 * np.mean(boot_diffs <= 0)\n",
    "        else:\n",
    "            p_val = 2 * np.mean(boot_diffs >= 0)\n",
    "        \n",
    "        results.append({\n",
    "            'comparison': f'OTC vs {comp_group}',\n",
    "            'observed_diff': observed_diff,\n",
    "            'ci_low': ci_low,\n",
    "            'ci_high': ci_high,\n",
    "            'p_value': p_val\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results), subject_gaps\n",
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"BOOTSTRAP ANALYSIS: OTC BILATERAL ADVANTAGE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for approach_name in ['all_scramble', 'hybrid']:\n",
    "    print(f\"\\n--- {approach_name.upper()} ---\")\n",
    "    \n",
    "    if approach_name == 'hybrid':\n",
    "        select_df = hybrid_results['selectivity']\n",
    "        geom_df = hybrid_results['geometry']\n",
    "    else:\n",
    "        select_df = standard_results[approach_name]['selectivity']\n",
    "        geom_df = standard_results[approach_name]['geometry']\n",
    "    \n",
    "    print(\"\\nSelectivity Change (bilateral advantage = more reorganization):\")\n",
    "    boot_results, gaps = bootstrap_group_comparison(select_df, 'selectivity_change')\n",
    "    print(f\"  Subject gaps - OTC: {gaps['OTC'].mean():.3f}, nonOTC: {gaps['nonOTC'].mean():.3f}, control: {gaps['control'].mean():.3f}\")\n",
    "    for _, row in boot_results.iterrows():\n",
    "        sig = '***' if row['p_value'] < 0.001 else '**' if row['p_value'] < 0.01 else '*' if row['p_value'] < 0.05 else ''\n",
    "        print(f\"  {row['comparison']}: diff={row['observed_diff']:.3f}, 95%CI=[{row['ci_low']:.3f}, {row['ci_high']:.3f}], p={row['p_value']:.4f} {sig}\")\n",
    "    \n",
    "    print(\"\\nGeometry Preservation (bilateral disadvantage = more reorganization):\")\n",
    "    boot_results, gaps = bootstrap_group_comparison(geom_df, 'geometry_preservation')\n",
    "    print(f\"  Subject gaps - OTC: {gaps['OTC'].mean():.3f}, nonOTC: {gaps['nonOTC'].mean():.3f}, control: {gaps['control'].mean():.3f}\")\n",
    "    for _, row in boot_results.iterrows():\n",
    "        sig = '***' if row['p_value'] < 0.001 else '**' if row['p_value'] < 0.01 else '*' if row['p_value'] < 0.05 else ''\n",
    "        print(f\"  {row['comparison']}: diff={row['observed_diff']:.3f}, 95%CI=[{row['ci_low']:.3f}, {row['ci_high']:.3f}], p={row['p_value']:.4f} {sig}\")\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 14: Decision and Final Export\n",
    "\n",
    "# %%\n",
    "print(\"=\"*70)\n",
    "print(\"DECISION: WHICH CONTRAST SCHEME TO USE?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\"\"\n",
    "Based on the comparisons above, evaluate:\n",
    "\n",
    "1. ROI YIELD: Does the scheme find meaningful ROIs for all categories?\n",
    "   - Check Word ROI voxel counts (liu_mixed may have very few)\n",
    "   \n",
    "2. THEORETICAL CONSISTENCY: Same baseline across categories for RSA?\n",
    "   - all_scramble and all_vs_others are consistent\n",
    "   - liu_mixed and current_differential mix baselines\n",
    "   \n",
    "3. STATISTICAL POWER: Does the scheme detect the hypothesized effect?\n",
    "   - OTC bilateral > unilateral change\n",
    "\n",
    "4. HYBRID APPROACH: Does separating localization from patterns help?\n",
    "   - May get better ROI localization (liu_mixed) \n",
    "   - While maintaining RSA consistency (all_scramble patterns)\n",
    "\n",
    "RECOMMENDATION: Review the summary tables above and decide.\n",
    "\"\"\")\n",
    "\n",
    "# Show final recommendation based on results\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"QUANTITATIVE COMPARISON:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "comparison_data = []\n",
    "for approach in ['liu_mixed', 'all_scramble', 'current_differential', 'hybrid']:\n",
    "    if approach not in approach_tests:\n",
    "        continue\n",
    "    \n",
    "    row = {'approach': approach}\n",
    "    \n",
    "    # Get OTC p-values\n",
    "    if 'selectivity' in approach_tests[approach]:\n",
    "        sel_df = approach_tests[approach]['selectivity']\n",
    "        otc_sel = sel_df[sel_df['group'] == 'OTC']\n",
    "        if len(otc_sel) > 0:\n",
    "            row['selectivity_p'] = otc_sel['p'].values[0]\n",
    "            row['selectivity_diff'] = otc_sel['difference'].values[0]\n",
    "    \n",
    "    if 'geometry' in approach_tests[approach]:\n",
    "        geo_df = approach_tests[approach]['geometry']\n",
    "        otc_geo = geo_df[geo_df['group'] == 'OTC']\n",
    "        if len(otc_geo) > 0:\n",
    "            row['geometry_p'] = otc_geo['p'].values[0]\n",
    "            row['geometry_diff'] = otc_geo['difference'].values[0]\n",
    "    \n",
    "    comparison_data.append(row)\n",
    "\n",
    "comp_df = pd.DataFrame(comparison_data)\n",
    "print(comp_df.to_string(index=False))\n",
    "\n",
    "# %% [markdown]\n",
    "# ## Cell 15: Export Final Results with Chosen Approach\n",
    "\n",
    "# %%\n",
    "# Set the chosen approach here after reviewing results\n",
    "CHOSEN_APPROACH = 'hybrid'  # Change this based on Cell 14 analysis\n",
    "\n",
    "print(f\"=\"*70)\n",
    "print(f\"EXPORTING FINAL RESULTS: {CHOSEN_APPROACH}\")\n",
    "print(f\"=\"*70)\n",
    "\n",
    "if CHOSEN_APPROACH == 'hybrid':\n",
    "    final_results = hybrid_results\n",
    "else:\n",
    "    final_results = standard_results[CHOSEN_APPROACH]\n",
    "\n",
    "# Build comprehensive results DataFrame\n",
    "export_data = []\n",
    "\n",
    "for _, row in final_results['selectivity'].iterrows():\n",
    "    sid = row['subject']\n",
    "    info = SUBJECTS[sid]\n",
    "    \n",
    "    # Get matching geometry and drift\n",
    "    geom_match = final_results['geometry'][\n",
    "        (final_results['geometry']['subject'] == sid) & \n",
    "        (final_results['geometry']['hemi'] == row['hemi']) &\n",
    "        (final_results['geometry']['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    drift_match = final_results['drift'][\n",
    "        (final_results['drift']['subject'] == sid) & \n",
    "        (final_results['drift']['hemi'] == row['hemi']) &\n",
    "        (final_results['drift']['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    export_row = {\n",
    "        'Subject': row['code'],\n",
    "        'Group': info['group'],\n",
    "        'Surgery_Side': info.get('surgery_side', 'na'),\n",
    "        'Intact_Hemisphere': 'left' if info['hemi'] == 'l' else 'right',\n",
    "        'Sex': info.get('sex', 'na'),\n",
    "        'nonpt_hemi': row['hemi'].upper() if info['group'] == 'control' else 'na',\n",
    "        'Category': row['category'].title(),\n",
    "        'Category_Type': 'Bilateral' if row['category'] in BILATERAL else 'Unilateral',\n",
    "        'age_1': info.get('age_1', np.nan),\n",
    "        'age_2': info.get('age_2', np.nan),\n",
    "        'yr_gap': info.get('age_2', 0) - info.get('age_1', 0) if info.get('age_1') and info.get('age_2') else np.nan,\n",
    "        'Selectivity_Change': row['selectivity_change'],\n",
    "        'Spatial_Relocation_mm': drift_match['spatial_drift_mm'].values[0] if len(drift_match) > 0 else np.nan,\n",
    "        'Geometry_Preservation_6mm': geom_match['geometry_preservation'].values[0] if len(geom_match) > 0 else np.nan,\n",
    "    }\n",
    "    \n",
    "    export_data.append(export_row)\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# Add MDS shift (averaged across ROI categories for each measured category)\n",
    "mds_df = final_results['mds']\n",
    "mds_summary = mds_df.groupby(['subject', 'measured_category'])['mds_shift'].mean().reset_index()\n",
    "\n",
    "for i, row in export_df.iterrows():\n",
    "    sid = [s for s in SUBJECTS if SUBJECTS[s]['code'] == row['Subject']][0]\n",
    "    cat = row['Category'].lower()\n",
    "    \n",
    "    mds_match = mds_summary[\n",
    "        (mds_summary['subject'] == sid) & \n",
    "        (mds_summary['measured_category'] == cat)\n",
    "    ]\n",
    "    \n",
    "    if len(mds_match) > 0:\n",
    "        export_df.loc[i, 'MDS_Shift'] = mds_match['mds_shift'].values[0]\n",
    "\n",
    "# Save\n",
    "output_file = OUTPUT_DIR / 'results_final_corrected.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "print(f\"\\n✓ Saved to: {output_file}\")\n",
    "print(f\"  Shape: {export_df.shape}\")\n",
    "\n",
    "# Final summary\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"FINAL SUMMARY BY GROUP AND CATEGORY:\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "print(f\"\\n{'Measure':<25} {'Group':<10} {'Face':<8} {'Word':<8} {'Object':<8} {'House':<8}\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "for measure in ['Selectivity_Change', 'Geometry_Preservation_6mm', 'Spatial_Relocation_mm', 'MDS_Shift']:\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = export_df[export_df['Group'] == group]\n",
    "        vals = []\n",
    "        for cat in ['Face', 'Word', 'Object', 'House']:\n",
    "            cd = gd[gd['Category'] == cat][measure]\n",
    "            vals.append(f\"{cd.mean():.2f}\" if len(cd) > 0 and cd.notna().any() else \"--\")\n",
    "        print(f\"{measure:<25} {group:<10} {vals[0]:<8} {vals[1]:<8} {vals[2]:<8} {vals[3]:<8}\")\n",
    "    print()\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

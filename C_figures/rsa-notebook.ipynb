{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal RSA Analysis: VOTC Resection Study\n",
    "\n",
    "## Hypothesis\n",
    "Bilateral visual categories (Object, House) show greater representational reorganization than unilateral categories (Face, Word) in OTC patients, because bilateral representations are **collaborative** (not redundant) across hemispheres—losing one hemisphere forces compensation.\n",
    "\n",
    "## Contrast Scheme Justification\n",
    "\n",
    "### Liu Distinctiveness (Selectivity Change)\n",
    "- Measures how **selective** a region is for its preferred category\n",
    "- Uses contrasts that **define** category selectivity (following Liu et al.):\n",
    "  - FFA: Face > Object (cope 1)\n",
    "  - VWFA: Word > Scramble (cope 12) — cannot use Word > Face because face signal dominates VWFA's neighborhood\n",
    "  - PPA: House > Object (cope 2)\n",
    "  - LOC: Object > Scramble (cope 3)\n",
    "- Question: \"How correlated is preferred with non-preferred?\" — about ROI's functional **identity**\n",
    "\n",
    "### RSA Measures (Geometry Preservation, MDS Shift)\n",
    "- Measures representational **structure** — how categories relate to each other\n",
    "- Requires comparing patterns across all four categories simultaneously\n",
    "- **Must use same baseline** for fair RDM comparison\n",
    "- All Category > Scramble (copes 10, 12, 3, 11):\n",
    "  - Consistent reference point\n",
    "  - Each pattern reflects category response above low-level visual baseline\n",
    "  - RDM comparisons are apples-to-apples\n",
    "\n",
    "**Key distinction:** Selectivity is about a region's *identity*; RSA is about representational *structure*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Excluding: ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
      "  Liu Distinctiveness: COPE_MAP_LIU\n",
      "  RSA Measures: COPE_MAP_SCRAMBLE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, ttest_ind, ttest_rel\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === PATHS ===\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "OUTPUT_DIR = Path('/user_data/csimmon2/git_repos/long_pt/B_analyses')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === SUBJECT INFO ===\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "EXCLUDE_SUBJECTS = ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
    "\n",
    "# === CATEGORIES ===\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "BILATERAL = ['object', 'house']\n",
    "UNILATERAL = ['face', 'word']\n",
    "\n",
    "# === CONTRAST SCHEMES ===\n",
    "\n",
    "# For Liu Distinctiveness (Selectivity Change)\n",
    "# Uses ROI-defining contrasts per Liu et al.\n",
    "COPE_MAP_LIU = {\n",
    "    'face': (1, 1),    # Face > Object\n",
    "    'word': (12, 1),   # Word > Scramble\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (2, 1)    # House > Object\n",
    "}\n",
    "\n",
    "# For RSA measures (Geometry, MDS, Drift)\n",
    "# Consistent baseline across all categories\n",
    "COPE_MAP_SCRAMBLE = {\n",
    "    'face': (10, 1),   # Face > Scramble\n",
    "    'word': (12, 1),   # Word > Scramble\n",
    "    'object': (3, 1),  # Object > Scramble\n",
    "    'house': (11, 1)   # House > Scramble\n",
    "}\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Excluding: {EXCLUDE_SUBJECTS}\")\n",
    "print(f\"  Liu Distinctiveness: COPE_MAP_LIU\")\n",
    "print(f\"  RSA Measures: COPE_MAP_SCRAMBLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Load Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 20 subjects (after exclusions)\n",
      "  OTC: 6\n",
      "  nonOTC: 7\n",
      "  control: 7\n"
     ]
    }
   ],
   "source": [
    "def load_subjects():\n",
    "    \"\"\"Load all subjects from CSV, excluding problematic ones\"\"\"\n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        \n",
    "        if subject_id in EXCLUDE_SUBJECTS:\n",
    "            continue\n",
    "            \n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        sessions = sorted(\n",
    "            [d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()], \n",
    "            key=int\n",
    "        )\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        \n",
    "        if len(sessions) < 2:\n",
    "            continue\n",
    "        \n",
    "        hemi = 'l' if row.get('intact_hemi', 'left') == 'left' else 'r'\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemi,\n",
    "            'group': row['group'],\n",
    "            'patient': row['patient'] == 1,\n",
    "            'surgery_side': row.get('SurgerySide', 'na'),\n",
    "            'sex': row.get('sex', 'na'),\n",
    "            'age_1': row.get('age_1', np.nan),\n",
    "            'age_2': row.get('age_2', np.nan)\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "SUBJECTS = load_subjects()\n",
    "\n",
    "print(f\"✓ Loaded {len(SUBJECTS)} subjects (after exclusions)\")\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    n = sum(1 for s in SUBJECTS.values() if s['group'] == group)\n",
    "    print(f\"  {group}: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_sphere(center_coord, affine, brain_shape, radius=6):\n",
    "    \"\"\"Create spherical mask around coordinate\"\"\"\n",
    "    grid = np.array(np.meshgrid(\n",
    "        np.arange(brain_shape[0]),\n",
    "        np.arange(brain_shape[1]),\n",
    "        np.arange(brain_shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "    \n",
    "    world = nib.affines.apply_affine(affine, grid)\n",
    "    distances = np.linalg.norm(world - center_coord, axis=1)\n",
    "    \n",
    "    mask = np.zeros(brain_shape, dtype=bool)\n",
    "    within = grid[distances <= radius]\n",
    "    for c in within:\n",
    "        mask[c[0], c[1], c[2]] = True\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def filter_to_intact_hemisphere(df_results):\n",
    "    \"\"\"Filter results to intact hemisphere for patients, keep both for controls\"\"\"\n",
    "    filtered = []\n",
    "    for _, row in df_results.iterrows():\n",
    "        sid = row['subject']\n",
    "        info = SUBJECTS[sid]\n",
    "        if info['group'] == 'control':\n",
    "            filtered.append(row)\n",
    "        elif row['hemi'] == info['hemi']:\n",
    "            filtered.append(row)\n",
    "    return pd.DataFrame(filtered)\n",
    "\n",
    "\n",
    "print(\"✓ Helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: ROI Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ ROI extraction function defined\n"
     ]
    }
   ],
   "source": [
    "def extract_rois(cope_map, threshold_z=2.3, min_voxels=20):\n",
    "    \"\"\"Extract ROIs for all subjects using specified contrast scheme\"\"\"\n",
    "    \n",
    "    all_rois = {}\n",
    "    \n",
    "    for sid, info in SUBJECTS.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        \n",
    "        if not roi_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        all_rois[sid] = {}\n",
    "        \n",
    "        # For controls, extract both hemispheres\n",
    "        hemis = ['l', 'r'] if info['group'] == 'control' else [info['hemi']]\n",
    "        \n",
    "        for hemi in hemis:\n",
    "            for category in CATEGORIES:\n",
    "                cope_num, mult = cope_map[category]\n",
    "                \n",
    "                # Load search mask\n",
    "                mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "                if not mask_file.exists():\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mask_img = nib.load(mask_file)\n",
    "                    search_mask = mask_img.get_fdata() > 0\n",
    "                    affine = mask_img.affine\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                roi_key = f'{hemi}_{category}'\n",
    "                all_rois[sid][roi_key] = {}\n",
    "                \n",
    "                for session in info['sessions']:\n",
    "                    feat_dir = BASE_DIR / sid / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                    z_name = 'zstat1.nii.gz' if session == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        z_data = nib.load(cope_file).get_fdata() * mult\n",
    "                        suprathresh = (z_data > threshold_z) & search_mask\n",
    "                        \n",
    "                        if suprathresh.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        labeled, n_clusters = label(suprathresh)\n",
    "                        if n_clusters == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        # Largest cluster\n",
    "                        sizes = [(labeled == i).sum() for i in range(1, n_clusters + 1)]\n",
    "                        best_idx = np.argmax(sizes) + 1\n",
    "                        roi_mask = (labeled == best_idx)\n",
    "                        \n",
    "                        if roi_mask.sum() < min_voxels:\n",
    "                            continue\n",
    "                        \n",
    "                        peak_idx = np.unravel_index(np.argmax(z_data * roi_mask), z_data.shape)\n",
    "                        \n",
    "                        all_rois[sid][roi_key][session] = {\n",
    "                            'n_voxels': int(roi_mask.sum()),\n",
    "                            'peak_z': z_data[peak_idx],\n",
    "                            'centroid': nib.affines.apply_affine(affine, center_of_mass(roi_mask)),\n",
    "                            'peak_coord': nib.affines.apply_affine(affine, peak_idx),\n",
    "                            'roi_mask': roi_mask,\n",
    "                            'affine': affine,\n",
    "                            'shape': z_data.shape\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "    \n",
    "    return all_rois\n",
    "\n",
    "print(\"✓ ROI extraction function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Liu Distinctiveness (Selectivity Change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Selectivity change function defined\n"
     ]
    }
   ],
   "source": [
    "def compute_selectivity_change(rois, pattern_cope_map):\n",
    "    \"\"\"\n",
    "    Selectivity Change (Liu Distinctiveness):\n",
    "    - Correlation of preferred category with non-preferred categories\n",
    "    - Change from T1 to T2 (absolute difference)\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            distinctiveness = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius=6)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = {}\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns[cat] = pattern\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    pref_pattern = patterns[category]\n",
    "                    nonpref_corrs = []\n",
    "                    for other_cat in CATEGORIES:\n",
    "                        if other_cat != category:\n",
    "                            r, _ = pearsonr(pref_pattern, patterns[other_cat])\n",
    "                            nonpref_corrs.append(np.arctanh(np.clip(r, -0.999, 0.999)))\n",
    "                    \n",
    "                    distinctiveness[ses] = np.mean(nonpref_corrs)\n",
    "            \n",
    "            if len(distinctiveness) == 2:\n",
    "                change = abs(distinctiveness[sessions[-1]] - distinctiveness[sessions[0]])\n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'selectivity_change': change\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ Selectivity change function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: RSA Measures (Geometry Preservation, MDS Shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RSA metric functions defined\n"
     ]
    }
   ],
   "source": [
    "def compute_geometry_preservation(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    Geometry Preservation: RDM stability across sessions\n",
    "    - Extract patterns from sphere at each session's centroid\n",
    "    - Correlate T1 and T2 RDMs\n",
    "    - Higher = more stable; lower in bilateral = MORE reorganization\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    corr_matrix = np.corrcoef(patterns)\n",
    "                    rdm = 1 - corr_matrix\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                triu = np.triu_indices(4, k=1)\n",
    "                r, _ = pearsonr(rdms[sessions[0]][triu], rdms[sessions[-1]][triu])\n",
    "                \n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'code': info['code'],\n",
    "                    'group': info['group'],\n",
    "                    'hemi': hemi,\n",
    "                    'category': category,\n",
    "                    'geometry_preservation': r\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_mds_shift(rois, pattern_cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    MDS Shift: Procrustes-aligned embedding distance\n",
    "    - MDS embed RDMs to 2D\n",
    "    - Align with Procrustes\n",
    "    - Measure movement of each category\n",
    "    \"\"\"\n",
    "    def mds_2d(rdm):\n",
    "        n = rdm.shape[0]\n",
    "        H = np.eye(n) - np.ones((n, n)) / n\n",
    "        B = -0.5 * H @ (rdm ** 2) @ H\n",
    "        eigvals, eigvecs = np.linalg.eigh(B)\n",
    "        idx = np.argsort(eigvals)[::-1]\n",
    "        coords = eigvecs[:, idx[:2]] * np.sqrt(np.maximum(eigvals[idx[:2]], 0))\n",
    "        return coords\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            roi_category = roi_key.split('_')[1]\n",
    "            \n",
    "            ref_data = sessions_data[sessions[0]]\n",
    "            affine = ref_data['affine']\n",
    "            shape = ref_data['shape']\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses in [sessions[0], sessions[-1]]:\n",
    "                if ses not in sessions_data:\n",
    "                    continue\n",
    "                \n",
    "                centroid = sessions_data[ses]['centroid']\n",
    "                sphere = create_sphere(centroid, affine, shape, radius)\n",
    "                \n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = pattern_cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    corr_matrix = np.corrcoef(patterns)\n",
    "                    rdm = 1 - corr_matrix\n",
    "                    rdms[ses] = rdm\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                try:\n",
    "                    coords_t1 = mds_2d(rdms[sessions[0]])\n",
    "                    coords_t2 = mds_2d(rdms[sessions[-1]])\n",
    "                    \n",
    "                    R, _ = orthogonal_procrustes(coords_t1, coords_t2)\n",
    "                    coords_t1_aligned = coords_t1 @ R\n",
    "                    \n",
    "                    for i, cat in enumerate(CATEGORIES):\n",
    "                        dist = np.linalg.norm(coords_t1_aligned[i] - coords_t2[i])\n",
    "                        results.append({\n",
    "                            'subject': sid,\n",
    "                            'code': info['code'],\n",
    "                            'group': info['group'],\n",
    "                            'hemi': hemi,\n",
    "                            'roi_category': roi_category,\n",
    "                            'measured_category': cat,\n",
    "                            'mds_shift': dist\n",
    "                        })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def compute_spatial_drift(rois):\n",
    "    \"\"\"\n",
    "    Spatial Drift: Euclidean distance between T1 and T2 peak centroids\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois.items():\n",
    "        info = SUBJECTS[sid]\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            c1 = sessions_data[sessions[0]]['centroid']\n",
    "            c2 = sessions_data[sessions[-1]]['centroid']\n",
    "            drift = np.linalg.norm(np.array(c2) - np.array(c1))\n",
    "            \n",
    "            results.append({\n",
    "                'subject': sid,\n",
    "                'code': info['code'],\n",
    "                'group': info['group'],\n",
    "                'hemi': hemi,\n",
    "                'category': category,\n",
    "                'spatial_drift_mm': drift,\n",
    "                't1_peak_z': sessions_data[sessions[0]]['peak_z']\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"✓ RSA metric functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: Extract ROIs and Compute All Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXTRACTING ROIs\n",
      "======================================================================\n",
      "\n",
      "Extracting Liu ROIs (for Selectivity Change)...\n",
      "  ✓ 20 subjects, 107 ROIs with 2+ sessions\n",
      "\n",
      "Extracting Scramble ROIs (for RSA measures)...\n",
      "  ✓ 20 subjects, 107 ROIs with 2+ sessions\n",
      "\n",
      "======================================================================\n",
      "COMPUTING MEASURES\n",
      "======================================================================\n",
      "\n",
      "Computing Selectivity Change (Liu ROIs + Liu patterns)...\n",
      "  ✓ 107 measurements\n",
      "\n",
      "Computing Geometry Preservation (Scramble ROIs + Scramble patterns)...\n",
      "  ✓ 107 measurements\n",
      "\n",
      "Computing MDS Shift (Scramble ROIs + Scramble patterns)...\n",
      "  ✓ 428 measurements\n",
      "\n",
      "Computing Spatial Drift (Scramble ROIs)...\n",
      "  ✓ 107 measurements\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXTRACTING ROIs\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Liu ROIs for Selectivity Change\n",
    "print(\"\\nExtracting Liu ROIs (for Selectivity Change)...\")\n",
    "rois_liu = extract_rois(COPE_MAP_LIU)\n",
    "n_liu = sum(len([k for k, v in roi_data.items() if len(v) >= 2]) for roi_data in rois_liu.values())\n",
    "print(f\"  ✓ {len(rois_liu)} subjects, {n_liu} ROIs with 2+ sessions\")\n",
    "\n",
    "# Scramble ROIs for RSA measures\n",
    "print(\"\\nExtracting Scramble ROIs (for RSA measures)...\")\n",
    "rois_scramble = extract_rois(COPE_MAP_SCRAMBLE)\n",
    "n_scr = sum(len([k for k, v in roi_data.items() if len(v) >= 2]) for roi_data in rois_scramble.values())\n",
    "print(f\"  ✓ {len(rois_scramble)} subjects, {n_scr} ROIs with 2+ sessions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPUTING MEASURES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Selectivity Change (using Liu ROIs and Liu patterns)\n",
    "print(\"\\nComputing Selectivity Change (Liu ROIs + Liu patterns)...\")\n",
    "selectivity_df = compute_selectivity_change(rois_liu, COPE_MAP_LIU)\n",
    "print(f\"  ✓ {len(selectivity_df)} measurements\")\n",
    "\n",
    "# Geometry Preservation (using Scramble ROIs and Scramble patterns)\n",
    "print(\"\\nComputing Geometry Preservation (Scramble ROIs + Scramble patterns)...\")\n",
    "geometry_df = compute_geometry_preservation(rois_scramble, COPE_MAP_SCRAMBLE)\n",
    "print(f\"  ✓ {len(geometry_df)} measurements\")\n",
    "\n",
    "# MDS Shift (using Scramble ROIs and Scramble patterns)\n",
    "print(\"\\nComputing MDS Shift (Scramble ROIs + Scramble patterns)...\")\n",
    "mds_df = compute_mds_shift(rois_scramble, COPE_MAP_SCRAMBLE)\n",
    "print(f\"  ✓ {len(mds_df)} measurements\")\n",
    "\n",
    "# Spatial Drift (using Scramble ROIs)\n",
    "print(\"\\nComputing Spatial Drift (Scramble ROIs)...\")\n",
    "drift_df = compute_spatial_drift(rois_scramble)\n",
    "print(f\"  ✓ {len(drift_df)} measurements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: Statistical Tests - Bilateral vs Unilateral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "BILATERAL vs UNILATERAL STATISTICAL TESTS\n",
      "######################################################################\n",
      "\n",
      "======================================================================\n",
      "SELECTIVITY CHANGE\n",
      "(Higher = more change; expect bilateral > unilateral in OTC)\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral          Unilateral         Diff       t        p         \n",
      "---------------------------------------------------------------------------\n",
      "OTC          0.396±0.273      0.143±0.121      +0.253     2.82    0.0102 *\n",
      "nonOTC       0.148±0.104      0.125±0.112      +0.023     0.56    0.5781 \n",
      "control      0.233±0.179      0.150±0.121      +0.083     2.02    0.0482 *\n",
      "\n",
      "======================================================================\n",
      "GEOMETRY PRESERVATION\n",
      "(Lower = more change; expect bilateral < unilateral in OTC)\n",
      "======================================================================\n",
      "\n",
      "Group        Bilateral          Unilateral         Diff       t        p         \n",
      "---------------------------------------------------------------------------\n",
      "OTC          -0.025±0.465      0.240±0.466      -0.265     -1.36    0.1872 \n",
      "nonOTC       0.646±0.282      0.571±0.411      +0.075     0.56    0.5799 \n",
      "control      0.519±0.455      0.468±0.426      +0.051     0.43    0.6661 \n"
     ]
    }
   ],
   "source": [
    "def test_bilateral_effect(df, metric_col, metric_name, higher_means_more_change=True):\n",
    "    \"\"\"Test if bilateral differs from unilateral within each group\"\"\"\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{metric_name}\")\n",
    "    if higher_means_more_change:\n",
    "        print(\"(Higher = more change; expect bilateral > unilateral in OTC)\")\n",
    "    else:\n",
    "        print(\"(Lower = more change; expect bilateral < unilateral in OTC)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    filtered_df = filter_to_intact_hemisphere(df)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n{'Group':<12} {'Bilateral':<18} {'Unilateral':<18} {'Diff':<10} {'t':<8} {'p':<10}\")\n",
    "    print(\"-\"*75)\n",
    "    \n",
    "    results = []\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        bil = gd[gd['cat_type'] == 'Bilateral'][metric_col]\n",
    "        uni = gd[gd['cat_type'] == 'Unilateral'][metric_col]\n",
    "        \n",
    "        if len(bil) > 1 and len(uni) > 1:\n",
    "            t, p = ttest_ind(bil, uni)\n",
    "            diff = bil.mean() - uni.mean()\n",
    "            sig = '***' if p < 0.001 else '**' if p < 0.01 else '*' if p < 0.05 else ''\n",
    "            \n",
    "            print(f\"{group:<12} {bil.mean():.3f}±{bil.std():.3f}      {uni.mean():.3f}±{uni.std():.3f}      {diff:+.3f}     {t:.2f}    {p:.4f} {sig}\")\n",
    "            \n",
    "            results.append({\n",
    "                'group': group,\n",
    "                'bilateral_mean': bil.mean(),\n",
    "                'unilateral_mean': uni.mean(),\n",
    "                'difference': diff,\n",
    "                't': t,\n",
    "                'p': p\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run tests\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"BILATERAL vs UNILATERAL STATISTICAL TESTS\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "selectivity_stats = test_bilateral_effect(\n",
    "    selectivity_df, 'selectivity_change', 'SELECTIVITY CHANGE', \n",
    "    higher_means_more_change=True\n",
    ")\n",
    "\n",
    "geometry_stats = test_bilateral_effect(\n",
    "    geometry_df, 'geometry_preservation', 'GEOMETRY PRESERVATION',\n",
    "    higher_means_more_change=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: Bootstrap Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "######################################################################\n",
      "BOOTSTRAP ANALYSIS\n",
      "######################################################################\n",
      "\n",
      "--- SELECTIVITY CHANGE ---\n",
      "(Positive diff = OTC shows MORE bilateral advantage)\n",
      "\n",
      "  Subject-level gaps:\n",
      "    OTC: n=6, mean=0.257\n",
      "    nonOTC: n=7, mean=0.023\n",
      "    control: n=7, mean=0.083\n",
      "\n",
      "  OTC vs nonOTC: diff=0.234, 95%CI=[0.029, 0.454], p=0.0132 *\n",
      "\n",
      "  OTC vs control: diff=0.174, 95%CI=[-0.034, 0.398], p=0.1142 \n",
      "\n",
      "--- GEOMETRY PRESERVATION ---\n",
      "(Negative diff = OTC shows MORE bilateral disadvantage = more reorganization)\n",
      "\n",
      "  Subject-level gaps:\n",
      "    OTC: n=6, mean=-0.291\n",
      "    nonOTC: n=7, mean=0.075\n",
      "    control: n=7, mean=0.051\n",
      "\n",
      "  OTC vs nonOTC: diff=-0.366, 95%CI=[-0.816, 0.079], p=0.1104 \n",
      "\n",
      "  OTC vs control: diff=-0.342, 95%CI=[-0.650, -0.016], p=0.0414 *\n"
     ]
    }
   ],
   "source": [
    "def bootstrap_group_comparison(df, metric_col, n_boot=10000, seed=42):\n",
    "    \"\"\"Bootstrap test for OTC bilateral advantage vs other groups\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Filter to intact hemisphere\n",
    "    filtered_df = filter_to_intact_hemisphere(df)\n",
    "    filtered_df['cat_type'] = filtered_df['category'].apply(\n",
    "        lambda x: 'Bilateral' if x in BILATERAL else 'Unilateral'\n",
    "    )\n",
    "    \n",
    "    # Calculate subject-level bilateral advantage (gap)\n",
    "    subject_gaps = {}\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered_df[filtered_df['group'] == group]\n",
    "        gaps = []\n",
    "        for sid in gd['subject'].unique():\n",
    "            sd = gd[gd['subject'] == sid]\n",
    "            bil = sd[sd['cat_type'] == 'Bilateral'][metric_col].mean()\n",
    "            uni = sd[sd['cat_type'] == 'Unilateral'][metric_col].mean()\n",
    "            if pd.notna(bil) and pd.notna(uni):\n",
    "                gaps.append(bil - uni)\n",
    "        subject_gaps[group] = np.array(gaps)\n",
    "    \n",
    "    print(f\"\\n  Subject-level gaps:\")\n",
    "    for g, gaps in subject_gaps.items():\n",
    "        print(f\"    {g}: n={len(gaps)}, mean={gaps.mean():.3f}\")\n",
    "    \n",
    "    results = []\n",
    "    for comp_group in ['nonOTC', 'control']:\n",
    "        g1 = subject_gaps['OTC']\n",
    "        g2 = subject_gaps[comp_group]\n",
    "        \n",
    "        if len(g1) < 2 or len(g2) < 2:\n",
    "            continue\n",
    "        \n",
    "        observed_diff = np.mean(g1) - np.mean(g2)\n",
    "        \n",
    "        boot_diffs = []\n",
    "        for _ in range(n_boot):\n",
    "            s1 = np.random.choice(g1, size=len(g1), replace=True)\n",
    "            s2 = np.random.choice(g2, size=len(g2), replace=True)\n",
    "            boot_diffs.append(np.mean(s1) - np.mean(s2))\n",
    "        \n",
    "        boot_diffs = np.array(boot_diffs)\n",
    "        ci_low = np.percentile(boot_diffs, 2.5)\n",
    "        ci_high = np.percentile(boot_diffs, 97.5)\n",
    "        \n",
    "        if observed_diff > 0:\n",
    "            p_val = 2 * np.mean(boot_diffs <= 0)\n",
    "        else:\n",
    "            p_val = 2 * np.mean(boot_diffs >= 0)\n",
    "        \n",
    "        sig = '***' if p_val < 0.001 else '**' if p_val < 0.01 else '*' if p_val < 0.05 else ''\n",
    "        print(f\"\\n  OTC vs {comp_group}: diff={observed_diff:.3f}, 95%CI=[{ci_low:.3f}, {ci_high:.3f}], p={p_val:.4f} {sig}\")\n",
    "        \n",
    "        results.append({\n",
    "            'comparison': f'OTC vs {comp_group}',\n",
    "            'observed_diff': observed_diff,\n",
    "            'ci_low': ci_low,\n",
    "            'ci_high': ci_high,\n",
    "            'p_value': p_val\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"#\"*70)\n",
    "print(\"BOOTSTRAP ANALYSIS\")\n",
    "print(\"#\"*70)\n",
    "\n",
    "print(\"\\n--- SELECTIVITY CHANGE ---\")\n",
    "print(\"(Positive diff = OTC shows MORE bilateral advantage)\")\n",
    "boot_selectivity = bootstrap_group_comparison(selectivity_df, 'selectivity_change')\n",
    "\n",
    "print(\"\\n--- GEOMETRY PRESERVATION ---\")\n",
    "print(\"(Negative diff = OTC shows MORE bilateral disadvantage = more reorganization)\")\n",
    "boot_geometry = bootstrap_group_comparison(geometry_df, 'geometry_preservation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Category-Level Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CATEGORY-LEVEL RESULTS\n",
      "======================================================================\n",
      "\n",
      "--- SELECTIVITY CHANGE (higher = more change) ---\n",
      "Group        Face       Word       Object     House     \n",
      "-------------------------------------------------------\n",
      "OTC          0.15       0.14       0.48       0.31      \n",
      "nonOTC       0.11       0.14       0.17       0.13      \n",
      "control      0.18       0.12       0.20       0.27      \n",
      "\n",
      "--- GEOMETRY PRESERVATION (lower = more change) ---\n",
      "Group        Face       Word       Object     House     \n",
      "-------------------------------------------------------\n",
      "OTC          0.32       0.15       0.06       -0.11     \n",
      "nonOTC       0.55       0.59       0.69       0.60      \n",
      "control      0.64       0.30       0.55       0.49      \n",
      "\n",
      "--- SPATIAL DRIFT (mm) ---\n",
      "Group        Face       Word       Object     House     \n",
      "-------------------------------------------------------\n",
      "OTC          6.99       19.01      5.93       13.19     \n",
      "nonOTC       3.40       8.96       2.52       5.69      \n",
      "control      5.74       10.00      3.66       6.49      \n",
      "\n",
      "--- MDS SHIFT (averaged across ROI locations) ---\n",
      "Group        Face       Word       Object     House     \n",
      "-------------------------------------------------------\n",
      "OTC          0.34       0.31       0.32       0.31      \n",
      "nonOTC       0.20       0.26       0.22       0.26      \n",
      "control      0.22       0.25       0.27       0.24      \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CATEGORY-LEVEL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "def print_category_table(df, metric_col, title):\n",
    "    filtered = filter_to_intact_hemisphere(df)\n",
    "    \n",
    "    print(f\"\\n--- {title} ---\")\n",
    "    print(f\"{'Group':<12} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "    print(\"-\"*55)\n",
    "    \n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        gd = filtered[filtered['group'] == group]\n",
    "        vals = []\n",
    "        for cat in ['face', 'word', 'object', 'house']:\n",
    "            cd = gd[gd['category'] == cat][metric_col]\n",
    "            if len(cd) > 0:\n",
    "                vals.append(f\"{cd.mean():.2f}\")\n",
    "            else:\n",
    "                vals.append(\"--\")\n",
    "        print(f\"{group:<12} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")\n",
    "\n",
    "print_category_table(selectivity_df, 'selectivity_change', 'SELECTIVITY CHANGE (higher = more change)')\n",
    "print_category_table(geometry_df, 'geometry_preservation', 'GEOMETRY PRESERVATION (lower = more change)')\n",
    "print_category_table(drift_df, 'spatial_drift_mm', 'SPATIAL DRIFT (mm)')\n",
    "\n",
    "# MDS shift needs special handling (has roi_category and measured_category)\n",
    "print(\"\\n--- MDS SHIFT (averaged across ROI locations) ---\")\n",
    "mds_filtered = filter_to_intact_hemisphere(\n",
    "    mds_df.rename(columns={'roi_category': 'category'})\n",
    ")\n",
    "mds_avg = mds_filtered.groupby(['group', 'measured_category'])['mds_shift'].mean().reset_index()\n",
    "\n",
    "print(f\"{'Group':<12} {'Face':<10} {'Word':<10} {'Object':<10} {'House':<10}\")\n",
    "print(\"-\"*55)\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    gd = mds_avg[mds_avg['group'] == group]\n",
    "    vals = []\n",
    "    for cat in ['face', 'word', 'object', 'house']:\n",
    "        cd = gd[gd['measured_category'] == cat]['mds_shift']\n",
    "        if len(cd) > 0:\n",
    "            vals.append(f\"{cd.values[0]:.2f}\")\n",
    "        else:\n",
    "            vals.append(\"--\")\n",
    "    print(f\"{group:<12} {vals[0]:<10} {vals[1]:<10} {vals[2]:<10} {vals[3]:<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Export Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "EXPORTING FINAL RESULTS\n",
      "======================================================================\n",
      "\n",
      "✓ Saved to: /user_data/csimmon2/git_repos/long_pt/B_analyses/results_final_corrected.csv\n",
      "  Shape: (107, 15)\n",
      "\n",
      "Columns: ['Subject', 'Group', 'Surgery_Side', 'Intact_Hemisphere', 'Sex', 'nonpt_hemi', 'Category', 'Category_Type', 'age_1', 'age_2', 'yr_gap', 'Selectivity_Change', 'Spatial_Relocation_mm', 'Geometry_Preservation_6mm', 'MDS_Shift']\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "FINAL SUMMARY\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Subjects per group:\n",
      "Group\n",
      "OTC        6\n",
      "control    7\n",
      "nonOTC     7\n",
      "Name: Subject, dtype: int64\n",
      "\n",
      "Measurements per category:\n",
      "Category\n",
      "Face      27\n",
      "House     27\n",
      "Object    27\n",
      "Word      26\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"EXPORTING FINAL RESULTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Build comprehensive export DataFrame\n",
    "# Use selectivity as base (Liu ROIs)\n",
    "export_data = []\n",
    "\n",
    "selectivity_filt = filter_to_intact_hemisphere(selectivity_df)\n",
    "geometry_filt = filter_to_intact_hemisphere(geometry_df)\n",
    "drift_filt = filter_to_intact_hemisphere(drift_df)\n",
    "\n",
    "for _, row in selectivity_filt.iterrows():\n",
    "    sid = row['subject']\n",
    "    info = SUBJECTS[sid]\n",
    "    \n",
    "    # Match geometry and drift (from scramble ROIs)\n",
    "    geom_match = geometry_filt[\n",
    "        (geometry_filt['subject'] == sid) & \n",
    "        (geometry_filt['hemi'] == row['hemi']) &\n",
    "        (geometry_filt['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    drift_match = drift_filt[\n",
    "        (drift_filt['subject'] == sid) & \n",
    "        (drift_filt['hemi'] == row['hemi']) &\n",
    "        (drift_filt['category'] == row['category'])\n",
    "    ]\n",
    "    \n",
    "    # MDS shift (average across ROI locations for this measured category)\n",
    "    mds_match = mds_df[\n",
    "        (mds_df['subject'] == sid) & \n",
    "        (mds_df['hemi'] == row['hemi']) &\n",
    "        (mds_df['measured_category'] == row['category'])\n",
    "    ]['mds_shift'].mean()\n",
    "    \n",
    "    export_row = {\n",
    "        'Subject': row['code'],\n",
    "        'Group': info['group'],\n",
    "        'Surgery_Side': info['surgery_side'],\n",
    "        'Intact_Hemisphere': 'left' if info['hemi'] == 'l' else 'right',\n",
    "        'Sex': info['sex'],\n",
    "        'nonpt_hemi': row['hemi'].upper() if info['group'] == 'control' else 'na',\n",
    "        'Category': row['category'].title(),\n",
    "        'Category_Type': 'Bilateral' if row['category'] in BILATERAL else 'Unilateral',\n",
    "        'age_1': info['age_1'],\n",
    "        'age_2': info['age_2'],\n",
    "        'yr_gap': info['age_2'] - info['age_1'] if pd.notna(info['age_1']) and pd.notna(info['age_2']) else np.nan,\n",
    "        'Selectivity_Change': row['selectivity_change'],\n",
    "        'Spatial_Relocation_mm': drift_match['spatial_drift_mm'].values[0] if len(drift_match) > 0 else np.nan,\n",
    "        'Geometry_Preservation_6mm': geom_match['geometry_preservation'].values[0] if len(geom_match) > 0 else np.nan,\n",
    "        'MDS_Shift': mds_match if pd.notna(mds_match) else np.nan\n",
    "    }\n",
    "    \n",
    "    export_data.append(export_row)\n",
    "\n",
    "export_df = pd.DataFrame(export_data)\n",
    "\n",
    "# Save\n",
    "output_file = OUTPUT_DIR / 'results_final_corrected.csv'\n",
    "export_df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved to: {output_file}\")\n",
    "print(f\"  Shape: {export_df.shape}\")\n",
    "print(f\"\\nColumns: {list(export_df.columns)}\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"-\"*70)\n",
    "print(f\"\\nSubjects per group:\")\n",
    "print(export_df.groupby('Group')['Subject'].nunique())\n",
    "print(f\"\\nMeasurements per category:\")\n",
    "print(export_df.groupby('Category').size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "FINAL SUMMARY STATISTICS\n",
      "======================================================================\n",
      "\n",
      "--- BY GROUP AND CATEGORY TYPE ---\n",
      "                      Selectivity_Change               \\\n",
      "                                    mean    std count   \n",
      "Group   Category_Type                                   \n",
      "OTC     Bilateral                  0.396  0.273    12   \n",
      "        Unilateral                 0.143  0.121    11   \n",
      "control Bilateral                  0.233  0.179    28   \n",
      "        Unilateral                 0.150  0.121    28   \n",
      "nonOTC  Bilateral                  0.148  0.104    14   \n",
      "        Unilateral                 0.125  0.112    14   \n",
      "\n",
      "                      Geometry_Preservation_6mm        Spatial_Relocation_mm  \\\n",
      "                                           mean    std                  mean   \n",
      "Group   Category_Type                                                          \n",
      "OTC     Bilateral                        -0.025  0.465                 9.556   \n",
      "        Unilateral                        0.240  0.466                12.457   \n",
      "control Bilateral                         0.519  0.455                 5.076   \n",
      "        Unilateral                        0.468  0.426                 7.869   \n",
      "nonOTC  Bilateral                         0.646  0.282                 4.107   \n",
      "        Unilateral                        0.571  0.411                 6.177   \n",
      "\n",
      "                              MDS_Shift         \n",
      "                          std      mean    std  \n",
      "Group   Category_Type                           \n",
      "OTC     Bilateral      13.295     0.310  0.081  \n",
      "        Unilateral      9.572     0.323  0.076  \n",
      "control Bilateral       4.552     0.253  0.094  \n",
      "        Unilateral      7.053     0.238  0.089  \n",
      "nonOTC  Bilateral       2.559     0.239  0.085  \n",
      "        Unilateral      9.433     0.231  0.095  \n",
      "\n",
      "======================================================================\n",
      "KEY FINDINGS\n",
      "======================================================================\n",
      "\n",
      "OTC Selectivity Change:\n",
      "  Bilateral: 0.396 ± 0.273\n",
      "  Unilateral: 0.143 ± 0.121\n",
      "  Bil - Uni = 0.253, p = 0.0102\n",
      "\n",
      "OTC Geometry Preservation:\n",
      "  Bilateral: -0.025 ± 0.465\n",
      "  Unilateral: 0.240 ± 0.466\n",
      "  Bil - Uni = -0.265, p = 0.1872\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"FINAL SUMMARY STATISTICS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n--- BY GROUP AND CATEGORY TYPE ---\")\n",
    "summary = export_df.groupby(['Group', 'Category_Type']).agg({\n",
    "    'Selectivity_Change': ['mean', 'std', 'count'],\n",
    "    'Geometry_Preservation_6mm': ['mean', 'std'],\n",
    "    'Spatial_Relocation_mm': ['mean', 'std'],\n",
    "    'MDS_Shift': ['mean', 'std']\n",
    "}).round(3)\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY FINDINGS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Extract OTC stats\n",
    "otc_bil = export_df[(export_df['Group'] == 'OTC') & (export_df['Category_Type'] == 'Bilateral')]\n",
    "otc_uni = export_df[(export_df['Group'] == 'OTC') & (export_df['Category_Type'] == 'Unilateral')]\n",
    "\n",
    "print(f\"\\nOTC Selectivity Change:\")\n",
    "print(f\"  Bilateral: {otc_bil['Selectivity_Change'].mean():.3f} ± {otc_bil['Selectivity_Change'].std():.3f}\")\n",
    "print(f\"  Unilateral: {otc_uni['Selectivity_Change'].mean():.3f} ± {otc_uni['Selectivity_Change'].std():.3f}\")\n",
    "t, p = ttest_ind(otc_bil['Selectivity_Change'], otc_uni['Selectivity_Change'])\n",
    "print(f\"  Bil - Uni = {otc_bil['Selectivity_Change'].mean() - otc_uni['Selectivity_Change'].mean():.3f}, p = {p:.4f}\")\n",
    "\n",
    "print(f\"\\nOTC Geometry Preservation:\")\n",
    "print(f\"  Bilateral: {otc_bil['Geometry_Preservation_6mm'].mean():.3f} ± {otc_bil['Geometry_Preservation_6mm'].std():.3f}\")\n",
    "print(f\"  Unilateral: {otc_uni['Geometry_Preservation_6mm'].mean():.3f} ± {otc_uni['Geometry_Preservation_6mm'].std():.3f}\")\n",
    "t, p = ttest_ind(otc_bil['Geometry_Preservation_6mm'].dropna(), otc_uni['Geometry_Preservation_6mm'].dropna())\n",
    "print(f\"  Bil - Uni = {otc_bil['Geometry_Preservation_6mm'].mean() - otc_uni['Geometry_Preservation_6mm'].mean():.3f}, p = {p:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

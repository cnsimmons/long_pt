{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DID NOT USE REGISTERED FILES for functional rois?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal RSA Analysis: Asymmetric vs. Symmetric Visual Categories\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook implements longitudinal Representational Similarity Analysis (RSA) following Liu et al. (2025) Figure 5, with key methodological improvements:\n",
    "\n",
    "### Key Analyses:\n",
    "1. **Asymmetric Categories (Face-Word):** Unilateral, ventral representations\n",
    "2. **Symmetric Categories (Object-House):** Bilateral representations\n",
    "\n",
    "### Patients:\n",
    "- **TC (sub-021):** Left VOTC resection → analyze RIGHT hemisphere (3 sessions)\n",
    "- **UD (sub-004):** Right VOTC resection → analyze LEFT hemisphere (5 sessions)\n",
    "\n",
    "### Method:\n",
    "- Extract all 4 categories (faces, words, objects, houses) from SAME voxels in each ROI\n",
    "- Compute 4×4 representational dissimilarity matrix (RDM) per session\n",
    "- Track dissimilarity trajectories across sessions\n",
    "- Bootstrap null distribution (1000 iterations, shuffled labels)\n",
    "- Test if regression slopes fall outside 95% CI\n",
    "\n",
    "### Research Question:\n",
    "Do asymmetric (lateralized) categories show different competitive dynamics than symmetric (bilateral) categories during cortical reorganization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Libraries loaded\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"✓ Libraries loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: /user_data/csimmon2/long_pt\n",
      "Output directory: /user_data/csimmon2/long_pt/analyses/longitudinal_rsa_final\n",
      "Patients: ['UD', 'TC']\n",
      "Bootstrap iterations: 1000\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "BETA_DIR = BASE_DIR / \"analyses\" / \"beta_extraction\"\n",
    "OUTPUT_DIR = BASE_DIR / \"analyses\" / \"longitudinal_rsa_final\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Patient configurations\n",
    "PATIENTS = {\n",
    "    'sub-004': {\n",
    "        'code': 'UD',\n",
    "        'sessions': ['01', '02', '03', '05', '06'],\n",
    "        'hemi': 'l',  # Analyze left (right was resected)\n",
    "        'resection': 'right',\n",
    "        'expected': 'Increasing face-word dissimilarity (competition)'\n",
    "    },\n",
    "    'sub-021': {\n",
    "        'code': 'TC',\n",
    "        'sessions': ['01', '02', '03'],\n",
    "        'hemi': 'r',  # Analyze right (left was resected)\n",
    "        'resection': 'left',\n",
    "        'expected': 'Increasing face-word dissimilarity (competition)'\n",
    "    }\n",
    "}\n",
    "\n",
    "# ROI configurations\n",
    "ROI_ANALYSES = {\n",
    "    'face_word': {\n",
    "        'name': 'face_word_dual_cluster',\n",
    "        'description': 'Asymmetric/Unilateral Categories',\n",
    "        'dissim_pair': ('faces', 'words'),\n",
    "        'color': '#FF1493'  # Deep pink\n",
    "    },\n",
    "    'object_house': {\n",
    "        'name': 'object_house_dual_cluster',\n",
    "        'description': 'Symmetric/Bilateral Categories',\n",
    "        'dissim_pair': ('houses', 'objects'),\n",
    "        'color': '#00CED1'  # Dark turquoise\n",
    "    }\n",
    "}\n",
    "\n",
    "N_BOOTSTRAP = 1000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"Patients: {[p['code'] for p in PATIENTS.values()]}\")\n",
    "print(f\"Bootstrap iterations: {N_BOOTSTRAP}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Beta Extraction Configuration\n",
    "# ============================================================================\n",
    "\n",
    "# Cope mappings - confirmed from design\n",
    "COPE_MAP = {\n",
    "    'faces': 6,    # Face > all others\n",
    "    'houses': 7,   # House > all others\n",
    "    'objects': 8,  # Object > all others\n",
    "    'words': 9     # Word > all others\n",
    "}\n",
    "\n",
    "# ROI configurations (matching your existing ROI_ANALYSES dict)\n",
    "ROI_ANALYSES = {\n",
    "    'face_word': {'name': 'face_word_dual_cluster'},\n",
    "    'object_house': {'name': 'object_house_dual_cluster'}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Beta Extraction Functions\n",
    "# ============================================================================\n",
    "\n",
    "def extract_betas_from_roi(cope_file, roi_file):\n",
    "    \"\"\"Extract mean beta values from ROI voxels\"\"\"\n",
    "    cope_img = nib.load(cope_file)\n",
    "    roi_img = nib.load(roi_file)\n",
    "    \n",
    "    cope_data = cope_img.get_fdata()\n",
    "    roi_data = roi_img.get_fdata()\n",
    "    \n",
    "    # Get voxels in ROI (non-zero)\n",
    "    roi_mask = roi_data > 0\n",
    "    \n",
    "    if not roi_mask.any():\n",
    "        return None\n",
    "    \n",
    "    # Extract betas from ROI voxels\n",
    "    betas = cope_data[roi_mask]\n",
    "    \n",
    "    return betas\n",
    "\n",
    "def extract_session_betas(subject_id, session, roi_configs, base_dir):\n",
    "    \"\"\"Extract betas using ses-01 registered copes\"\"\"\n",
    "    \n",
    "    hemi = PATIENTS[subject_id]['hemi']\n",
    "    roi_dir = base_dir / subject_id / 'ses-01' / 'ROIs'\n",
    "    session_dir = base_dir / subject_id / f'ses-{session}'\n",
    "    feat_dir = session_dir / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for roi_type, roi_config in roi_configs.items():\n",
    "        roi_name = f\"{hemi}_{roi_config['name']}.nii.gz\"\n",
    "        roi_file = roi_dir / roi_name\n",
    "        \n",
    "        if not roi_file.exists():\n",
    "            print(f\"  ✗ ROI not found: {roi_file}\")\n",
    "            continue\n",
    "        \n",
    "        roi_betas = {}\n",
    "        \n",
    "        for cat_name, cope_num in COPE_MAP.items():\n",
    "            cope_dir = feat_dir / f'cope{cope_num}.feat' / 'stats'\n",
    "            \n",
    "            # Use ses-01 registered files for non-ses-01 sessions\n",
    "            if session == '01':\n",
    "                cope_file = cope_dir / 'cope1.nii.gz'\n",
    "            else:\n",
    "                cope_file = cope_dir / 'cope1_ses01.nii.gz'\n",
    "            \n",
    "            if not cope_file.exists():\n",
    "                print(f\"  ✗ Cope not found: {cope_file}\")\n",
    "                continue\n",
    "            \n",
    "            betas = extract_betas_from_roi(cope_file, roi_file)\n",
    "            \n",
    "            if betas is not None:\n",
    "                roi_betas[cat_name] = betas\n",
    "        \n",
    "        if len(roi_betas) == 4:\n",
    "            results[roi_type] = roi_betas\n",
    "            print(f\"  ✓ {roi_type}: {len(roi_betas['faces'])} voxels\")\n",
    "    \n",
    "    return results if len(results) == 2 else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "BETA EXTRACTION\n",
      "================================================================================\n",
      "\n",
      "UD (sub-004):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Session 01:\n",
      "  ✓ face_word: 8023 voxels\n",
      "  ✓ object_house: 13734 voxels\n",
      "  ✓ Extraction complete\n",
      "\n",
      "Session 02:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "Session 03:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "Session 05:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-05/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "Session 06:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-004/ses-06/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "✓ UD: 1 sessions extracted\n",
      "\n",
      "TC (sub-021):\n",
      "------------------------------------------------------------\n",
      "\n",
      "Session 01:\n",
      "  ✓ face_word: 6366 voxels\n",
      "  ✓ object_house: 10405 voxels\n",
      "  ✓ Extraction complete\n",
      "\n",
      "Session 02:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-02/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "Session 03:\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope6.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope7.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope8.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Cope not found: /user_data/csimmon2/long_pt/sub-021/ses-03/derivatives/fsl/loc/HighLevel.gfeat/cope9.feat/stats/cope1_ses01.nii.gz\n",
      "  ✗ Extraction failed\n",
      "\n",
      "✓ TC: 1 sessions extracted\n",
      "\n",
      "================================================================================\n",
      "Total patients with data: 2\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL: Extract Betas for All Sessions\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BETA EXTRACTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_session_data = {}\n",
    "\n",
    "for subject_id, config in PATIENTS.items():\n",
    "    code = config['code']\n",
    "    print(f\"\\n{code} ({subject_id}):\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    subject_data = {}\n",
    "    \n",
    "    for session in config['sessions']:\n",
    "        print(f\"\\nSession {session}:\")\n",
    "        \n",
    "        betas = extract_session_betas(subject_id, session, ROI_ANALYSES, BASE_DIR)\n",
    "        \n",
    "        if betas is not None:\n",
    "            subject_data[session] = betas\n",
    "            print(f\"  ✓ Extraction complete\")\n",
    "        else:\n",
    "            print(f\"  ✗ Extraction failed\")\n",
    "    \n",
    "    if len(subject_data) > 0:\n",
    "        all_session_data[code] = subject_data\n",
    "        print(f\"\\n✓ {code}: {len(subject_data)} sessions extracted\")\n",
    "    else:\n",
    "        print(f\"\\n✗ {code}: No sessions extracted\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"Total patients with data: {len(all_session_data)}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "COMPUTING RDMs\n",
      "================================================================================\n",
      "\n",
      "UD:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Session 01:\n",
      "  Face-Word: dissim=1.4953\n",
      "  House-Object: dissim=1.6898\n",
      "\n",
      "Session 02:\n",
      "  Face-Word: dissim=0.4737\n",
      "  House-Object: dissim=1.1656\n",
      "\n",
      "Session 03:\n",
      "  Face-Word: dissim=0.9712\n",
      "  House-Object: dissim=0.8472\n",
      "\n",
      "Session 05:\n",
      "  Face-Word: dissim=1.1347\n",
      "  House-Object: dissim=1.1203\n",
      "\n",
      "Session 06:\n",
      "  Face-Word: dissim=0.6663\n",
      "  House-Object: dissim=0.9814\n",
      "\n",
      "TC:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Session 01:\n",
      "  Face-Word: dissim=1.7938\n",
      "  House-Object: dissim=1.8621\n",
      "\n",
      "Session 02:\n",
      "  Face-Word: dissim=0.9567\n",
      "  House-Object: dissim=1.4962\n",
      "\n",
      "Session 03:\n",
      "  Face-Word: dissim=1.2059\n",
      "  House-Object: dissim=1.5631\n",
      "\n",
      "================================================================================\n",
      "RDM COMPUTATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL: Compute RDMs from Extracted Betas\n",
    "# ============================================================================\n",
    "\n",
    "def compute_rdm_from_betas(beta_dict):\n",
    "    \"\"\"Compute 4x4 RDM from beta dictionary\"\"\"\n",
    "    categories = ['faces', 'words', 'objects', 'houses']\n",
    "    \n",
    "    # Stack into matrix\n",
    "    beta_matrix = np.vstack([beta_dict[cat] for cat in categories])\n",
    "    \n",
    "    # Correlate across voxels\n",
    "    corr_matrix = np.corrcoef(beta_matrix)\n",
    "    \n",
    "    # Convert to dissimilarity\n",
    "    rdm = 1 - corr_matrix\n",
    "    \n",
    "    return rdm, categories\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COMPUTING RDMs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Store RDMs and dissimilarities\n",
    "rsa_data = {}\n",
    "\n",
    "for code, sessions_dict in all_session_data.items():\n",
    "    print(f\"\\n{code}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    rsa_data[code] = {\n",
    "        'face_word': [],\n",
    "        'object_house': []\n",
    "    }\n",
    "    \n",
    "    for session, beta_data in sorted(sessions_dict.items()):\n",
    "        print(f\"\\nSession {session}:\")\n",
    "        \n",
    "        # Face-Word ROI\n",
    "        if 'face_word' in beta_data:\n",
    "            rdm_fw, cats = compute_rdm_from_betas(beta_data['face_word'])\n",
    "            face_idx = cats.index('faces')\n",
    "            word_idx = cats.index('words')\n",
    "            dissim_fw = rdm_fw[face_idx, word_idx]\n",
    "            \n",
    "            rsa_data[code]['face_word'].append({\n",
    "                'session': int(session),\n",
    "                'rdm': rdm_fw,\n",
    "                'dissimilarity': dissim_fw,\n",
    "                'n_voxels': len(beta_data['face_word']['faces'])\n",
    "            })\n",
    "            print(f\"  Face-Word: dissim={dissim_fw:.4f}\")\n",
    "        \n",
    "        # Object-House ROI  \n",
    "        if 'object_house' in beta_data:\n",
    "            rdm_oh, cats = compute_rdm_from_betas(beta_data['object_house'])\n",
    "            house_idx = cats.index('houses')\n",
    "            object_idx = cats.index('objects')\n",
    "            dissim_oh = rdm_oh[house_idx, object_idx]\n",
    "            \n",
    "            rsa_data[code]['object_house'].append({\n",
    "                'session': int(session),\n",
    "                'rdm': rdm_oh,\n",
    "                'dissimilarity': dissim_oh,\n",
    "                'n_voxels': len(beta_data['object_house']['faces'])\n",
    "            })\n",
    "            print(f\"  House-Object: dissim={dissim_oh:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RDM COMPUTATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Session Inventory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EXTRACTED DATA SUMMARY\n",
      "================================================================================\n",
      "\n",
      "UD:\n",
      "  Face-Word: 5 sessions\n",
      "  Object-House: 5 sessions\n",
      "\n",
      "TC:\n",
      "  Face-Word: 3 sessions\n",
      "  Object-House: 3 sessions\n"
     ]
    }
   ],
   "source": [
    "# Check what we extracted\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"EXTRACTED DATA SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for code, roi_dict in rsa_data.items():\n",
    "    print(f\"\\n{code}:\")\n",
    "    print(f\"  Face-Word: {len(roi_dict['face_word'])} sessions\")\n",
    "    print(f\"  Object-House: {len(roi_dict['object_house'])} sessions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Core functions defined\n"
     ]
    }
   ],
   "source": [
    "def load_session_data(session_id, beta_dir):\n",
    "    \"\"\"Load beta matrix, ROI info, and metadata\"\"\"\n",
    "    session_dir = beta_dir / session_id\n",
    "    \n",
    "    if not session_dir.exists():\n",
    "        return None, None, None\n",
    "    \n",
    "    beta_file = session_dir / \"beta_matrix.npy\"\n",
    "    roi_file = session_dir / \"roi_info.csv\"\n",
    "    metadata_file = session_dir / \"metadata.json\"\n",
    "    \n",
    "    if not all([beta_file.exists(), roi_file.exists(), metadata_file.exists()]):\n",
    "        return None, None, None\n",
    "    \n",
    "    beta_matrix = np.load(beta_file)\n",
    "    roi_info = pd.read_csv(roi_file)\n",
    "    \n",
    "    with open(metadata_file, 'r') as f:\n",
    "        metadata = json.load(f)\n",
    "    \n",
    "    return beta_matrix, roi_info, metadata\n",
    "\n",
    "\n",
    "def extract_category_betas_from_roi(beta_matrix, roi_info, condition_order, \n",
    "                                    roi_name, hemisphere):\n",
    "    \"\"\"Extract betas for all 4 categories from specified ROI\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    category_betas : dict\n",
    "        {category: beta_array} for faces, words, objects, houses\n",
    "    n_voxels : int\n",
    "    \"\"\"\n",
    "    # Select voxels from this ROI in this hemisphere\n",
    "    hemi_roi_name = f\"{hemisphere}_{roi_name}\"\n",
    "    voxel_mask = roi_info['roi_type'].str.contains(roi_name, case=False, na=False)\n",
    "    voxel_mask &= roi_info['roi_type'].str.startswith(f\"{hemisphere}_\", na=False)\n",
    "    \n",
    "    n_selected = voxel_mask.sum()\n",
    "    \n",
    "    if n_selected == 0:\n",
    "        return None, 0\n",
    "    \n",
    "    # Extract all 4 categories from same voxels\n",
    "    categories = ['faces', 'words', 'objects', 'houses']\n",
    "    category_betas = {}\n",
    "    \n",
    "    for cat in categories:\n",
    "        if cat not in condition_order:\n",
    "            return None, 0\n",
    "        cat_idx = condition_order.index(cat)\n",
    "        category_betas[cat] = beta_matrix[cat_idx, voxel_mask]\n",
    "    \n",
    "    return category_betas, n_selected\n",
    "\n",
    "\n",
    "def compute_rdm(category_betas):\n",
    "    \"\"\"Compute 4×4 representational dissimilarity matrix\n",
    "    \n",
    "    RDM[i,j] = 1 - correlation(category_i, category_j)\n",
    "    \"\"\"\n",
    "    categories = ['faces', 'words', 'objects', 'houses']\n",
    "    beta_matrix = np.vstack([category_betas[cat] for cat in categories])\n",
    "    correlation_matrix = np.corrcoef(beta_matrix)\n",
    "    rdm = 1 - correlation_matrix\n",
    "    return rdm, categories\n",
    "\n",
    "\n",
    "def extract_dissimilarity(rdm, categories, cat1, cat2):\n",
    "    \"\"\"Extract specific dissimilarity pair from RDM\"\"\"\n",
    "    idx1 = categories.index(cat1)\n",
    "    idx2 = categories.index(cat2)\n",
    "    return rdm[idx1, idx2]\n",
    "\n",
    "\n",
    "print(\"✓ Core functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Patient Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Patient processing function defined\n"
     ]
    }
   ],
   "source": [
    "def process_patient_rsa(subject_id, patient_config, roi_config, \n",
    "                       session_inventory, beta_dir):\n",
    "    \"\"\"Process one ROI analysis for one patient\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    trajectory_df : pd.DataFrame with columns:\n",
    "        - session, session_id, n_voxels, dissimilarity, rdm\n",
    "    \"\"\"\n",
    "    code = patient_config['code']\n",
    "    hemisphere = patient_config['hemi']\n",
    "    roi_name = roi_config['name']\n",
    "    cat1, cat2 = roi_config['dissim_pair']\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{code} - {roi_config['description']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"ROI: {hemisphere}_{roi_name}\")\n",
    "    print(f\"Tracking: {cat1}-{cat2} dissimilarity\\n\")\n",
    "    \n",
    "    # Get sessions\n",
    "    patient_sessions = session_inventory[\n",
    "        session_inventory['subject'] == subject_id\n",
    "    ].sort_values('session')\n",
    "    \n",
    "    trajectory = []\n",
    "    \n",
    "    for _, session_row in patient_sessions.iterrows():\n",
    "        session_id = session_row['session_id']\n",
    "        session_num = session_row['session']\n",
    "        \n",
    "        print(f\"Session {session_num}:\", end=' ')\n",
    "        \n",
    "        # Load data\n",
    "        beta_matrix, roi_info, metadata = load_session_data(session_id, beta_dir)\n",
    "        if beta_matrix is None:\n",
    "            print(\"✗ Load failed\")\n",
    "            continue\n",
    "        \n",
    "        # Extract betas\n",
    "        category_betas, n_voxels = extract_category_betas_from_roi(\n",
    "            beta_matrix, roi_info, metadata['condition_order'],\n",
    "            roi_name, hemisphere\n",
    "        )\n",
    "        \n",
    "        if category_betas is None:\n",
    "            print(\"✗ No voxels\")\n",
    "            continue\n",
    "        \n",
    "        # Compute RDM\n",
    "        rdm, categories = compute_rdm(category_betas)\n",
    "        \n",
    "        # Extract dissimilarity\n",
    "        dissim = extract_dissimilarity(rdm, categories, cat1, cat2)\n",
    "        \n",
    "        print(f\"✓ {n_voxels} voxels, dissim={dissim:.4f}\")\n",
    "        \n",
    "        trajectory.append({\n",
    "            'subject': subject_id,\n",
    "            'code': code,\n",
    "            'session': session_num,\n",
    "            'session_id': session_id,\n",
    "            'hemisphere': hemisphere,\n",
    "            'roi_type': roi_config['name'],\n",
    "            'n_voxels': n_voxels,\n",
    "            'dissimilarity': dissim,\n",
    "            'rdm': rdm,\n",
    "            'categories': categories,\n",
    "            'pair': f\"{cat1}-{cat2}\"\n",
    "        })\n",
    "    \n",
    "    if len(trajectory) == 0:\n",
    "        print(f\"\\n✗ No valid sessions\")\n",
    "        return None\n",
    "    \n",
    "    trajectory_df = pd.DataFrame(trajectory)\n",
    "    print(f\"\\n✓ Extracted {len(trajectory)} sessions\")\n",
    "    \n",
    "    return trajectory_df\n",
    "\n",
    "print(\"✓ Patient processing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap Null Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UD - STATISTICAL TESTING\n",
      "======================================================================\n",
      "\n",
      "Face-Word:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.0635 (p=0.507) (ns)\n",
      "\n",
      "Object-House:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.0978 (p=0.108) (ns)\n",
      "\n",
      "======================================================================\n",
      "TC - STATISTICAL TESTING\n",
      "======================================================================\n",
      "\n",
      "Face-Word:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.2940 (p=0.541) (ns)\n",
      "\n",
      "Object-House:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.1495 (p=0.661) (ns)\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL: Bootstrap and Statistical Testing\n",
    "# ============================================================================\n",
    "\n",
    "def bootstrap_null_slopes(trajectory_list, cat1_name, cat2_name, n_bootstrap=1000, seed=42):\n",
    "    \"\"\"Generate null distribution from shuffled RDMs\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    sessions = np.array([t['session'] for t in trajectory_list])\n",
    "    n_sessions = len(sessions)\n",
    "    categories = ['faces', 'words', 'objects', 'houses']\n",
    "    cat1_idx = categories.index(cat1_name)\n",
    "    cat2_idx = categories.index(cat2_name)\n",
    "    \n",
    "    print(f\"  Bootstrapping ({n_bootstrap} iterations)...\", end=' ')\n",
    "    \n",
    "    null_slopes = []\n",
    "    for i in range(n_bootstrap):\n",
    "        shuffled_dissims = []\n",
    "        for t in trajectory_list:\n",
    "            rdm = t['rdm'].copy()\n",
    "            shuffle_idx = np.random.permutation(4)\n",
    "            rdm_shuffled = rdm[shuffle_idx, :][:, shuffle_idx]\n",
    "            shuffled_dissims.append(rdm_shuffled[cat1_idx, cat2_idx])\n",
    "        \n",
    "        slope = np.polyfit(sessions, shuffled_dissims, 1)[0] if n_sessions >= 2 else 0\n",
    "        null_slopes.append(slope)\n",
    "    \n",
    "    print(\"✓\")\n",
    "    return np.array(null_slopes)\n",
    "\n",
    "\n",
    "def test_significance(trajectory_list, null_slopes):\n",
    "    \"\"\"Test observed slope against null\"\"\"\n",
    "    sessions = np.array([t['session'] for t in trajectory_list])\n",
    "    dissims = np.array([t['dissimilarity'] for t in trajectory_list])\n",
    "    \n",
    "    slope_obs = np.polyfit(sessions, dissims, 1)[0]\n",
    "    ci_lower, ci_upper = np.percentile(null_slopes, [2.5, 97.5])\n",
    "    p_value = np.mean(np.abs(null_slopes) >= np.abs(slope_obs))\n",
    "    significant = (slope_obs < ci_lower) or (slope_obs > ci_upper)\n",
    "    \n",
    "    return {\n",
    "        'slope_obs': slope_obs,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'p_value': p_value,\n",
    "        'significant': significant,\n",
    "        'null_slopes': null_slopes\n",
    "    }\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "all_results = {}\n",
    "\n",
    "for code, roi_dict in rsa_data.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{code} - STATISTICAL TESTING\")\n",
    "    print('='*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Face-Word\n",
    "    if len(roi_dict['face_word']) >= 2:\n",
    "        print(\"\\nFace-Word:\")\n",
    "        null_fw = bootstrap_null_slopes(roi_dict['face_word'], 'faces', 'words', N_BOOTSTRAP, RANDOM_SEED)\n",
    "        stats_fw = test_significance(roi_dict['face_word'], null_fw)\n",
    "        results['face_word'] = {'trajectory': roi_dict['face_word'], 'stats': stats_fw}\n",
    "        print(f\"  Slope: {stats_fw['slope_obs']:.4f} (p={stats_fw['p_value']:.3f}) ({'***' if stats_fw['significant'] else 'ns'})\")\n",
    "    \n",
    "    # Object-House\n",
    "    if len(roi_dict['object_house']) >= 2:\n",
    "        print(\"\\nObject-House:\")\n",
    "        null_oh = bootstrap_null_slopes(roi_dict['object_house'], 'houses', 'objects', N_BOOTSTRAP, RANDOM_SEED)\n",
    "        stats_oh = test_significance(roi_dict['object_house'], null_oh)\n",
    "        results['object_house'] = {'trajectory': roi_dict['object_house'], 'stats': stats_oh}\n",
    "        print(f\"  Slope: {stats_oh['slope_obs']:.4f} (p={stats_oh['p_value']:.3f}) ({'***' if stats_oh['significant'] else 'ns'})\")\n",
    "    \n",
    "    all_results[code] = results\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Statistical testing function defined\n"
     ]
    }
   ],
   "source": [
    "def test_slope_significance(trajectory_df, null_slopes):\n",
    "    \"\"\"Test if observed slope falls outside 95% CI of null distribution\"\"\"\n",
    "    \n",
    "    sessions = trajectory_df['session'].values\n",
    "    dissims = trajectory_df['dissimilarity'].values\n",
    "    \n",
    "    # Observed slope\n",
    "    slope_obs = np.polyfit(sessions, dissims, 1)[0]\n",
    "    \n",
    "    # 95% CI\n",
    "    ci_lower, ci_upper = np.percentile(null_slopes, [2.5, 97.5])\n",
    "    \n",
    "    # Two-tailed p-value\n",
    "    p_value = np.mean(np.abs(null_slopes) >= np.abs(slope_obs))\n",
    "    \n",
    "    # Significance\n",
    "    significant = (slope_obs < ci_lower) or (slope_obs > ci_upper)\n",
    "    \n",
    "    return {\n",
    "        'slope_obs': slope_obs,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'p_value': p_value,\n",
    "        'significant': significant,\n",
    "        'null_slopes': null_slopes\n",
    "    }\n",
    "\n",
    "print(\"✓ Statistical testing function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Visualization functions defined\n"
     ]
    }
   ],
   "source": [
    "def plot_patient_complete_analysis(trajectory_fw, trajectory_oh, \n",
    "                                   stats_fw, stats_oh, \n",
    "                                   patient_config, output_dir):\n",
    "    \"\"\"Create comprehensive 2×3 panel figure\n",
    "    \n",
    "    Top row: Face-Word (asymmetric)\n",
    "    Bottom row: Object-House (symmetric)\n",
    "    \n",
    "    Columns:\n",
    "    1. Trajectory\n",
    "    2. Example RDMs (first & last session)\n",
    "    3. Bootstrap histogram\n",
    "    \"\"\"\n",
    "    code = patient_config['code']\n",
    "    \n",
    "    fig = plt.figure(figsize=(20, 12))\n",
    "    gs = fig.add_gridspec(2, 3, hspace=0.3, wspace=0.3)\n",
    "    \n",
    "    # ===== TOP ROW: FACE-WORD =====\n",
    "    \n",
    "    # Panel A: Trajectory\n",
    "    ax1 = fig.add_subplot(gs[0, 0])\n",
    "    sessions_fw = trajectory_fw['session'].values\n",
    "    dissims_fw = trajectory_fw['dissimilarity'].values\n",
    "    \n",
    "    ax1.plot(sessions_fw, dissims_fw, 'o-', color='#FF1493', \n",
    "            linewidth=4, markersize=14, markeredgecolor='black', markeredgewidth=2)\n",
    "    ax1.set_xlabel('Session', fontsize=14, fontweight='bold')\n",
    "    ax1.set_ylabel('Dissimilarity (1-r)', fontsize=14, fontweight='bold')\n",
    "    ax1.set_title(f'{code} - Face-Word\\n(Asymmetric/Unilateral)', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    \n",
    "    # Add slope annotation\n",
    "    slope_text = f\"Slope: {stats_fw['slope_obs']:.4f}\"\n",
    "    if stats_fw['significant']:\n",
    "        slope_text += \" ***\"\n",
    "    ax1.text(0.05, 0.95, slope_text, transform=ax1.transAxes,\n",
    "            fontsize=12, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    # Panel B: RDMs\n",
    "    ax2 = fig.add_subplot(gs[0, 1])\n",
    "    rdm_first = trajectory_fw.iloc[0]['rdm']\n",
    "    rdm_last = trajectory_fw.iloc[-1]['rdm']\n",
    "    categories = trajectory_fw.iloc[0]['categories']\n",
    "    \n",
    "    # Show side-by-side RDMs\n",
    "    rdm_compare = np.hstack([rdm_first, rdm_last])\n",
    "    im = ax2.imshow(rdm_compare, cmap='viridis', vmin=0, vmax=2)\n",
    "    ax2.set_title(f'RDMs: Session {sessions_fw[0]} → {sessions_fw[-1]}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax2.set_yticks(range(4))\n",
    "    ax2.set_yticklabels(categories, fontsize=10)\n",
    "    ax2.set_xticks([])\n",
    "    plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Panel C: Bootstrap\n",
    "    ax3 = fig.add_subplot(gs[0, 2])\n",
    "    ax3.hist(stats_fw['null_slopes'], bins=50, color='gold', alpha=0.7, \n",
    "            edgecolor='black', linewidth=1)\n",
    "    ax3.axvline(stats_fw['slope_obs'], color='#FF1493', linewidth=4,\n",
    "               label=f\"Observed (p={stats_fw['p_value']:.3f})\")\n",
    "    ax3.axvline(stats_fw['ci_lower'], color='gray', linestyle='--', linewidth=2)\n",
    "    ax3.axvline(stats_fw['ci_upper'], color='gray', linestyle='--', linewidth=2,\n",
    "               label='95% CI')\n",
    "    ax3.set_xlabel('Regression Slope', fontsize=14, fontweight='bold')\n",
    "    ax3.set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "    ax3.set_title('Bootstrap Test', fontsize=14, fontweight='bold')\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    # ===== BOTTOM ROW: OBJECT-HOUSE =====\n",
    "    \n",
    "    # Panel D: Trajectory\n",
    "    ax4 = fig.add_subplot(gs[1, 0])\n",
    "    sessions_oh = trajectory_oh['session'].values\n",
    "    dissims_oh = trajectory_oh['dissimilarity'].values\n",
    "    \n",
    "    ax4.plot(sessions_oh, dissims_oh, 's-', color='#00CED1',\n",
    "            linewidth=4, markersize=14, markeredgecolor='black', markeredgewidth=2)\n",
    "    ax4.set_xlabel('Session', fontsize=14, fontweight='bold')\n",
    "    ax4.set_ylabel('Dissimilarity (1-r)', fontsize=14, fontweight='bold')\n",
    "    ax4.set_title(f'{code} - House-Object\\n(Symmetric/Bilateral)',\n",
    "                 fontsize=16, fontweight='bold')\n",
    "    ax4.grid(alpha=0.3)\n",
    "    \n",
    "    # Add slope annotation\n",
    "    slope_text = f\"Slope: {stats_oh['slope_obs']:.4f}\"\n",
    "    if stats_oh['significant']:\n",
    "        slope_text += \" ***\"\n",
    "    ax4.text(0.05, 0.95, slope_text, transform=ax4.transAxes,\n",
    "            fontsize=12, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.5))\n",
    "    \n",
    "    # Panel E: RDMs\n",
    "    ax5 = fig.add_subplot(gs[1, 1])\n",
    "    rdm_first = trajectory_oh.iloc[0]['rdm']\n",
    "    rdm_last = trajectory_oh.iloc[-1]['rdm']\n",
    "    \n",
    "    rdm_compare = np.hstack([rdm_first, rdm_last])\n",
    "    im = ax5.imshow(rdm_compare, cmap='viridis', vmin=0, vmax=2)\n",
    "    ax5.set_title(f'RDMs: Session {sessions_oh[0]} → {sessions_oh[-1]}',\n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax5.set_yticks(range(4))\n",
    "    ax5.set_yticklabels(categories, fontsize=10)\n",
    "    ax5.set_xticks([])\n",
    "    plt.colorbar(im, ax=ax5, fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Panel F: Bootstrap\n",
    "    ax6 = fig.add_subplot(gs[1, 2])\n",
    "    ax6.hist(stats_oh['null_slopes'], bins=50, color='gold', alpha=0.7,\n",
    "            edgecolor='black', linewidth=1)\n",
    "    ax6.axvline(stats_oh['slope_obs'], color='#00CED1', linewidth=4,\n",
    "               label=f\"Observed (p={stats_oh['p_value']:.3f})\")\n",
    "    ax6.axvline(stats_oh['ci_lower'], color='gray', linestyle='--', linewidth=2)\n",
    "    ax6.axvline(stats_oh['ci_upper'], color='gray', linestyle='--', linewidth=2,\n",
    "               label='95% CI')\n",
    "    ax6.set_xlabel('Regression Slope', fontsize=14, fontweight='bold')\n",
    "    ax6.set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "    ax6.set_title('Bootstrap Test', fontsize=14, fontweight='bold')\n",
    "    ax6.legend(fontsize=10)\n",
    "    ax6.grid(alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.suptitle(f'{code} - Longitudinal RSA: Asymmetric vs. Symmetric Categories',\n",
    "                fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Save\n",
    "    output_file = output_dir / f'{code}_complete_rsa_analysis.png'\n",
    "    plt.savefig(output_file, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"\\n✓ Figure saved: {output_file}\")\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return fig\n",
    "\n",
    "print(\"✓ Visualization functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Analysis Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "UD - STATISTICAL TESTING\n",
      "======================================================================\n",
      "\n",
      "Face-Word:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.0635 (ns)\n",
      "\n",
      "Object-House:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.0978 (ns)\n",
      "\n",
      "======================================================================\n",
      "TC - STATISTICAL TESTING\n",
      "======================================================================\n",
      "\n",
      "Face-Word:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.2940 (ns)\n",
      "\n",
      "Object-House:\n",
      "  Bootstrapping (1000 iterations)... ✓\n",
      "  Slope: -0.1495 (ns)\n",
      "\n",
      "======================================================================\n",
      "ANALYSIS COMPLETE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL: Bootstrap and Statistical Testing\n",
    "# ============================================================================\n",
    "\n",
    "def bootstrap_null_slopes(trajectory_list, n_bootstrap=1000, seed=42):\n",
    "    \"\"\"Generate null distribution from shuffled RDMs\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    sessions = np.array([t['session'] for t in trajectory_list])\n",
    "    n_sessions = len(sessions)\n",
    "    \n",
    "    print(f\"  Bootstrapping ({n_bootstrap} iterations)...\", end=' ')\n",
    "    \n",
    "    null_slopes = []\n",
    "    for i in range(n_bootstrap):\n",
    "        shuffled_dissims = []\n",
    "        for t in trajectory_list:\n",
    "            rdm = t['rdm'].copy()\n",
    "            shuffle_idx = np.random.permutation(4)\n",
    "            rdm_shuffled = rdm[shuffle_idx, :][:, shuffle_idx]\n",
    "            shuffled_dissims.append(rdm_shuffled[0, 1])  # Any pair\n",
    "        \n",
    "        slope = np.polyfit(sessions, shuffled_dissims, 1)[0] if n_sessions >= 2 else 0\n",
    "        null_slopes.append(slope)\n",
    "    \n",
    "    print(\"✓\")\n",
    "    return np.array(null_slopes)\n",
    "\n",
    "\n",
    "def test_significance(trajectory_list, null_slopes):\n",
    "    \"\"\"Test observed slope against null\"\"\"\n",
    "    sessions = np.array([t['session'] for t in trajectory_list])\n",
    "    dissims = np.array([t['dissimilarity'] for t in trajectory_list])\n",
    "    \n",
    "    slope_obs = np.polyfit(sessions, dissims, 1)[0]\n",
    "    ci_lower, ci_upper = np.percentile(null_slopes, [2.5, 97.5])\n",
    "    p_value = np.mean(np.abs(null_slopes) >= np.abs(slope_obs))\n",
    "    significant = (slope_obs < ci_lower) or (slope_obs > ci_upper)\n",
    "    \n",
    "    return {\n",
    "        'slope_obs': slope_obs,\n",
    "        'ci_lower': ci_lower,\n",
    "        'ci_upper': ci_upper,\n",
    "        'p_value': p_value,\n",
    "        'significant': significant,\n",
    "        'null_slopes': null_slopes\n",
    "    }\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "all_results = {}\n",
    "\n",
    "for code, roi_dict in rsa_data.items():\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"{code} - STATISTICAL TESTING\")\n",
    "    print('='*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # Face-Word\n",
    "    if len(roi_dict['face_word']) >= 2:\n",
    "        print(\"\\nFace-Word:\")\n",
    "        null_fw = bootstrap_null_slopes(roi_dict['face_word'], N_BOOTSTRAP, RANDOM_SEED)\n",
    "        stats_fw = test_significance(roi_dict['face_word'], null_fw)\n",
    "        results['face_word'] = {'trajectory': roi_dict['face_word'], 'stats': stats_fw}\n",
    "        print(f\"  Slope: {stats_fw['slope_obs']:.4f} ({'SIG' if stats_fw['significant'] else 'ns'})\")\n",
    "    \n",
    "    # Object-House\n",
    "    if len(roi_dict['object_house']) >= 2:\n",
    "        print(\"\\nObject-House:\")\n",
    "        null_oh = bootstrap_null_slopes(roi_dict['object_house'], N_BOOTSTRAP, RANDOM_SEED)\n",
    "        stats_oh = test_significance(roi_dict['object_house'], null_oh)\n",
    "        results['object_house'] = {'trajectory': roi_dict['object_house'], 'stats': stats_oh}\n",
    "        print(f\"  Slope: {stats_oh['slope_obs']:.4f} ({'SIG' if stats_oh['significant'] else 'ns'})\")\n",
    "    \n",
    "    all_results[code] = results\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY TABLE\n",
      "================================================================================\n",
      "Patient  N_Sessions FW_Slope  FW_p FW_Sig OH_Slope  OH_p OH_Sig\n",
      "     UD           5  -0.0635 0.507     ns  -0.0978 0.112     ns\n",
      "     TC           3  -0.2940 0.541     ns  -0.1495 0.644     ns\n",
      "\n",
      "✓ Summary saved: /user_data/csimmon2/long_pt/analyses/longitudinal_rsa_final/longitudinal_rsa_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive summary\n",
    "summary_data = []\n",
    "\n",
    "for code, results in all_results.items():\n",
    "    row = {'Patient': code}\n",
    "    \n",
    "    if 'face_word' in results:\n",
    "        stats_fw = results['face_word']['stats']\n",
    "        n_sess = len(results['face_word']['trajectory'])\n",
    "        row.update({\n",
    "            'N_Sessions': n_sess,\n",
    "            'FW_Slope': f\"{stats_fw['slope_obs']:.4f}\",\n",
    "            'FW_p': f\"{stats_fw['p_value']:.3f}\",\n",
    "            'FW_Sig': '***' if stats_fw['significant'] else 'ns'\n",
    "        })\n",
    "    \n",
    "    if 'object_house' in results:\n",
    "        stats_oh = results['object_house']['stats']\n",
    "        row.update({\n",
    "            'OH_Slope': f\"{stats_oh['slope_obs']:.4f}\",\n",
    "            'OH_p': f\"{stats_oh['p_value']:.3f}\",\n",
    "            'OH_Sig': '***' if stats_oh['significant'] else 'ns'\n",
    "        })\n",
    "    \n",
    "    summary_data.append(row)\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SUMMARY TABLE\")\n",
    "print(\"=\"*80)\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "# Save\n",
    "summary_file = OUTPUT_DIR / 'longitudinal_rsa_summary.csv'\n",
    "summary_df.to_csv(summary_file, index=False)\n",
    "print(f\"\\n✓ Summary saved: {summary_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation Guide\n",
    "\n",
    "### Expected Patterns:\n",
    "\n",
    "**Asymmetric Categories (Face-Word):**\n",
    "- **TC & UD:** Should show INCREASING dissimilarity (positive slope, significant)\n",
    "- Interpretation: Competitive differentiation as representations reorganize in single hemisphere\n",
    "- Higher initial overlap → must differentiate over time\n",
    "\n",
    "**Symmetric Categories (Object-House):**\n",
    "- **TC & UD:** Should show STABLE dissimilarity (slope near zero, not significant)\n",
    "- Interpretation: Bilateral categories less affected by unilateral resection\n",
    "- Already differentiated in typical development\n",
    "\n",
    "### Key Comparisons:\n",
    "\n",
    "1. **Within-patient:** Face-Word slope > House-Object slope\n",
    "2. **Cross-patient:** Both TC and UD show similar patterns\n",
    "3. **Mechanism:** Pattern differentiation (correlation-based), not magnitude changes\n",
    "\n",
    "### Liu et al. (2025) Reference Values:\n",
    "- **TC Face-Word:** 0.15 (significant)\n",
    "- **UD Face-Word:** 0.12 (significant, first 4 sessions)\n",
    "- **TC House-Object:** 0.01 (not significant)\n",
    "- **UD House-Object:** 0.02 (not significant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROI shape: (176, 256, 256)\n",
      "Cope shape: (176, 256, 256)\n",
      "\n",
      "ROI affine:\n",
      " [[   1.     0.     0.   -83.5]\n",
      " [   0.     1.     0.  -127. ]\n",
      " [   0.     0.     1.  -127. ]\n",
      " [   0.     0.     0.     1. ]]\n",
      "\n",
      "Cope affine:\n",
      " [[   1.     0.     0.   -83.5]\n",
      " [   0.     1.     0.  -127. ]\n",
      " [   0.     0.     1.  -127. ]\n",
      " [   0.     0.     0.     1. ]]\n",
      "\n",
      "Shapes match: True\n",
      "Affines match: True\n"
     ]
    }
   ],
   "source": [
    "# Check image spaces match\n",
    "subject_id = 'sub-004'\n",
    "session = '01'\n",
    "\n",
    "roi_file = BASE_DIR / subject_id / 'ses-01' / 'ROIs' / 'l_face_word_dual_cluster.nii.gz'\n",
    "cope_file = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat' / 'cope6.feat' / 'stats' / 'cope1.nii.gz'\n",
    "\n",
    "roi_img = nib.load(roi_file)\n",
    "cope_img = nib.load(cope_file)\n",
    "\n",
    "print(\"ROI shape:\", roi_img.shape)\n",
    "print(\"Cope shape:\", cope_img.shape)\n",
    "print(\"\\nROI affine:\\n\", roi_img.affine)\n",
    "print(\"\\nCope affine:\\n\", cope_img.affine)\n",
    "print(\"\\nShapes match:\", roi_img.shape == cope_img.shape)\n",
    "print(\"Affines match:\", np.allclose(roi_img.affine, cope_img.affine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UD:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Face-Word dissimilarity trajectory:\n",
      "  Session 01: 1.4953\n",
      "  Session 02: 0.4737\n",
      "  Session 03: 0.9712\n",
      "  Session 05: 1.1347\n",
      "  Session 06: 0.6663\n",
      "\n",
      "Object-House dissimilarity trajectory:\n",
      "  Session 01: 1.6898\n",
      "  Session 02: 1.1656\n",
      "  Session 03: 0.8472\n",
      "  Session 05: 1.1203\n",
      "  Session 06: 0.9814\n",
      "\n",
      "TC:\n",
      "------------------------------------------------------------\n",
      "\n",
      "Face-Word dissimilarity trajectory:\n",
      "  Session 01: 1.7938\n",
      "  Session 02: 0.9567\n",
      "  Session 03: 1.2059\n",
      "\n",
      "Object-House dissimilarity trajectory:\n",
      "  Session 01: 1.8621\n",
      "  Session 02: 1.4962\n",
      "  Session 03: 1.5631\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# CELL: Diagnostic - View Dissimilarity Trajectories\n",
    "# ============================================================================\n",
    "\n",
    "for code, roi_dict in rsa_data.items():\n",
    "    print(f\"\\n{code}:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(\"\\nFace-Word dissimilarity trajectory:\")\n",
    "    for t in roi_dict['face_word']:\n",
    "        print(f\"  Session {t['session']:02d}: {t['dissimilarity']:.4f}\")\n",
    "    \n",
    "    print(\"\\nObject-House dissimilarity trajectory:\")\n",
    "    for t in roi_dict['object_house']:\n",
    "        print(f\"  Session {t['session']:02d}: {t['dissimilarity']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Session 01:\n",
      "  Shapes match: True\n",
      "  Affines match: True\n",
      "Session 02:\n",
      "  Shapes match: True\n",
      "  Affines match: False\n",
      "Session 03:\n",
      "  Shapes match: True\n",
      "  Affines match: False\n",
      "Session 01:\n",
      "  Shapes match: True\n",
      "  Affines match: True\n",
      "Session 02:\n",
      "  Shapes match: True\n",
      "  Affines match: False\n",
      "Session 03:\n",
      "  Shapes match: True\n",
      "  Affines match: False\n"
     ]
    }
   ],
   "source": [
    "# Check if images are actually aligned\n",
    "subject_id = 'sub-004'\n",
    "roi_file = BASE_DIR / subject_id / 'ses-01' / 'ROIs' / 'l_face_word_dual_cluster.nii.gz'\n",
    "\n",
    "for session in ['01', '02', '03']:\n",
    "    cope_file = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat' / 'cope6.feat' / 'stats' / 'cope1.nii.gz'\n",
    "    \n",
    "    roi_img = nib.load(roi_file)\n",
    "    cope_img = nib.load(cope_file)\n",
    "    \n",
    "    print(f\"Session {session}:\")\n",
    "    print(f\"  Shapes match: {roi_img.shape == cope_img.shape}\")\n",
    "    print(f\"  Affines match: {np.allclose(roi_img.affine, cope_img.affine)}\")# Check if images are actually aligned\n",
    "subject_id = 'sub-004'\n",
    "roi_file = BASE_DIR / subject_id / 'ses-01' / 'ROIs' / 'l_face_word_dual_cluster.nii.gz'\n",
    "\n",
    "for session in ['01', '02', '03']:\n",
    "    cope_file = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat' / 'cope6.feat' / 'stats' / 'cope1.nii.gz'\n",
    "    \n",
    "    roi_img = nib.load(roi_file)\n",
    "    cope_img = nib.load(cope_file)\n",
    "    \n",
    "    print(f\"Session {session}:\")\n",
    "    print(f\"  Shapes match: {roi_img.shape == cope_img.shape}\")\n",
    "    print(f\"  Affines match: {np.allclose(roi_img.affine, cope_img.affine)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

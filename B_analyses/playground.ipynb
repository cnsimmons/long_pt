{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6dd6fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV loaded and configuration set\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Load CSV and Basic Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn import plotting, image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load subject info from CSV\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "OUTPUT_DIR = BASE_DIR / \"analyses\" / \"rsa_corrected\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Session start mapping (for special cases)\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "'''\n",
    "# Cope mapping (condition > scramble contrasts)\n",
    "COPE_MAP = {\n",
    "    'face': 10, # 10, 11, 12 are the same contrasts as 1, 2, 4\n",
    "    'word': 12,\n",
    "    'object': 3,\n",
    "    'house': 11\n",
    "}\n",
    "'''\n",
    "\n",
    "# Cope mapping: Key -> (Cope Number, Multiplier)\n",
    "# Multiplier 1  = Use contrast as is (e.g., Face > Scramble)\n",
    "# Multiplier -1 = Invert contrast (e.g., Face > Word becomes Word > Face)\n",
    "\n",
    "COPE_MAP = {\n",
    "    'face':   (10, 1),   # Face > Scramble\n",
    "    'word':   (13, -1),  # Face > Word (INVERTED to create Word > Face)\n",
    "    'object': (3,  1),   # Object > Scramble\n",
    "    'house':  (11, 1)    # House > Scramble\n",
    "}\n",
    "\n",
    "# Parcels are touchy. \n",
    "CATEGORY_PARCELS = {\n",
    "    'face': ['fusiform'],\n",
    "    'word': ['fusiform', 'inferiortemporal'], # needed to add IT to capture VWFA\n",
    "    'object': ['lateraloccipital'],\n",
    "    'house': ['parahippocampal', 'lingual', 'isthmuscingulate']\n",
    "}\n",
    "\n",
    "print(\"✓ CSV loaded and configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3c49762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMLINED SUBJECT LOADING COMPLETE\n",
      "==================================================\n",
      "Patients loaded: 16\n",
      "  - OTC: 7\n",
      "  - nonOTC: 9\n",
      "Controls loaded: 9\n",
      "Total analysis subjects: 25\n",
      "\n",
      "CORRECT CATEGORY_PARCELS:\n",
      "  face  : ['fusiform']\n",
      "  word  : ['fusiform', 'inferiortemporal']\n",
      "  object: ['lateraloccipital']\n",
      "  house : ['parahippocampal', 'lingual', 'isthmuscingulate']\n",
      "\n",
      "Sample subjects:\n",
      "  OTC004: OTC patient, hemi='l'\n",
      "  nonOTC007: nonOTC patient, hemi='r'\n",
      "  OTC008: OTC patient, hemi='l'\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Streamlined Subject Loading and Configuration\n",
    "def load_subjects_by_group(group_filter=None, patient_only=True):\n",
    "    \"\"\"Streamlined subject loading with proper configuration\"\"\"\n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if patient_only is True:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 1]\n",
    "    elif patient_only is False:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 0]\n",
    "    \n",
    "    if group_filter:\n",
    "        if isinstance(group_filter, str):\n",
    "            group_filter = [group_filter]\n",
    "        filtered_df = filtered_df[filtered_df['group'].isin(group_filter)]\n",
    "    \n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in filtered_df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        \n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        # Get available sessions\n",
    "        sessions = []\n",
    "        for ses_dir in subj_dir.glob('ses-*'):\n",
    "            if ses_dir.is_dir():\n",
    "                sessions.append(ses_dir.name.replace('ses-', ''))\n",
    "        \n",
    "        if not sessions:\n",
    "            continue\n",
    "            \n",
    "        sessions = sorted(sessions, key=lambda x: int(x))\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        available_sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        \n",
    "        if not available_sessions:\n",
    "            continue\n",
    "        \n",
    "        # Proper hemisphere mapping\n",
    "        if row['patient'] == 1:  # Patients\n",
    "            hemisphere_full = row.get('intact_hemi', 'left')\n",
    "            hemisphere = 'l' if hemisphere_full == 'left' else 'r'\n",
    "        else:  # Controls \n",
    "            hemisphere = 'r'  # Default for controls (we'll add bilateral later)\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': available_sessions,\n",
    "            'hemi': hemisphere,\n",
    "            'group': row['group'],\n",
    "            'patient_status': 'patient' if row['patient'] == 1 else 'control',\n",
    "            'age_1': row['age_1'] if pd.notna(row['age_1']) else None,\n",
    "            'surgery_side': row.get('SurgerySide', None) if row['patient'] == 1 else None\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "# Load subjects systematically\n",
    "ALL_PATIENTS = load_subjects_by_group(group_filter=None, patient_only=True)\n",
    "OTC_PATIENTS = load_subjects_by_group(group_filter='OTC', patient_only=True)\n",
    "NON_OTC_PATIENTS = load_subjects_by_group(group_filter='nonOTC', patient_only=True)\n",
    "ALL_CONTROLS = load_subjects_by_group(group_filter=None, patient_only=False)\n",
    "\n",
    "# Start with original subjects only\n",
    "ANALYSIS_SUBJECTS = {**ALL_PATIENTS, **ALL_CONTROLS}\n",
    "\n",
    "print(\"STREAMLINED SUBJECT LOADING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Patients loaded: {len(ALL_PATIENTS)}\")\n",
    "print(f\"  - OTC: {len(OTC_PATIENTS)}\")\n",
    "print(f\"  - nonOTC: {len(NON_OTC_PATIENTS)}\")\n",
    "print(f\"Controls loaded: {len(ALL_CONTROLS)}\")\n",
    "print(f\"Total analysis subjects: {len(ANALYSIS_SUBJECTS)}\")\n",
    "\n",
    "print(f\"\\nCORRECT CATEGORY_PARCELS:\")\n",
    "for category, parcels in CATEGORY_PARCELS.items():\n",
    "    print(f\"  {category:6s}: {parcels}\")\n",
    "\n",
    "print(f\"\\nSample subjects:\")\n",
    "for subj_id, info in list(ANALYSIS_SUBJECTS.items())[:3]:\n",
    "    print(f\"  {info['code']}: {info['group']} {info['patient_status']}, hemi='{info['hemi']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ec6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-running extraction...\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Functional ROI Extraction (FIXED IMPORTS)\n",
    "from scipy.ndimage import label, center_of_mass # <--- THIS WAS MISSING\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def extract_functional_rois_bilateral(subject_id, threshold_z=2.3, min_cluster_size=30):\n",
    "    info = ANALYSIS_SUBJECTS[subject_id]\n",
    "    roi_dir = BASE_DIR / subject_id / f'ses-{info[\"sessions\"][0]}' / 'ROIs'\n",
    "    if not roi_dir.exists(): return {}\n",
    "    \n",
    "    all_results = {}\n",
    "    first_session = info['sessions'][0]\n",
    "\n",
    "    for hemi in ['l', 'r']:\n",
    "        for category, cope_params in COPE_MAP.items():\n",
    "            # Unpack Tuple\n",
    "            cope_num, multiplier = cope_params if isinstance(cope_params, tuple) else (cope_params, 1)\n",
    "            \n",
    "            # Load Search Mask\n",
    "            mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "            if not mask_file.exists(): continue\n",
    "            \n",
    "            try:\n",
    "                search_mask = nib.load(mask_file).get_fdata() > 0\n",
    "                affine = nib.load(mask_file).affine\n",
    "            except: continue\n",
    "            \n",
    "            hemi_key = f'{hemi}_{category}'\n",
    "            all_results[hemi_key] = {}\n",
    "            \n",
    "            for session in info['sessions']:\n",
    "                feat_dir = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                z_name = 'zstat1.nii.gz' if session == first_session else f'zstat1_ses{first_session}.nii.gz'\n",
    "                cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                \n",
    "                if not cope_file.exists(): continue\n",
    "                \n",
    "                try:\n",
    "                    # Load & Invert\n",
    "                    zstat = nib.load(cope_file).get_fdata() * multiplier\n",
    "                    \n",
    "                    # Threshold\n",
    "                    suprathresh = (zstat > threshold_z) & search_mask\n",
    "                    \n",
    "                    # Cluster & Filter\n",
    "                    labeled, n_clusters = label(suprathresh) # <--- This is where it failed\n",
    "                    if n_clusters == 0: continue\n",
    "                    \n",
    "                    best_idx = -1\n",
    "                    max_peak = -999\n",
    "                    \n",
    "                    for i in range(1, n_clusters + 1):\n",
    "                        cluster_mask = (labeled == i)\n",
    "                        if np.sum(cluster_mask) >= min_cluster_size:\n",
    "                            peak_val = np.max(zstat[cluster_mask])\n",
    "                            if peak_val > max_peak:\n",
    "                                max_peak = peak_val\n",
    "                                best_idx = i\n",
    "                    \n",
    "                    if best_idx == -1: continue \n",
    "                    \n",
    "                    # Save Result\n",
    "                    roi_mask = (labeled == best_idx)\n",
    "                    peak_idx = np.unravel_index(np.argmax(zstat * roi_mask), zstat.shape)\n",
    "                    \n",
    "                    all_results[hemi_key][session] = {\n",
    "                        'n_voxels': int(np.sum(roi_mask)),\n",
    "                        'peak_z': zstat[peak_idx],\n",
    "                        'centroid': nib.affines.apply_affine(affine, center_of_mass(roi_mask)),\n",
    "                        'roi_mask': roi_mask\n",
    "                    }\n",
    "                except Exception as e: print(f\"Err {subject_id} {category}: {e}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# EXECUTE\n",
    "print(\"Re-running extraction...\")\n",
    "golarai_functional_final = {}\n",
    "for sub in ANALYSIS_SUBJECTS:\n",
    "    res = extract_functional_rois_bilateral(sub, min_cluster_size=30)\n",
    "    if res: golarai_functional_final[sub] = res\n",
    "print(f\"✓ Extraction Complete: {len(golarai_functional_final)} subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b1116f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROI SELECTIVITY CHECK\n",
      "========================================\n",
      "\n",
      ">> OTC004:\n",
      "\n",
      ">> control025:\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Verify Selectivity (Tuple Corrected)\n",
    "def verify_roi_selectivity(functional_results, subjects, sample_ids=['OTC004', 'control025']):\n",
    "    print(\"\\nROI SELECTIVITY CHECK\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for pid in sample_ids:\n",
    "        # Find full ID\n",
    "        sid = next((k for k,v in subjects.items() if v['code'] == pid), None)\n",
    "        if not sid or sid not in functional_results: continue\n",
    "        \n",
    "        print(f\"\\n>> {pid}:\")\n",
    "        res = functional_results[sid]\n",
    "        first_ses = subjects[sid]['sessions'][0]\n",
    "        \n",
    "        for roi_name in sorted(res.keys()):\n",
    "            if first_ses not in res[roi_name]: continue\n",
    "            roi_mask = res[roi_name][first_ses]['roi_mask']\n",
    "            target_cat = roi_name.split('_')[1]\n",
    "            \n",
    "            scores = {}\n",
    "            feat_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "            \n",
    "            for cat, (cope, mult) in COPE_MAP.items():\n",
    "                f = feat_dir / f'cope{cope}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "                if f.exists():\n",
    "                    d = nib.load(f).get_fdata() * mult\n",
    "                    scores[cat] = np.mean(d[roi_mask])\n",
    "            \n",
    "            top = max(scores, key=scores.get)\n",
    "            mark = \"✓\" if top == target_cat else \"✗\"\n",
    "            print(f\"  {roi_name:10s}: {mark} Top={top} (Target: {scores.get(target_cat,0):.2f})\")\n",
    "            \n",
    "verify_roi_selectivity(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84924c3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStability (r)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39munstack()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 48\u001b[0m df_hybrid \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_hybrid_stability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgolarai_functional_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mANALYSIS_SUBJECTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 41\u001b[0m, in \u001b[0;36mcompute_hybrid_stability\u001b[0;34m(functional_results, subjects, min_voxels)\u001b[0m\n\u001b[1;32m     38\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[1;32m     40\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m8\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n\u001b[0;32m---> 41\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mbarplot(data\u001b[38;5;241m=\u001b[39mdf, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStability (r)\u001b[39m\u001b[38;5;124m'\u001b[39m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSet2\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     42\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHybrid Stability (Fixed ROI)\u001b[39m\u001b[38;5;124m\"\u001b[39m, fontweight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbold\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     43\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# CELL 5: Hybrid Stability (Fixed ROI + Robust Extraction)\n",
    "def compute_hybrid_stability(functional_results, subjects, min_voxels=50):\n",
    "    # Robust Copes for Extraction Only\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        info = subjects[sid]\n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        first_ses = sessions[0]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            cat = roi_name.split('_')[1]\n",
    "            if first_ses not in roi_data: continue\n",
    "            \n",
    "            # 1. Fixed ROI from Session 1\n",
    "            mask = roi_data[first_ses]['roi_mask']\n",
    "            if np.sum(mask) < min_voxels: continue\n",
    "            \n",
    "            # 2. Extract using Robust Cope\n",
    "            patterns = {}\n",
    "            for ses in sessions:\n",
    "                f = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                z = f / f'cope{EXTRACTION_MAP[cat]}.feat' / 'stats' / ('zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz')\n",
    "                if z.exists():\n",
    "                    try: patterns[ses] = nib.load(z).get_fdata()[mask]\n",
    "                    except: pass\n",
    "            \n",
    "            # 3. Correlate\n",
    "            if sessions[-1] in patterns:\n",
    "                corr = np.corrcoef(patterns[first_ses], patterns[sessions[-1]])[0,1]\n",
    "                data.append({\n",
    "                    'Group': info['group'], 'Category': cat.capitalize(),\n",
    "                    'Type': CATEGORY_TYPES[cat], 'Stability (r)': corr\n",
    "                })\n",
    "                \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.barplot(data=df, x='Type', y='Stability (r)', hue='Group', palette='Set2')\n",
    "    plt.title(\"Hybrid Stability (Fixed ROI)\", fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    print(df.groupby(['Group', 'Type'])['Stability (r)'].mean().unstack().round(3))\n",
    "    return df\n",
    "\n",
    "df_hybrid = compute_hybrid_stability(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b788de61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 6: Drift Analysis\n",
    "def analyze_drift(functional_results, subjects, min_voxels=50):\n",
    "    data = []\n",
    "    for sid, res in functional_results.items():\n",
    "        info = subjects[sid]\n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            cat = roi_name.split('_')[1]\n",
    "            first, last = sessions[0], sessions[-1]\n",
    "            \n",
    "            if first in roi_data and last in roi_data:\n",
    "                if roi_data[first]['n_voxels'] >= min_voxels:\n",
    "                    c1 = np.array(roi_data[first]['centroid'])\n",
    "                    c2 = np.array(roi_data[last]['centroid'])\n",
    "                    dist = np.linalg.norm(c2 - c1)\n",
    "                    \n",
    "                    data.append({\n",
    "                        'Group': info['group'], 'Category': cat.capitalize(),\n",
    "                        'Type': CATEGORY_TYPES[cat], 'Drift (mm)': dist\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.groupby(['Group', 'Category'])['Drift (mm)'].mean().unstack().round(2))\n",
    "    return df\n",
    "\n",
    "df_drift = analyze_drift(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41cbfca5",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Group'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGroup\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mType\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRDM Stability (r)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39munstack()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[0;32m---> 44\u001b[0m df_rdm \u001b[38;5;241m=\u001b[39m \u001b[43manalyze_rdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgolarai_functional_final\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mANALYSIS_SUBJECTS\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 41\u001b[0m, in \u001b[0;36manalyze_rdm\u001b[0;34m(functional_results, subjects, min_voxels)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;28;01mexcept\u001b[39;00m: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     40\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(data)\n\u001b[0;32m---> 41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGroup\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mType\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRDM Stability (r)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39munstack()\u001b[38;5;241m.\u001b[39mround(\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/core/frame.py:8402\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, squeeze, observed, dropna)\u001b[0m\n\u001b[1;32m   8399\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8400\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8403\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8405\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8406\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8407\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8408\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8410\u001b[0m \u001b[43m    \u001b[49m\u001b[43msqueeze\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8411\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8412\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8413\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/core/groupby/groupby.py:965\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, squeeze, observed, mutated, dropna)\u001b[0m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    963\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgroupby\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgrouper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_grouper\n\u001b[0;32m--> 965\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmutated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmutated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    977\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/anaconda3/envs/fmri/lib/python3.9/site-packages/pandas/core/groupby/grouper.py:888\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, mutated, validate, dropna)\u001b[0m\n\u001b[1;32m    886\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    887\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    891\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Group'"
     ]
    }
   ],
   "source": [
    "# CELL 7: RDM Stability (Geometry)\n",
    "def analyze_rdm(functional_results, subjects, min_voxels=30):\n",
    "    RDM_CATS = ['face', 'house', 'object', 'word']\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        info = subjects[sid]\n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        first, last = sessions[0], sessions[-1]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            # Iterate through every ROI (e.g. \"Left Face\")\n",
    "            if first not in roi_data or last not in roi_data: continue\n",
    "            \n",
    "            # Dynamic Masks\n",
    "            m1, m2 = roi_data[first]['roi_mask'], roi_data[last]['roi_mask']\n",
    "            if np.sum(m1) < min_voxels or np.sum(m2) < min_voxels: continue\n",
    "            \n",
    "            # Build RDMs\n",
    "            try:\n",
    "                feats1 = [nib.load(BASE_DIR/sid/f'ses-{first}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/'zstat1.nii.gz').get_fdata()[m1] for c in RDM_CATS]\n",
    "                feats2 = [nib.load(BASE_DIR/sid/f'ses-{last}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/f'zstat1_ses{first}.nii.gz').get_fdata()[m2] for c in RDM_CATS]\n",
    "                \n",
    "                # Correlate & Sanitize\n",
    "                rdm1 = 1 - np.corrcoef(np.array(feats1))\n",
    "                rdm2 = 1 - np.corrcoef(np.array(feats2))\n",
    "                rdm1 = (rdm1 + rdm1.T)/2; np.fill_diagonal(rdm1, 0)\n",
    "                rdm2 = (rdm2 + rdm2.T)/2; np.fill_diagonal(rdm2, 0)\n",
    "                \n",
    "                corr = np.corrcoef(squareform(rdm1), squareform(rdm2))[0,1]\n",
    "                \n",
    "                data.append({\n",
    "                    'Group': info['group'], 'Type': CATEGORY_TYPES[roi_name.split('_')[1]],\n",
    "                    'RDM Stability (r)': corr\n",
    "                })\n",
    "            except: pass\n",
    "            \n",
    "    df = pd.DataFrame(data)\n",
    "    print(df.groupby(['Group', 'Type'])['RDM Stability (r)'].mean().unstack().round(3))\n",
    "    return df\n",
    "\n",
    "df_rdm = analyze_rdm(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5a8dca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 1: Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246667c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pattern directory: /user_data/csimmon2/long_pt/results/patterns\n",
      "Output directory: /user_data/csimmon2/long_pt/results/decoding\n",
      "Found 0 pattern files\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Paths\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "PATTERN_DIR = BASE_DIR / \"results\" / \"patterns\"  # From Cell 8 output\n",
    "OUTPUT_DIR = BASE_DIR / \"results\" / \"decoding\"\n",
    "RESULTS_DIR = Path(\"/user_data/csimmon2/git_repos/long_pt\") / \"results\" / \"decoding\"\n",
    "RESULTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SUBJECTS = {\n",
    "    'sub-004': {'code': 'UD', 'sessions': ['01', '02', '03', '05', '06']},\n",
    "    'sub-021': {'code': 'TC', 'sessions': ['01', '02', '03']}\n",
    "}\n",
    "\n",
    "print(f\"Pattern directory: {PATTERN_DIR}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")\n",
    "\n",
    "# Verify patterns exist\n",
    "pattern_files = list(PATTERN_DIR.glob('*.npy'))\n",
    "print(f\"Found {len(pattern_files)} pattern files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51d2b649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 900 pattern files in: /user_data/csimmon2/long_pt/analyses/rsa_corrected/patterns\n",
      "Example: UD_ses-05_run-2_house_pair-1_Scramble.npy\n"
     ]
    }
   ],
   "source": [
    "# Run this\n",
    "import os\n",
    "for root, dirs, files in os.walk('/user_data/csimmon2/long_pt'):\n",
    "    npy_files = [f for f in files if f.endswith('.npy') and 'UD_ses' in f]\n",
    "    if npy_files:\n",
    "        print(f\"Found {len(npy_files)} pattern files in: {root}\")\n",
    "        print(f\"Example: {npy_files[0]}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "189837e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UD: Decoding in 0 ROIs across 5 sessions\n",
      "\n",
      "TC: Decoding in 0 ROIs across 3 sessions\n",
      "\n",
      "✓ Decoding complete - saved to /user_data/csimmon2/git_repos/long_pt/results/decoding\n",
      "\n",
      "✓ Decoding complete\n",
      "UD: 0 results\n",
      "TC: 0 results\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Category Decoding Function\n",
    "def decode_categories(subject_id, n_folds=30, test_size=0.2):\n",
    "    \"\"\"\n",
    "    Classify each category vs. others using SVM\n",
    "    Combines patterns across all 3 run pairs\n",
    "    \"\"\"\n",
    "    code = SUBJECTS[subject_id]['code']\n",
    "    sessions = SUBJECTS[subject_id]['sessions']\n",
    "    stim_conditions = ['Face', 'House', 'Object', 'Word']\n",
    "    pair_to_leftout_run = {0: 3, 1: 2, 2: 1}\n",
    "    \n",
    "    # Get all ROI categories from pattern files\n",
    "    roi_categories = []\n",
    "    for f in PATTERN_DIR.glob(f'{code}_*.npy'):\n",
    "        parts = f.stem.split('_')\n",
    "        roi = parts[3]  # e.g., 'face', 'word', etc.\n",
    "        if roi not in roi_categories:\n",
    "            roi_categories.append(roi)\n",
    "    \n",
    "    print(f\"\\n{code}: Decoding in {len(roi_categories)} ROIs across {len(sessions)} sessions\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for roi_category in roi_categories:\n",
    "        for session in sessions:\n",
    "            print(f\"  {roi_category.upper()} ROI, ses-{session}:\")\n",
    "            \n",
    "            # Load patterns from all 3 pairs\n",
    "            all_patterns = {cond: [] for cond in stim_conditions}\n",
    "            \n",
    "            for pair_idx in range(3):\n",
    "                run_idx = pair_to_leftout_run[pair_idx]\n",
    "                \n",
    "                for stim_cond in stim_conditions:\n",
    "                    pattern_file = PATTERN_DIR / f'{code}_ses-{session}_run-{run_idx}_{roi_category}_pair-{pair_idx}_{stim_cond}.npy'\n",
    "                    \n",
    "                    if pattern_file.exists():\n",
    "                        blocks = np.load(pattern_file)\n",
    "                        for block in blocks:\n",
    "                            all_patterns[stim_cond].append(block)\n",
    "            \n",
    "            # Decode each category vs. others\n",
    "            for target in stim_conditions:\n",
    "                target_key = target\n",
    "                \n",
    "                # Get target and distractor patterns\n",
    "                X_target = np.array(all_patterns[target_key])\n",
    "                X_others = []\n",
    "                for cond in stim_conditions:\n",
    "                    if cond != target:\n",
    "                        X_others.extend(all_patterns[cond])\n",
    "                X_others = np.array(X_others)\n",
    "                \n",
    "                if len(X_target) < 3 or len(X_others) < 3:\n",
    "                    print(f\"    {target}: insufficient data\")\n",
    "                    continue\n",
    "                \n",
    "                # Combine and create labels\n",
    "                X = np.vstack([X_target, X_others])\n",
    "                y = np.array([1]*len(X_target) + [0]*len(X_others))\n",
    "                \n",
    "                # Remove NaN columns\n",
    "                valid_mask = ~np.isnan(X).any(axis=0)\n",
    "                X_clean = X[:, valid_mask]\n",
    "                \n",
    "                if X_clean.shape[1] < 10:\n",
    "                    print(f\"    {target}: too few voxels\")\n",
    "                    continue\n",
    "                \n",
    "                # Stratified shuffle split\n",
    "                sss = StratifiedShuffleSplit(n_splits=n_folds, test_size=test_size, random_state=42)\n",
    "                \n",
    "                accuracies = []\n",
    "                clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "                \n",
    "                for train_idx, test_idx in sss.split(X_clean, y):\n",
    "                    X_train, X_test = X_clean[train_idx], X_clean[test_idx]\n",
    "                    y_train, y_test = y[train_idx], y[test_idx]\n",
    "                    \n",
    "                    clf.fit(X_train, y_train)\n",
    "                    accuracies.append(clf.score(X_test, y_test))\n",
    "                \n",
    "                acc_mean = np.mean(accuracies)\n",
    "                acc_std = np.std(accuracies)\n",
    "                \n",
    "                results.append({\n",
    "                    'subject': code,\n",
    "                    'roi': roi_category,\n",
    "                    'session': session,\n",
    "                    'target_category': target.lower(),\n",
    "                    'accuracy': acc_mean,\n",
    "                    'se': acc_std,\n",
    "                    'n_voxels': X_clean.shape[1],\n",
    "                    'n_target': len(X_target),\n",
    "                    'n_others': len(X_others)\n",
    "                })\n",
    "                \n",
    "                print(f\"    {target}: {acc_mean:.3f} ± {acc_std:.3f} ({X_clean.shape[1]} voxels)\")\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run decoding\n",
    "ud_decoding = decode_categories('sub-004', n_folds=30, test_size=0.2)\n",
    "tc_decoding = decode_categories('sub-021', n_folds=30, test_size=0.2)\n",
    "\n",
    "# Save results\n",
    "# At the end of Cell 3, change save lines:\n",
    "ud_decoding.to_csv(RESULTS_DIR / 'ud_decoding.csv', index=False)\n",
    "tc_decoding.to_csv(RESULTS_DIR / 'tc_decoding.csv', index=False)\n",
    "\n",
    "print(f\"\\n✓ Decoding complete - saved to {RESULTS_DIR}\")\n",
    "print(f\"\\n✓ Decoding complete\")\n",
    "print(f\"UD: {len(ud_decoding)} results\")\n",
    "print(f\"TC: {len(tc_decoding)} results\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dd6fd5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ CSV loaded and configuration set\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Load CSV and Basic Setup\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from nilearn import plotting, image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load subject info from CSV\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "OUTPUT_DIR = BASE_DIR / \"analyses\" / \"rsa_corrected\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Session start mapping (for special cases)\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# Cope mapping: Key -> (Cope Number, Multiplier)\n",
    "# Multiplier 1  = Use contrast as is (e.g., Face > Scramble)\n",
    "# Multiplier -1 = Invert contrast (e.g., Face > Word becomes Word > Face)\n",
    "\n",
    "COPE_MAP = {\n",
    "    'face':   (10, 1),   # Face > Scramble\n",
    "    'word':   (13, -1),  # Face > Word (INVERTED to create Word > Face)\n",
    "    'object': (3,  1),   # Object > Scramble\n",
    "    'house':  (11, 1)    # House > Scramble\n",
    "}\n",
    "\n",
    "# Parcels are touchy. \n",
    "CATEGORY_PARCELS = {\n",
    "    'face': ['fusiform'],\n",
    "    'word': ['fusiform', 'inferiortemporal'], # needed to add IT to capture VWFA\n",
    "    'object': ['lateraloccipital'],\n",
    "    'house': ['parahippocampal', 'lingual', 'isthmuscingulate']\n",
    "}\n",
    "\n",
    "print(\"✓ CSV loaded and configuration set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3c49762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STREAMLINED SUBJECT LOADING COMPLETE\n",
      "==================================================\n",
      "Patients loaded: 16\n",
      "  - OTC: 7\n",
      "  - nonOTC: 9\n",
      "Controls loaded: 9\n",
      "Total analysis subjects: 25\n",
      "\n",
      "CORRECT CATEGORY_PARCELS:\n",
      "  face  : ['fusiform']\n",
      "  word  : ['fusiform', 'inferiortemporal']\n",
      "  object: ['lateraloccipital']\n",
      "  house : ['parahippocampal', 'lingual', 'isthmuscingulate']\n",
      "\n",
      "Sample subjects:\n",
      "  OTC004: OTC patient, hemi='l'\n",
      "  nonOTC007: nonOTC patient, hemi='r'\n",
      "  OTC008: OTC patient, hemi='l'\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Streamlined Subject Loading and Configuration\n",
    "def load_subjects_by_group(group_filter=None, patient_only=True):\n",
    "    \"\"\"Streamlined subject loading with proper configuration\"\"\"\n",
    "    \n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if patient_only is True:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 1]\n",
    "    elif patient_only is False:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 0]\n",
    "    \n",
    "    if group_filter:\n",
    "        if isinstance(group_filter, str):\n",
    "            group_filter = [group_filter]\n",
    "        filtered_df = filtered_df[filtered_df['group'].isin(group_filter)]\n",
    "    \n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in filtered_df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        \n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "            \n",
    "        # Get available sessions\n",
    "        sessions = []\n",
    "        for ses_dir in subj_dir.glob('ses-*'):\n",
    "            if ses_dir.is_dir():\n",
    "                sessions.append(ses_dir.name.replace('ses-', ''))\n",
    "        \n",
    "        if not sessions:\n",
    "            continue\n",
    "            \n",
    "        sessions = sorted(sessions, key=lambda x: int(x))\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        available_sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        \n",
    "        if not available_sessions:\n",
    "            continue\n",
    "        \n",
    "        # Proper hemisphere mapping\n",
    "        if row['patient'] == 1:  # Patients\n",
    "            hemisphere_full = row.get('intact_hemi', 'left')\n",
    "            hemisphere = 'l' if hemisphere_full == 'left' else 'r'\n",
    "        else:  # Controls \n",
    "            hemisphere = 'r'  # Default for controls (we'll add bilateral later)\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': available_sessions,\n",
    "            'hemi': hemisphere,\n",
    "            'group': row['group'],\n",
    "            'patient_status': 'patient' if row['patient'] == 1 else 'control',\n",
    "            'age_1': row['age_1'] if pd.notna(row['age_1']) else None,\n",
    "            'surgery_side': row.get('SurgerySide', None) if row['patient'] == 1 else None\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "# Load subjects systematically\n",
    "ALL_PATIENTS = load_subjects_by_group(group_filter=None, patient_only=True)\n",
    "OTC_PATIENTS = load_subjects_by_group(group_filter='OTC', patient_only=True)\n",
    "NON_OTC_PATIENTS = load_subjects_by_group(group_filter='nonOTC', patient_only=True)\n",
    "ALL_CONTROLS = load_subjects_by_group(group_filter=None, patient_only=False)\n",
    "\n",
    "# Start with original subjects only\n",
    "ANALYSIS_SUBJECTS = {**ALL_PATIENTS, **ALL_CONTROLS}\n",
    "\n",
    "print(\"STREAMLINED SUBJECT LOADING COMPLETE\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Patients loaded: {len(ALL_PATIENTS)}\")\n",
    "print(f\"  - OTC: {len(OTC_PATIENTS)}\")\n",
    "print(f\"  - nonOTC: {len(NON_OTC_PATIENTS)}\")\n",
    "print(f\"Controls loaded: {len(ALL_CONTROLS)}\")\n",
    "print(f\"Total analysis subjects: {len(ANALYSIS_SUBJECTS)}\")\n",
    "\n",
    "print(f\"\\nCORRECT CATEGORY_PARCELS:\")\n",
    "for category, parcels in CATEGORY_PARCELS.items():\n",
    "    print(f\"  {category:6s}: {parcels}\")\n",
    "\n",
    "print(f\"\\nSample subjects:\")\n",
    "for subj_id, info in list(ANALYSIS_SUBJECTS.items())[:3]:\n",
    "    print(f\"  {info['code']}: {info['group']} {info['patient_status']}, hemi='{info['hemi']}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e20ec6d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-running extraction...\n",
      "✓ Extraction Complete: 24 subjects.\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Functional ROI Extraction (FIXED IMPORTS)\n",
    "from scipy.ndimage import label, center_of_mass \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def extract_functional_rois_bilateral(subject_id, threshold_z=2.3, min_cluster_size=30):\n",
    "    info = ANALYSIS_SUBJECTS[subject_id]\n",
    "    roi_dir = BASE_DIR / subject_id / f'ses-{info[\"sessions\"][0]}' / 'ROIs'\n",
    "    if not roi_dir.exists(): return {}\n",
    "    \n",
    "    all_results = {}\n",
    "    first_session = info['sessions'][0]\n",
    "\n",
    "    for hemi in ['l', 'r']:\n",
    "        for category, cope_params in COPE_MAP.items():\n",
    "            # Unpack Tuple\n",
    "            cope_num, multiplier = cope_params if isinstance(cope_params, tuple) else (cope_params, 1)\n",
    "            \n",
    "            # Load Search Mask\n",
    "            mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "            if not mask_file.exists(): continue\n",
    "            \n",
    "            try:\n",
    "                search_mask = nib.load(mask_file).get_fdata() > 0\n",
    "                affine = nib.load(mask_file).affine\n",
    "            except: continue\n",
    "            \n",
    "            hemi_key = f'{hemi}_{category}'\n",
    "            all_results[hemi_key] = {}\n",
    "            \n",
    "            for session in info['sessions']:\n",
    "                feat_dir = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                z_name = 'zstat1.nii.gz' if session == first_session else f'zstat1_ses{first_session}.nii.gz'\n",
    "                cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                \n",
    "                if not cope_file.exists(): continue\n",
    "                \n",
    "                try:\n",
    "                    # Load & Invert\n",
    "                    zstat = nib.load(cope_file).get_fdata() * multiplier\n",
    "                    \n",
    "                    # Threshold\n",
    "                    suprathresh = (zstat > threshold_z) & search_mask\n",
    "                    \n",
    "                    # Cluster & Filter\n",
    "                    labeled, n_clusters = label(suprathresh) # <--- This is where it failed\n",
    "                    if n_clusters == 0: continue\n",
    "                    \n",
    "                    best_idx = -1\n",
    "                    max_peak = -999\n",
    "                    \n",
    "                    for i in range(1, n_clusters + 1):\n",
    "                        cluster_mask = (labeled == i)\n",
    "                        if np.sum(cluster_mask) >= min_cluster_size:\n",
    "                            peak_val = np.max(zstat[cluster_mask])\n",
    "                            if peak_val > max_peak:\n",
    "                                max_peak = peak_val\n",
    "                                best_idx = i\n",
    "                    \n",
    "                    if best_idx == -1: continue \n",
    "                    \n",
    "                    # Save Result\n",
    "                    roi_mask = (labeled == best_idx)\n",
    "                    peak_idx = np.unravel_index(np.argmax(zstat * roi_mask), zstat.shape)\n",
    "                    \n",
    "                    all_results[hemi_key][session] = {\n",
    "                        'n_voxels': int(np.sum(roi_mask)),\n",
    "                        'peak_z': zstat[peak_idx],\n",
    "                        'centroid': nib.affines.apply_affine(affine, center_of_mass(roi_mask)),\n",
    "                        'roi_mask': roi_mask\n",
    "                    }\n",
    "                except Exception as e: print(f\"Err {subject_id} {category}: {e}\")\n",
    "\n",
    "    return all_results\n",
    "\n",
    "# EXECUTE\n",
    "print(\"Re-running extraction...\")\n",
    "golarai_functional_final = {}\n",
    "for sub in ANALYSIS_SUBJECTS:\n",
    "    res = extract_functional_rois_bilateral(sub, min_cluster_size=30)\n",
    "    if res: golarai_functional_final[sub] = res\n",
    "print(f\"✓ Extraction Complete: {len(golarai_functional_final)} subjects.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b1116f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ROI SELECTIVITY CHECK\n",
      "========================================\n",
      "\n",
      ">> OTC004:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  l_face    : ✓ Top=face (Target: 2.67)\n",
      "  l_house   : ✓ Top=house (Target: 3.08)\n",
      "  l_object  : ✓ Top=object (Target: 3.53)\n",
      "  l_word    : ✓ Top=word (Target: 2.81)\n",
      "\n",
      ">> control025:\n",
      "  l_face    : ✓ Top=face (Target: 6.56)\n",
      "  l_house   : ✓ Top=house (Target: 4.29)\n",
      "  l_object  : ✓ Top=object (Target: 5.16)\n",
      "  l_word    : ✓ Top=word (Target: 4.15)\n",
      "  r_face    : ✓ Top=face (Target: 5.65)\n",
      "  r_house   : ✓ Top=house (Target: 4.22)\n",
      "  r_object  : ✓ Top=object (Target: 5.00)\n",
      "  r_word    : ✓ Top=word (Target: 3.28)\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Verify Selectivity (Tuple Corrected)\n",
    "def verify_roi_selectivity(functional_results, subjects, sample_ids=['OTC004', 'control025']):\n",
    "    print(\"\\nROI SELECTIVITY CHECK\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    for pid in sample_ids:\n",
    "        # Find full ID\n",
    "        sid = next((k for k,v in subjects.items() if v['code'] == pid), None)\n",
    "        if not sid or sid not in functional_results: continue\n",
    "        \n",
    "        print(f\"\\n>> {pid}:\")\n",
    "        res = functional_results[sid]\n",
    "        first_ses = subjects[sid]['sessions'][0]\n",
    "        \n",
    "        for roi_name in sorted(res.keys()):\n",
    "            if first_ses not in res[roi_name]: continue\n",
    "            roi_mask = res[roi_name][first_ses]['roi_mask']\n",
    "            target_cat = roi_name.split('_')[1]\n",
    "            \n",
    "            scores = {}\n",
    "            feat_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "            \n",
    "            for cat, (cope, mult) in COPE_MAP.items():\n",
    "                f = feat_dir / f'cope{cope}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "                if f.exists():\n",
    "                    d = nib.load(f).get_fdata() * mult\n",
    "                    scores[cat] = np.mean(d[roi_mask])\n",
    "            \n",
    "            top = max(scores, key=scores.get)\n",
    "            mark = \"✓\" if top == target_cat else \"✗\"\n",
    "            print(f\"  {roi_name:10s}: {mark} Top={top} (Target: {scores.get(target_cat,0):.2f})\")\n",
    "            \n",
    "verify_roi_selectivity(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84924c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAArMAAAHUCAYAAAAp/qBkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLNElEQVR4nO3deXQUVf7+8aezk4SEEMgCxBA2wQEGCQ6bCIiGTRZRRAXDKgKyBFAUGXYZxoUA6rCoBFARUEZHRBRRdnCBAKIDgyBbgACyJRAga/3+4Jv+pcnWgQ6dCu/XOX1O161bVZ9q2j6PN7eqLIZhGAIAAABMyMXZBQAAAAA3izALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALlCKTJk2SxWKRxWJRnz59cq1v1aqVdf2iRYtu6hhVq1a17sMRctZ05MgRhx//zJkzGjFihGrWrCkvLy/5+PioSpUqat68uQYPHqzExESb/pMmTdKkSZM0a9asmzib/+/IkSPWOlu1alVo/w0bNuT5b9enTx9r+4YNG6zt2W1Vq1YtlvoL07dvX1ksFtWvX1/ZD5LMec75vf7zn/9Y9+Ho79LNKkodixYtynVOrq6uKl++vFq3bq2lS5fmu+2ePXs0YMAA1axZU97e3vL29lbNmjU1YMAA/fLLLwUeK+d3aPv27db2TZs23dQ5A6WJm7MLAIDicvHiRTVu3DhXSL5y5YpOnDihbdu2qX///goNDbWumzx5siQpPDxcMTExt7Fax7gd9W/fvl2LFy+WJE2cONHpYdTZsrKydOHCBW3YsEEbNmzQ+fPn9fzzz9v0mTlzpl588UVlZmbatB88eFAHDx7UokWL9MYbb2jkyJGFHu++++5Thw4dtHr1ag0fPlw7d+6UiwtjU7hz8e0H4BRXrlyRdH1E0jAMGYaRa5TxVi1YsMAaZPv06aOTJ0/q2rVrOnjwoFasWKEePXrIy8vLoce8Wa1atbJ+DvaMmmf3tWc029H+8Y9/yDAMVapUSV27ds23X3aNOV85+x85csTabkYtW7aUYRi6cOGC+vbta22fPXu2Tb8vv/xSo0aNUmZmplxdXTVz5kxduHBBFy5cUGxsrFxcXJSZmalRo0Zp1apVdh178ODBkqRffvnF7m2A0oowC9zhHnzwQeufLPfu3WuzrnPnztZ1ef0Z9OjRo3r88cfl7++vsmXLqlu3brnCVc4/h//www9q2bKlfHx81KFDB0n5TzM4f/68+vfvr8DAQPn4+Ojhhx/Wnj17inRuv//+u/X9Qw89pNDQUHl6eqp69ep67LHHtGzZMtWtW1fS/5+ikfPcbvxTfmJionr27Km//OUvCgwMlLu7u/z8/NSoUSPFxsYqIyMj31o2btyoZs2aqUyZMgoJCVFMTIyuXr1qXZ/fNIP83FhbYfV/8MEH1uWXXnrJZl+fffaZdV1hI4PHjx/Xl19+KUl68skn5erqWmit+bnxz/upqamKjIy0/ul+69atkq6H4rZt21r7rlixwrqPM2fOaPTo0apdu7bKlCkjHx8f3XfffZo/f36ukOyI71ReypUrZzMKfvToUZv1EyZMsL4fPHiwYmJiVK5cOZUrV04jR47UwIED8+xbkHbt2ikwMFCSNGfOnFuoHigFDAClxsSJEw1JhiSjd+/euda3bNnSun7hwoWGYRjG6tWrrW2DBw+29j179qzh7u5uSDKaNGlibQ8PD7f2r1y5svV99qtKlSrG2bNnrf2z2729vY0yZcpYl1u2bJmrpsOHDxuGYRipqalGZGRkrn37+fkZvr6+1uXCvPrqq9a+Hh4exiOPPGJMnz7dWLdunXHlypV8P7sbX+Hh4YZhGMauXbvy7SPJGDhwoHV/hw8ftrZXrFjR+lnmfHXo0MHaf/369Xn+2/Xu3dvavn79+lyfa3ZthdWflpZmVKlSxZBklC9f3rh69ap1X48++qi17759+wr8TN977z1r35UrV9qsy3nO9vz75PwuZTt48KDh5+dnSDIiIiKM5ORkY+bMmdZ+Q4cOtfb9448/jNDQ0HzP+8knn7T2ddR3auHChbm+w4ZhGLt377b5byBbYmKizfF27dqVa5/x8fE2fU6dOlXgsbJ17tzZ+t2+8fsM3EkYmQVKqcWLF+e6UGXjxo25+rVv3946Ovnhhx8qOTlZkvTJJ58oPT1dkjRo0KA8j3Hvvffq1KlTOnLkiJo0aSLp+sjdm2++mavvlStX1KRJE/3+++9KSUkpcDRpyZIlio+PlyRVq1ZNe/bs0fnz59WzZ09dvnzZ7s8gexROktLS0rRq1SqNHTtWDz74oIKCgjR69GilpqZKuj6yaeQYyQsPD8/1p/xKlSrp3//+t44ePaqUlBSlpqZqz549qlKliqTr0xouXryYq44///xTf//735WUlKRt27apQoUKkqTVq1drzZo1dp9PQQqr393dXSNGjJB0fYTy448/lnR9XvHq1aslXR8lr127doHH+fHHH63v//rXvxbYN68LwApTvXp1vffee5Kkw4cPq0ePHnr55ZclSZGRkZoxY4a174gRI5SYmCg3Nzd9+umnunLlik6fPq3u3btLkpYtW6avvvpKkuO+U3m5ePGizQV3zzzzjPX9sWPHbPpWq1Ytz3PO6cZt8tOwYUNJ17/bO3futLdcoNQhzALQCy+8IEm6fPmydb7mRx99JEkKCAhQjx498txuxowZCg4OVnh4uPXCI0n69ttv8+y/ePFi65Xc99xzT7715Nx+5MiRqlevngICAvTGG2/Izc3+61ZDQkK0e/du9enTR+XLl7dZd/nyZcXGxmrcuHF27698+fI6fPiwHn/8cYWGhsrLy0v169fX8ePHJUmZmZnav39/ru0qVaqk8ePHy8/PT02bNtWzzz6b57kWt4EDB8rPz0+S9K9//UuS9Omnn1oDfX7/05JTzrs/VKxYsRiqlJ544glrLV9//bVSU1Pl7++vTz75RB4eHpKka9eu6ZtvvpEkZWRkqHv37vL29lZwcLA+/fRT676y+zjqO5XTxo0bZbFYFBAQoEWLFsnDw0MjRozQlClTrH2MYpwPnPPzv/GuHMCdhDALlFK9e/fOdfFNy5Yt8+z79NNPq3LlypKuz787dOiQtm3bZt1PfhdJhYeH5/n+zJkzufpWrFhRYWFhdtV+9uxZ6/uc2/j4+FhHNe1VpUoVLVy4UGfOnFF8fLxmzpypv/zlL9b1y5Yts3tfI0eO1AsvvKDt27crOTk5z6CScx5strvuustmVLKwz6q4+Pn5Wedn7ty5U9u2bdOSJUskSUFBQerWrZtDj3fj968owe6ll16yuUK/W7duNqOa586dK3COcrbs75Ijv1P5ycrKyvW9yPlvLUmHDh3Ktd0ff/xhs3zXXXc5pB7gTkGYBSB3d3cNHz5ckrR//34NGDDAuq6g0bqcF7rkfB8UFJSrr7e3t9315AwXCQkJ1vcpKSk2oaQwSUlJ1veurq5q2LChYmJibP60f+7cObv3lz1aLV2/aCo1NVWGYVj/3JufhIQEm4BT2GdVnGJiYuTu7i5JGjdunPU+pf3797e2FyTnbcz+/PPPYqkxKytL/fv3V1ZWlrVt8eLF+u6776zLgYGB1hHVsmXLWv8tbnxlT6dw1Hcqp5YtWyozM1O//vqr7r77bmVkZGjhwoUaO3astU9ISIgaNGhgXY6Li8u1nwULFljf33vvvQoODrbr+Dk//5CQkJs4A6B0IMwCkCQ999xzKlu2rCRp/fr1kqTWrVvr7rvvznebMWPG6PTp0zp27JgmTpxobY+KirqlWnJuP3PmTP3666+6ePGiXnzxRbtG47K9+eabuv/++/Xee+/pwIEDSktL04ULF2xufZVzlFaSdY7t2bNndeLECZt1Of8cXbZsWWVkZOjdd9/Vrl27CqzjxIkTmjZtmpKTk/Xjjz9a54TeeK6OUFD9klS5cmU99dRTkv7/bdFcXFxsrqgvSOPGja3vd+/efesF52Hy5Mlat26dJGnYsGGqUKGCsrKy1KtXL506dUqS5OXlpXbt2kmSLl26pH79+unIkSNKT09XQkKCFi9erObNm1vDuqO+UzdycXFR3bp19fHHH1tHkmfNmqV9+/bZnE+2uXPn6u2331ZSUpKSkpI0e/ZszZ8/P8++hcmeJ+vh4VHo/1ABpdrtutIMQPG7mbsZ5DR69Gibq6qXL1+eq8/N3s0g+6r7gmoq7G4G3t7ehre3t91Xno8bN67Auw+4uLgYX375pc02nTp1ytUv+7McNGhQnjVl3yVAOe44YM/dDNq3b29kZWUZhnHrdzOwp/5se/bsyVWHvY4dO2a4uLgYkoxRo0bZrHPE3Qy+//576/6bN29uZGRkGKtWrbL2a926tZGZmWkYhmEcOnQoz+9gzlf2Z+ao71RBdxjo06ePdV3Hjh1t1s2YMcNwdXXNt05XV1cjNjbW7mOlp6cbgYGBhiQjKiqq0LqB0oyRWQBWMTEx1tHH4OBgPfroowX237p1q7p166ayZcvK19dXXbt21ebNm62jgzfLw8ND3377rfr166eAgACVKVNGrVu31saNG4t00dEzzzyjKVOm6KGHHlJERIR8fX3l5uam0NBQde3aVevXr9cjjzxis83bb7+tTp065XkOM2bMUExMjCpVqiQvLy81bdpUa9euzXU1+o3uueceffvtt2ratKk8PT0VFBSkESNGaMWKFQ5/elZB9WerV6+e2rZta12258KvbGFhYerUqZOk6/ONc04FuFWnTp3S008/raysLPn5+emjjz6Sq6urOnbsaJ0Gs379eusFVhEREdq9e7fGjBmje+65R15eXipTpoyqVaumTp06ae7cudYRS0d9pwoybdo063Sar776ymZaxKhRoxQfH6/+/furevXq8vLykpeXl6pXr65+/fppx44ddj39K9s333xjnSIzZMgQh9QPmJXFMEz66BUADrdz5041atRIhmFowoQJRfqTJ8wjLS1N999/v7Zv366IiAgdOHCgSA8/+Pnnn9WkSRMZhqHPPvus0P/pgeN17NhRq1evVv369bVr1y4eZ4s7Gt9+AHrnnXdUs2ZNNW7cWIZhqGLFijZPNELpcOLECdWuXVvBwcHavn27JGnq1KlFforX3/72N/Xu3VtS7vvbovjt2LHDem/gt956iyCLOx7/BQDQ2bNndfDgQXl4eKhFixZas2aNAgICnF0WHCw9PV379+9XcnKyIiIiNHv2bPXs2fOm9rVw4UIZhqFffvnF4VMlULDsv54YBdxuD7iTMM0AAAAApsXILAAAAEyLMAsAAADTIswCAADAtNwK71K6ZGVl6eTJkypbtiwXLQAAAJRAhmHo0qVLqlSpUqF37LjjwuzJkycVFhbm7DIAAABQiISEBFWpUqXAPndcmM1+9nxCQoL8/PycXA0AAABulJycrLCwMGtuK8gdF2azpxb4+fkRZgEAAEowe6aEcgEYAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATIswCwAAANMizAIAAMC0CLMAAAAwLcIsAAAATMvN2QUApZFhGEpJSbEu+/j4yGKxOLEiAABKJ8IsUAxSUlLUpUsX6/IXX3whX19fJ1YEAEDpxDQDAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpuTm7AAAAUPIZhqGUlBTrso+PjywWixMrAq4jzAIAgEKlpKSoS5cu1uUvvvhCvr6+TqwIuI5pBgAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAt7mYA0+q97mtnl5CvrGvXbJYHb1orFy8vJ1VTuMUPtnd2CQAA3BRGZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGlxARiAEo3nwQMACkKYBVCi8Tx4AEBBmGYAAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLScHmbnzJmjiIgIeXl5KTIyUps3by6w/5IlS/TXv/5V3t7eCg0NVd++fXXu3LnbVC0AAABKEqfeZ3b58uWKiYnRnDlz1Lx5c82fP1/t27fX3r17ddddd+Xqv2XLFkVHR2vmzJnq1KmTTpw4oUGDBmnAgAH6/PPPnXAGAAA4Tu91Xzu7hHxlXbtmszx401q5eHk5qZrCLX6wvbNLwG3i1JHZ2NhY9e/fXwMGDFCdOnU0a9YshYWFae7cuXn2//HHH1W1alUNHz5cERERuv/++/Xcc89px44dt7lyAAAAlAROC7NpaWmKj49XVFSUTXtUVJS2bduW5zbNmjXT8ePHtXr1ahmGodOnT2vFihXq2LFjvsdJTU1VcnKyzQsAAAClg9PC7NmzZ5WZmang4GCb9uDgYJ06dSrPbZo1a6YlS5aoR48e8vDwUEhIiMqVK6e333473+NMnz5d/v7+1ldYWJhDzwMAAADO4/QLwCwWi82yYRi52rLt3btXw4cP14QJExQfH69vvvlGhw8f1qBBg/Ld/9ixY5WUlGR9JSQkOLR+AAAAOI/TLgCrUKGCXF1dc43CnjlzJtdobbbp06erefPmevHFFyVJ9evXl4+Pj1q0aKFXX31VoaGhubbx9PSUp6en408AAAAATue0kVkPDw9FRkZq7dq1Nu1r165Vs2bN8tzmypUrcnGxLdnV1VXS9RFdAAAA3FmcOs1g1KhRev/99xUXF6d9+/Zp5MiROnbsmHXawNixYxUdHW3t36lTJ3322WeaO3euDh06pK1bt2r48OH629/+pkqVKjnrNAAAAOAkTr3PbI8ePXTu3DlNmTJFiYmJqlu3rlavXq3w8HBJUmJioo4dO2bt36dPH126dEnvvPOORo8erXLlyunBBx/Ua6+95qxTAAAAgBM5NcxK0pAhQzRkyJA81y1atChX27BhwzRs2LBirgoAAABm4PS7GQAAAAA3izALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLScfp9ZoDSyeHqq0uihNssAAMDxCLNAMbBYLLJ4eTm7DLvN+2iJs0vIV1pqqs1y3PJP5FFC/+dgUK+ezi4BAO44TDMAAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmxQVgAACgUNylBSUVYRYAABTKbHdpwZ2DaQYAAAAwLUZmAQAAbiPDMJSSkmJd9vHxkcVicWJF5kaYBQAAuI1SUlLUpUsX6/IXX3whX19fJ1ZkbkwzAAAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYlpuzC0DJYhiGUlJSrMs+Pj6yWCxOrAgAACB/hFnYSElJUZcuXazLX3zxhXx9fZ1YEQAAQP6YZgAAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADT4m4GAEo0dw8PdXm6p80yAADZCLMASjSLxSIPT09nlwEAKKGYZgAAAADTIswCAADAtJhmAAAASp15Hy1xdgn5SktNtVmOW/5JiZ1ONahXz8I7ORkjswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAtN2cXAABAcTIMQykpKdZlHx8fWSwWJ1YEwJEIswCAUi0lJUVdunSxLn/xxRfy9fV1YkUAHIlpBgAAADAtwiwAAABMizALAAAA0yLMAgAAwLQIswAAADAt7mYAAABwG7l7eKjL0z1tlnHzCLMAAAC3kcVikYenp7PLKDWYZgAAAADTIswCAADAtAizAAAAMC3CLAAAAEzL6WF2zpw5ioiIkJeXlyIjI7V58+YC+6empmrcuHEKDw+Xp6enqlevrri4uNtULQAAAEoSp97NYPny5YqJidGcOXPUvHlzzZ8/X+3bt9fevXt111135bnNE088odOnT2vBggWqUaOGzpw5o4yMjNtcOQAAAEoCp4bZ2NhY9e/fXwMGDJAkzZo1S2vWrNHcuXM1ffr0XP2/+eYbbdy4UYcOHVL58uUlSVWrVr2dJQMAAKAEcdo0g7S0NMXHxysqKsqmPSoqStu2bctzm5UrV6pRo0Z6/fXXVblyZdWqVUsvvPCCrl69mu9xUlNTlZycbPMCAABA6eC0kdmzZ88qMzNTwcHBNu3BwcE6depUntscOnRIW7ZskZeXlz7//HOdPXtWQ4YM0fnz5/OdNzt9+nRNnjzZ4fUDAADA+Zx+AZjFYrFZNgwjV1u2rKwsWSwWLVmyRH/729/UoUMHxcbGatGiRfmOzo4dO1ZJSUnWV0JCgsPPAQAAAM7htJHZChUqyNXVNdco7JkzZ3KN1mYLDQ1V5cqV5e/vb22rU6eODMPQ8ePHVbNmzVzbeHp6ypNHxgEAAJRKThuZ9fDwUGRkpNauXWvTvnbtWjVr1izPbZo3b66TJ0/q8uXL1rbff/9dLi4uqlKlSrHWCwAAgJLHqdMMRo0apffff19xcXHat2+fRo4cqWPHjmnQoEGSrk8RiI6OtvZ/+umnFRgYqL59+2rv3r3atGmTXnzxRfXr109lypRx1mkAAADASZx6a64ePXro3LlzmjJlihITE1W3bl2tXr1a4eHhkqTExEQdO3bM2t/X11dr167VsGHD1KhRIwUGBuqJJ57Qq6++6qxTAAAAgBM5NcxK0pAhQzRkyJA81y1atChXW+3atXNNTQAAAMCdyel3MwAAAABuFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAAplWkx9nu379fS5cu1ebNm3XkyBFduXJFFStW1L333qu2bdvqsccek6enZ3HVCgAAANiwa2R2165devjhh/XXv/5VmzZt0n333aeYmBhNnTpVvXr1kmEYGjdunCpVqqTXXntNqampxV03AAAAYN/IbNeuXfXiiy9q+fLlKl++fL79fvjhB82cOVMzZszQK6+84rAiAQAAgLzYFWYPHDggDw+PQvs1bdpUTZs2VVpa2i0XBgAAABTGrmkG2UE2PT1drVu31u+//25XfwAAAKA4FeluBu7u7vrtt99ksViKqx4AAADAbkW+NVd0dLQWLFhQHLUAAAAARVKkW3NJUlpamt5//32tXbtWjRo1ko+Pj8362NhYhxUHAAAAFKTIYfa3335Tw4YNJSnX3FmmHwAAAOB2KnKYXb9+fXHUAQAAABRZkcMsbs35CROcXUKBUjIybJYv/OMfSnMroV+TVk2dXQEAAHAyuy4AGzRokBISEuza4fLly7VkyZJbKgoAAACwh11DbhUrVlTdunXVrFkzde7cWY0aNVKlSpXk5eWlCxcuaO/evdqyZYuWLVumypUr69133y3uugEAAAD7wuzUqVM1bNgwLViwQPPmzdNvv/1ms75s2bJ66KGH9P777ysqKqpYCgUAAABuZPdkyKCgII0dO1Zjx47VxYsXdfToUV29elUVKlRQ9erVuZMBAAAAbruburKnXLlyKleunINLAQAAAIqmyE8AAwAAAEoKwiwAAABMq4TeQBQAYBbcP9uBuH82UGSMzAIAAMC0ihxmJ02apKNHjxZHLQAAAECRFDnMfvnll6pevbratGmjjz/+WNeuXSuOugAAAIBCFTnMxsfHa+fOnapfv75Gjhyp0NBQDR48WNu3by+O+gAAAIB83dSc2fr162vmzJk6ceKE4uLidOLECTVv3lz16tXT7NmzlZSU5Og6AQAAgFxu6QKwrKwspaWlKTU1VYZhqHz58po7d67CwsK0fPlyR9UIAAAA5Ommwmx8fLyGDh2q0NBQjRw5Uvfee6/27dunjRs36n//+58mTpyo4cOHO7pWAAAAwEaRw2z9+vXVpEkTHT58WAsWLFBCQoL++c9/qkaNGtY+0dHR+vPPPx1aKAAAAHCjIt81unv37urXr58qV66cb5+KFSsqKyvrlgoDAAAAClPkkVnDMBQQEJCr/erVq5oyZYpDigIAAADsUeQwO3nyZF2+fDlX+5UrVzR58mSHFAUAAADY46ZGZi0WS672X375ReXLl3dIUQAAAIA97J4zGxAQIIvFIovFolq1atkE2szMTF2+fFmDBg0qliIBAACAvNgdZmfNmiXDMNSvXz9NnjxZ/v7+1nUeHh6qWrWqmjZtWixFAgAAAHmxO8z27t1bkhQREaFmzZrJ3d292IoCAAAA7GFXmE1OTpafn58k6d5779XVq1d19erVPPtm9wMAAACKm11hNiAgQImJiQoKClK5cuXyvAAs+8KwzMxMhxcJAAAA5MWuMLtu3TrrnQrWr19frAUBAAAA9rIrzLZs2TLP9wAAAIAz2RVm9+zZY/cO69evf9PFAAAAAEVhV5ht0KCBLBaLDMMosB9zZgEAAHA72RVmDx8+XNx1AAAAAEVmV5gNDw8v7joAAACAIrMrzK5cuVLt27eXu7u7Vq5cWWDfzp07O6QwAAAAoDB2hdmuXbvq1KlTCgoKUteuXfPtx5xZAAAA3E52hdmsrKw83wMAAADO5OLsAgAAAICbdVNh9vvvv9cjjzyi6tWrq0aNGnrkkUf03XffObo2AAAAoEBFDrPvvPOO2rVrp7Jly2rEiBEaPny4/Pz81KFDB73zzjvFUSMAAACQJ7vmzOY0ffp0zZw5U0OHDrW2DR8+XM2bN9e0adNs2gEAAIDiVOSR2eTkZLVr1y5Xe1RUlJKTkx1SFAAAAGCPIofZzp076/PPP8/V/sUXX6hTp04OKQoAAACwh13TDN566y3r+zp16mjatGnasGGDmjZtKkn68ccftXXrVo0ePbp4qgQAAADyYFeYnTlzps1yQECA9u7dq71791rbypUrp7i4OP397393bIUAAABAPuwKs4cPHy7uOgAAAIAi46EJAAAAMK0i35pLko4fP66VK1fq2LFjSktLs1kXGxvrkMIAAACAwhQ5zH7//ffq3LmzIiIitH//ftWtW1dHjhyRYRhq2LBhcdQIAAAA5KnI0wzGjh2r0aNH67fffpOXl5f+/e9/KyEhQS1btlT37t2Lo0YAAAAgT0UOs/v27VPv3r0lSW5ubrp69ap8fX01ZcoUvfbaaw4vEAAAAMhPkcOsj4+PUlNTJUmVKlXSH3/8YV139uxZx1UGAAAAFKLIc2abNGmirVu36p577lHHjh01evRo/frrr/rss8/UpEmT4qgRAAAAyFORR2ZjY2PVuHFjSdKkSZP08MMPa/ny5QoPD9eCBQuKXMCcOXMUEREhLy8vRUZGavPmzXZtt3XrVrm5ualBgwZFPiYAAABKhyKPzFarVs363tvbW3PmzLnpgy9fvlwxMTGaM2eOmjdvrvnz56t9+/bau3ev7rrrrny3S0pKUnR0tNq0aaPTp0/f9PEBAABgbkUema1WrZrOnTuXq/3ixYs2QdcesbGx6t+/vwYMGKA6depo1qxZCgsL09y5cwvc7rnnntPTTz+tpk2bFul4AAAAKF2KHGaPHDmizMzMXO2pqak6ceKE3ftJS0tTfHy8oqKibNqjoqK0bdu2fLdbuHCh/vjjD02cONGu46Smpio5OdnmBQAAgNLB7mkGK1eutL5fs2aN/P39rcuZmZn6/vvvVbVqVbsPfPbsWWVmZio4ONimPTg4WKdOncpzmwMHDujll1/W5s2b5eZmX+nTp0/X5MmT7a4LAAAA5mF3mO3ataskyWKxWO8zm83d3V1Vq1bVjBkzilyAxWKxWTYMI1ebdD0wP/3005o8ebJq1apl9/7Hjh2rUaNGWZeTk5MVFhZW5DoBAABQ8tgdZrOysiRJERER2r59uypUqHBLB65QoYJcXV1zjcKeOXMm12itJF26dEk7duzQrl27NHToUGtNhmHIzc1N3377rR588MFc23l6esrT0/OWagUAAEDJVOS7GRw+fNghB/bw8FBkZKTWrl2rRx991Nq+du1adenSJVd/Pz8//frrrzZtc+bM0bp167RixQpFREQ4pC4AAACYh90XgP3000/6+uuvbdo++OADRUREKCgoSAMHDrQ+Gcxeo0aN0vvvv6+4uDjt27dPI0eO1LFjxzRo0CBJ16cIREdHXy/UxUV169a1eQUFBcnLy0t169aVj49PkY4NAAAA87N7ZHbSpElq1aqV2rdvL0n69ddf1b9/f/Xp00d16tTRG2+8oUqVKmnSpEl2H7xHjx46d+6cpkyZosTERNWtW1erV69WeHi4JCkxMVHHjh0r2hkBAADgjmF3mN29e7emTp1qXV62bJkaN26s9957T5IUFhamiRMnFinMStKQIUM0ZMiQPNctWrSowG0nTZpU5OMBAO4s3q6uWvR/T67MXgZQetgdZi9cuGBzYdbGjRvVrl076/J9992nhIQEx1YHAMAtslgs8rHzdo4AzMfuObPBwcHWi7/S0tK0c+dOmydwXbp0Se7u7o6vEAAAAMiH3WG2Xbt21gcWjB07Vt7e3mrRooV1/Z49e1S9evViKRIAAADIi91/d3n11VfVrVs3tWzZUr6+vlq8eLE8PDys6+Pi4nI9mhYAAAAoTnaH2YoVK2rz5s1KSkqSr6+vXG+YQP/pp5/K19fX4QUCAAAA+SnyjHh/f/8828uXL3/LxQAAAABFYfecWQAAAKCkIcwCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTIswCAADAtAizAAAAMC3CLAAAAEyLMAsAAADTcnN2AShZvF1dtahxY5tlAACAkoowCxsWi0U+bnwtAACAOTDNAAAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmJabswsoqTIzM5Wenu7w/ab5+jp8n3cCi2HINTVVLhkZzi4FAACUIITZGxiGoVOnTunixYvFsv+sFi2KZb+lnWEYUlaWvI8ckf/vv8vi7IIAAECJQJi9QXaQDQoKkre3tywWx8amjNOnHbq/O4VhGLqakaE/3d0lSeV+/93JFQEAgJKAMJtDZmamNcgGBgYWyzEy3PjIb1YZd3cpMFBn0tPld+iQs8sBAAAlABeA5ZA9R9bb29vJlSA/ZdzcJBcXZXp6OrsUAABQAhBm8+DoqQVwHIvFIovFIoN/IwAAIMIsAAAATIwwCwAAANMizJZQp86c0cgJE1S7eXP5Vq+uyg0aqOWjj2r+hx/qytWrzi4PAACgRODS+hLo0NGjavnooyrn56epL7+surVrKyMjQwcOHdKi5ctVKThYnaKicm2Xnp4u9/+7dRUAAMCdwOkjs3PmzFFERIS8vLwUGRmpzZs359v3s88+08MPP6yKFSvKz89PTZs21Zo1a25jtbfHsFdekZurq35cvVrdO3VSnZo1Va9OHXXr2FErP/hAjzz8sCTJvUoVzf/wQ3Xr10/+NWvqH7NnS5LmffCB7m7eXN4REfrLAw/ooxUrrPs+kpAg9ypVtPu//7W2XUxKknuVKtq4bZskaeO2bXKvUkWrv/9eDR9+WL7Vq6vZI4/o1337buOnAAAAUDinhtnly5crJiZG48aN065du9SiRQu1b99ex44dy7P/pk2b9PDDD2v16tWKj49X69at1alTJ+3ates2V158zl24oLWbNmlw797yyecWYTnvtjBlxgx1iorSru++U58nn9R/vv5aoyZOVMzAgdr9/fca0KuXBowerQ1btxa5lpdffVWvjx+vH1atUlCFCurWr1+xPOIXAADgZjk1zMbGxqp///4aMGCA6tSpo1mzZiksLExz587Ns/+sWbM0ZswY3XfffapZs6b+8Y9/qGbNmvryyy9vc+XF5+DhwzIMQ7WqV7dpD6lXT+Vq1VK5WrU0dto0a/uTXbuq75NPqlp4uMKrVFHs/PmK7t5dg3v3Vq1q1TRy4EA92r69YufPL3Itfx85Ug898IDq1amjuJkzdfrPP/Wfb7655XMEAABwFKeF2bS0NMXHxyvqhrmfUVFR2vZ/f+4uTFZWli5duqTy5cvn2yc1NVXJyck2LzO48V6321at0o41a3RPrVpKTUuztkfWr2/T738HDqjZfffZtDVt1Ej/O3iwyDU0iYy0vi8fEKBa1avrfwcOFHk/AAAAxcVpYfbs2bPKzMxUcHCwTXtwcLBOnTpl1z5mzJihlJQUPfHEE/n2mT59uvz9/a2vsLCwW6q7uNWIiJDFYtH+G8JntfBw1YiIUBkvL5v2vKYi3BiEjRxtLi7X/8kNw7CuT8/IsLs+HigBAABKEqdfAJYreBmGXYFp6dKlmjRpkpYvX66goKB8+40dO1ZJSUnWV0JCwi3XXJwCAwL00AMPaM6iRUq5cqXI29euWVNbf/7Zpu3HHTtUu0YNSVLF/xvFPnX6tHX9LzkuBsvpp507re8vXLyoA4cO6e7/2w8AAEBJ4LRbc1WoUEGurq65RmHPnDmTa7T2RsuXL1f//v316aef6qGHHiqwr6enpzw9PW+53tvp7WnT1PLRR9WkQweNHzVK9erUkYuLi3bs3q39f/yhhjdMLchp9KBBemrwYN1br54ebN5cq777Tp9//bXWLF0qSSpTpowaN2yo1+fMUXhYmM6dP68Jr7+e576mzZqlwIAABVWooAmvv64K5curS9u2xXLOAAAAN8NpI7MeHh6KjIzU2rVrbdrXrl2rZs2a5bvd0qVL1adPH3388cfq2LFjcZfpFNWrVtX2b77Rg/ffr7//85+KjIpSkw4d9K+FCzXquec0+cUX8922S7t2ip08WbHz5umvbdro/Y8+0vszZqhljs/0vRkzlJ6eriYdOmjkxImaMmZMnvuaNnasRk2cqMYdOijx9Gl9tnChPDw8HH6+AAAAN8upD00YNWqUnnnmGTVq1EhNmzbVu+++q2PHjmnQoEGSrk8ROHHihD744ANJ14NsdHS0Zs+erSZNmlhHdcuUKSN/f3+nnUdxCA0O1uxXX9XsAvqkHz+eZ/ug6GgNio7Od7s6NWtqy8qVhe6r+X33aff339tVLwAAgDM4Ncz26NFD586d05QpU5SYmKi6detq9erVCg8PlyQlJiba3HN2/vz5ysjI0PPPP6/nn3/e2t67d28tWrTodpcPAAAAJ3P642yHDBmiIUOG5LnuxoC6YcOG4i8IAAAApuH0MIuSp2WzZvlOYQAAAChJnH5rLgAAAOBmEWYBAABgWoRZAAAAmBZhFgAAAKZFmAUAAIBpEWYBAABgWoRZAAAAmBb3mbXT+QkTbuvx/J577qa2Szh5UlNmzNCaDRt09vx5hQYFqXPbtvr7yJG6dPmyajZtWuD240eO1ITRo7Vh61bNmDdPP+/apavXrqlqWJjatm6tmGefVeXQ0JuqDQAAwNEIs6XIoaNH1aJLF9WsVk0fvfOOqt51l/bu36+Xp03TmvXrtXnlSiXs3GntHzt/vr7dsEHfLF1qbfP18dG7H32kYa+8ome6d9cn776r8LAwJZw4oQ9XrNDMd9/VmxMnOuP0AAAAciHMliLDx42Th7u7vl6yRGXKlJEk3VW5shrUrau7mzfXhNdf17+mT7f29/X2lqurq0KCgqxtx0+e1MgJEzS0Xz/NmDTJ2l41LEwtmjTRxaSk23Y+AAAAhWHObClx/sIFfbtxowb17m0NstlCgoL01KOP6tOVK2UYRoH7WfHVV0pLS9MLgwfnub6cv7/DagYAALhVhNlS4sDhwzIMQ7Vr1Mhzfe2aNXUhKUl/njtX4H4OHj4sv7JlFRocXBxlAgAAOBRh9g6RPSJrsVgK7VdYHwAAgJKCMFtK1IiIkMVi0b4DB/Jcv//gQQX4+6tC+fIF7qdmtWpKSk5W4unTxVEmAACAQxFmS4nAgAA99MADmrd4sa5evWqz7tSZM1r6+efq3rlzoaOuj3XsKA8PD705d26e67kADAAAlCSE2VJk9tSpSk1LU4devbT5xx+VcPKk1qxfr3ZPPaXKISGaOmZMofsIq1RJb06cqLcXLNCzo0dr0w8/6Ojx49q6fbsGv/SSps2efRvOBAAAwD7cmstO5adMcch+Mk6ccMh+8lKzWjX9uHq1psTG6ukhQ3TuwgWFVKyozm3bavyoUSofEGDXfgb37q1a1aopdt48PT5ggPWhCR3atFHMwIHFVj8AAEBREWZLmfAqVbQgNtauvhNGj9aE0aPzXNemRQu1adHCkaUBAAA4HNMMAAAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWj7O1U+91X9/W4y24u/5tPZ69Ek6e1JQZM7RmwwadPX9eoUFB6ty2rf4+cqQCAwJ0JCFBNZs2LXAf40eO1ITRo7Vh61bNmDdPP+/apavXrqlqWJjatm6tmGefVeXQ0Nt0RgAAwMwIs7DboaNH1aJLF9WsVk0fvfOOqt51l/bu36+Xp03TmvXrtWXlSoVVqqSEnTut28TOn69vN2zQN0uXWtt8fXz07kcfadgrr+iZ7t31ybvvKjwsTAknTujDFSs089139ebEic44RQAAYDKE2VKizeOPq16dOvLy9FTc0qXy8PDQwF69NGH0aEnSsRMnFDN+vNZt2SIXFxe1bdVKs6ZOVXDFipKkKTNm6Is1azRy4EBNevNNXUhKUrvWrTXv9ddV1tdXkjR83Dh5uLvr6yVLVKZMGUnSXZUrq0Hdurq7eXONf/11/Wv6dIUEBVnr8vX2lqurq03b8ZMnNXLCBA3t108zJk2ytlcNC1OLJk10MSmpuD8uAABQSjBnthT5cMUK+Xh7a+uXX2r6uHF6ddYsfbdpkwzD0GP9++v8xYv6fsUKff3xx/rj6FE9PXiwzfaHjh7VyjVr9J9Fi/TFokXa9OOPev1f/5Iknb9wQd9u3KhBvXtbg2y2kKAgPfXoo/p05UoZhlFonSu++kppaWl64YbjZyvn73+TnwAAALjTMDJbitSrU0fjR42SJNWsVk1zFi7Uui1bJEm/7tunAz/8oLBKlSRJi2bP1l8ffFDbd+/WfQ0aSJKysrK0YOZM60hsz27dtG7LFk196SUdOHxYhmGodo0aeR67ds2aupCUpD/PnVNQhQoF1nnw8GH5lS2r0OBgR5w2AAC4gzEyW4rUq1PHZjk0OFhnzp3TvgMHFFapkjXIStI9tWqpnL+//nfwoLWtaliYNchKUkhwsP48d86uY2ePyFosFrv62tMPAACgMITZUsTdzXag3WKxKCsrK9/waBiGcra65bO9JNWIiJDFYtG+AwfyPPb+gwcV4O+vCuXLF1pnzWrVlJScrMTTpwvtCwAAUBDC7B3gnlq1dOzECSWcPGlt2/v770pKTlbtmjXt2kdgQIAeeuABzVu8WFevXrVZd+rMGS39/HN179zZrhHXxzp2lIeHh96cOzfP9VwABgAA7EWYvQO0adFC9erUUfSwYdr566/6edcu9Y2J0QNNmqjRX/9q935mT52q1LQ0dejVS5t//FEJJ09qzfr1avfUU6ocEqKpY8bYtZ+wSpX05sSJenvBAj07erQ2/fCDjh4/rq3bt2vwSy9p2uzZN3uqAADgDsMFYHZa/GB7h+wn48QJh+ynKCwWi/69YIFixo/Xg489ZnNrrqKoWa2afly9WlNiY/X0kCE6d+GCQipWVOe2bTV+1CiVDwiwe1+De/dWrWrVFDtvnh4fMMD60IQObdooZuDAop4iAAC4Q1kMe+6lVIokJyfL399fSUlJ8vPzs1l37do1HT58WBEREfLy8iqW4zsjzJYm1zIydPTkSQVu3qyXGtVzdjmlRtOT551dQqkwqFdPZ5fgFOcnTHB2CaXGyFYFP0ER9uN3zTGc9btWUF67EdMMAAAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWTjF4k8+UYV77nF2GQAAwOTcnF2AWcz7aMltPd6A1q1u6/HsUaNJEw0bMEAjBgxwdikAAACSGJmFg2VmZiorK8vZZQAAgDsEYbYUycrK0hv/+pdqN28un2rVVO1vf9P0t96SJP26b58efuIJla1eXcF162rQmDG6nJJi3bbfyJF6rH9/xc6bp7CGDRVct66GjRun9PR0SVKbxx/X0ePH9cKkSXKvUkXuVapI+v/TBb767jvVb91aPtWq6ejx47pw8aL6jBihin/5i/xq1NAjvXrpwKFDt/9DAQAApRphthQZN3263pgzR6/ExGjPunX64J13FFShgq5cvapHevVSgL+/fvjqKy2bP1/rtmzR8L//3Wb7Ddu26Y+jR7X2k08UN2uWPvjkEy3+5BNJ0qfvvacqoaGa9MILSti5Uwk7d1q3u3L1ql575x3Ne+MN/bJunYIqVFD/UaO0c88efR4Xp80rV8owDHWOjraGYwAAAEdgzmwpcenyZb0dF6fZU6cqunt3SVL1qlV1/9/+pveXLNHVa9e0cPZs+Xh7S5JmT52qrn37avorryi4YkVJUoC/v9569VW5urqqdo0a6tCmjdZv3aoBPXuqfECAXF1d5evrq5CgIJtjp6en6+1//EN//b8Lug4cOqQvv/1WG//zHzVr1EiS9ME77yjivvv0xZo1evyRR27XxwIAAEo5RmZLiX0HDig1NVUP3n9/rnX/O3hQ9e+5xxpkJanZffcpKytLv//xh7Xtnlq15Orqal0OCQrSmbNnCz22h4eH6tepY3M8Nzc3Nb73XmtbYECAalWvrv8dOFDkcwMAAMgPYbaUKOPlle86wzBksVjyXJez3d3dPdc6ey7mKuPlZbMfwzCKXAcAAMDNIMyWEjUjIlTGy0vrtmzJta5OzZr65b//VcqVK9a2bdu3y8XFRTWrVbP7GB7u7srKzCy0X52aNZWRkaGfdu2ytp27cEEHDh1S7Ro17D4eAABAYQizpYSXl5deHDJEY6dN04crVuiPI0f0Y3y84pYu1dPdusnLy0v9YmL02//+pw1btypmwgT1fOwx63xZe4SHhWnzTz/pRGKizp4/n2+/mtWqqXPbtho8Zoy2/Pyzftm7V72HDVPlkBB1btvWEacLAAAgiQvA7DaoV0+H7CfjxAmH7Ccv42Ji5ObmpslvvqmTp08rNChIA595Rt5lyuirjz7SqIkT1bRjR3mXKaNHO3TQmxMnFmn/E0eP1pCXX9bd99+v1NRUpR8/nm/f92fM0MiJE9W1Tx+lpaWpRePGWvnBB7mmMgAAANwKi5HfBMdSKjk5Wf7+/kpKSpKfn5/NumvXrunw4cOKiIiQVwFzUG9FcYbZO8G1jAwdPXlSgZs366VG9ZxdTqnR9GT+I+2wn6P+p9dszk+Y4OwSSo2RrZo6u4RSg981x3DW71pBee1GTDMAAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZjNwx12TZypGIZx/eEL/BsBAAARZm1k3zbqSo6HC6BkuZqRIWVlyTU11dmlAACAEoD7zObg6uqqcuXK6cyZM5Ikb29vhz9+NSMjw6H7u1MYhqGrGRn689w5eR85Ihc+RwAAIMJsLiEhIZJkDbSOlnXxYrHst7QzDEPKypL3kSPy//13Z5cDAABKCMLsDSwWi0JDQxUUFKT09HSH7//iW285fJ93AothyDU1lRFZAABggzCbD1dXV7m6ujp8vx6XLzt8nwAAAHcqp18ANmfOHOvjYyMjI7V58+YC+2/cuFGRkZHy8vJStWrVNG/evNtUKQAAAEoap4bZ5cuXKyYmRuPGjdOuXbvUokULtW/fXseOHcuz/+HDh9WhQwe1aNFCu3bt0iuvvKLhw4fr3//+922uHAAAACWBU8NsbGys+vfvrwEDBqhOnTqaNWuWwsLCNHfu3Dz7z5s3T3fddZdmzZqlOnXqaMCAAerXr5/efPPN21w5AAAASgKnzZlNS0tTfHy8Xn75ZZv2qKgobdu2Lc9tfvjhB0VFRdm0tW3bVgsWLFB6err1PrE5paamKjXHPUmTkpIkScnJybd6CjclmfujOkxaCvcDdpSrV/ksHcFZvyvOxu+a4/C75jj8rjmG0/LS/x3XngdZOS3Mnj17VpmZmQoODrZpDw4O1qlTp/Lc5tSpU3n2z8jI0NmzZxUaGpprm+nTp2vy5Mm52sPCwm6hepQIrzu7gNJjmbMLKCVGDRzo7BJgdvyuOQy/a47h7N+1S5cuyd/fv8A+Tr+bwY0PJTAMo8AHFeTVP6/2bGPHjtWoUaOsy1lZWTp//rwCAwMd/kAEIKfk5GSFhYUpISFBfn5+zi4HAG4Zv2u4XQzD0KVLl1SpUqVC+zotzFaoUEGurq65RmHPnDmTa/Q1W0hISJ793dzcFBgYmOc2np6e8vT0tGkrV67czRcOFJGfnx8/+gBKFX7XcDsUNiKbzWkXgHl4eCgyMlJr1661aV+7dq2aNWuW5zZNmzbN1f/bb79Vo0aN8pwvCwAAgNLNqXczGDVqlN5//33FxcVp3759GjlypI4dO6ZBgwZJuj5FIDo62tp/0KBBOnr0qEaNGqV9+/YpLi5OCxYs0AsvvOCsUwAAAIATOXXObI8ePXTu3DlNmTJFiYmJqlu3rlavXq3w8HBJUmJios09ZyMiIrR69WqNHDlS//rXv1SpUiW99dZbeuyxx5x1CkC+PD09NXHixFzTXADArPhdQ0lkMey55wEAAABQAjn9cbYAAADAzSLMAgAAwLQIswAAADAtwixQCh05ckQWi0W7d+92dikASoAbfxM2bNggi8WiixcvOrWugixatIj7wsMuhFmUCtu2bZOrq6vatWvn7FKKTVF+2MPCwqx3CAFQ+vXp00cWi8X6CgwMVLt27bRnzx5JjvlNaNWqlWJiYhxUMeA4hFmUCnFxcRo2bJi2bNliczu3O1FaWppcXV0VEhIiNzenP7EawG3Srl07JSYmKjExUd9//73c3Nz0yCOPSFKJ+k1IS0tzdgkoZQizML2UlBR98sknGjx4sB555BEtWrTIuu7ChQvq2bOnKlasqDJlyqhmzZpauHChJOnBBx/U0KFDbfZ17tw5eXp6at26dZKkqlWr6tVXX1V0dLR8fX0VHh6uL774Qn/++ae6dOkiX19f1atXTzt27LDuI3sEddWqVbr77rvl7e2txx9/XCkpKVq8eLGqVq2qgIAADRs2TJmZmdbt0tLSNGbMGFWuXFk+Pj5q3LixNmzYIOn6nwT79u2rpKQk68jLpEmTbGrs06eP/P399eyzz+Y5zeC///2vOnbsKD8/P5UtW1YtWrTQH3/84cB/CQDO5OnpqZCQEIWEhKhBgwZ66aWXlJCQoD///LPQqUfnzp3TU089pSpVqsjb21v16tXT0qVLrev79OmjjRs3avbs2dbfoCNHjkiS9u7dqw4dOsjX11fBwcF65plndPbsWeu2rVq10tChQzVq1ChVqFBBDz/8sCQpNjZW9erVk4+Pj8LCwjRkyBBdvny52D4flF6EWZje8uXLdffdd+vuu+9Wr169tHDhQmXfPnn8+PHau3evvv76a+3bt09z585VhQoVJEkDBgzQxx9/rNTUVOu+lixZokqVKql169bWtpkzZ6p58+batWuXOnbsqGeeeUbR0dHq1auXdu7cqRo1aig6Olo5b9l85coVvfXWW1q2bJm++eYbbdiwQd26ddPq1au1evVqffjhh3r33Xe1YsUK6zZ9+/bV1q1btWzZMu3Zs0fdu3dXu3btdODAATVr1kyzZs2Sn5+fdeQl55Pv3njjDdWtW1fx8fEaP358rs/oxIkTeuCBB+Tl5aV169YpPj5e/fr1U0ZGhuP+IQCUGJcvX9aSJUtUo0YNBQYGFtr/2rVrioyM1KpVq/Tbb79p4MCBeuaZZ/TTTz9JkmbPnq2mTZvq2Weftf4GZU9daNmypRo0aKAdO3bom2++0enTp/XEE0/Y7H/x4sVyc3PT1q1bNX/+fEmSi4uL3nrrLf32229avHix1q1bpzFjxjj+w0DpZwAm16xZM2PWrFmGYRhGenq6UaFCBWPt2rWGYRhGp06djL59++a53bVr14zy5csby5cvt7Y1aNDAmDRpknU5PDzc6NWrl3U5MTHRkGSMHz/e2vbDDz8YkozExETDMAxj4cKFhiTj4MGD1j7PPfec4e3tbVy6dMna1rZtW+O5554zDMMwDh48aFgsFuPEiRM2NbZp08YYO3asdb/+/v65ziM8PNzo2rWrTdvhw4cNScauXbsMwzCMsWPHGhEREUZaWlqenwUAc+vdu7fh6upq+Pj4GD4+PoYkIzQ01IiPjzcMI/dvwvr16w1JxoULF/LdZ4cOHYzRo0dbl1u2bGmMGDHCps/48eONqKgom7aEhARDkrF//37rdg0aNCj0HD755BMjMDDQupzfbx5wI0ZmYWr79+/Xzz//rCeffFKS5Obmph49eiguLk6SNHjwYC1btkwNGjTQmDFjtG3bNuu2np6e6tWrl7Xv7t279csvv6hPnz42x6hfv771fXBwsCSpXr16udrOnDljbfP29lb16tVt+lStWlW+vr42bdnb7Ny5U4ZhqFatWvL19bW+Nm7caNdUgEaNGhW4fvfu3WrRooXc3d0L3RcAc2rdurV2796t3bt366efflJUVJTat2+vo0ePFrptZmampk2bpvr16yswMFC+vr769ttvC70GIT4+XuvXr7f53apdu7Yk2fx25fUbtX79ej388MOqXLmyypYtq+joaJ07d04pKSlFPHPc6Zw/Exy4BQsWLFBGRoYqV65sbTMMQ+7u7rpw4YL1h/yrr77Sd999pzZt2uj555/Xm2++Ken6VIMGDRro+PHjiouLU5s2bRQeHm5zjJwB0GKx5NuWlZWV5zbZffJqy94mKytLrq6uio+Pl6urq02/nAE4Pz4+PgWuL1OmTKH7AGBuPj4+qlGjhnU5MjJS/v7+eu+99zRgwIACt50xY4ZmzpypWbNmWeexxsTEFHqxVlZWljp16qTXXnst17rQ0FCb2nI6evSoOnTooEGDBmnq1KkqX768tmzZov79+ys9Pd2e0wWsCLMwrYyMDH3wwQeaMWOGoqKibNY99thjWrJkiYYOHaqKFSuqT58+6tOnj1q0aKEXX3zRGmbr1aunRo0a6b333tPHH3+st99+2xmnonvvvVeZmZk6c+aMWrRokWcfDw8PmwvGiqJ+/fpavHix0tPTGZ0F7hAWi0UuLi66evVqoX03b96sLl26qFevXpKuh9QDBw6oTp061j55/QY1bNhQ//73v1W1atUi3Slhx44dysjI0IwZM+Ticv2PxJ988ond2wM5Mc0AprVq1SpduHBB/fv3V926dW1ejz/+uBYsWKAJEyboiy++0MGDB/Xf//5Xq1atsvlxlq6Pzv7zn/9UZmamHn30UaecS61atdSzZ09FR0frs88+0+HDh7V9+3a99tprWr16taTrdy24fPmyvv/+e509e1ZXrlyxe/9Dhw5VcnKynnzySe3YsUMHDhzQhx9+qP379xfXKQG4zVJTU3Xq1CmdOnVK+/bt07Bhw3T58mV16tSp0G1r1KihtWvXatu2bdq3b5+ee+45nTp1yqZP1apV9dNPP+nIkSM6e/assrKy9Pzzz+v8+fN66qmn9PPPP+vQoUP69ttv1a9fvwL/57t69erKyMjQ22+/rUOHDunDDz/UvHnzbvkzwJ2JMAvTWrBggR566CH5+/vnWvfYY49p9+7dcnNz09ixY1W/fn098MADcnV11bJly2z6PvXUU3Jzc9PTTz8tLy+v21V+LgsXLlR0dLRGjx6tu+++W507d9ZPP/2ksLAwSVKzZs00aNAg9ejRQxUrVtTrr79u974DAwO1bt06Xb58WS1btlRkZKTee+89RmmBUuSbb75RaGioQkND1bhxY23fvl2ffvqpWrVqVei248ePV8OGDdW2bVu1atVKISEh6tq1q02fF154Qa6urrrnnntUsWJFHTt2TJUqVdLWrVuVmZmptm3bqm7duhoxYoT8/f2tI655adCggWJjY/Xaa6+pbt26WrJkiaZPn36LnwDuVBbDyHE/IeAOlJCQoKpVq2r79u1q2LChs8sBAABFQJjFHSs9PV2JiYl6+eWXdfToUW3dutXZJQEAgCJimgHuWFu3blV4eLji4+OZqwUAgEkxMgsAAADTYmQWAAAApkWYBQAAgGkRZgEAAGBahFkAAACYFmEWAAAApkWYBQAAgGkRZgGgBLBYLAW++vTp4+wSAaBEcnN2AQAAKTEx0fp++fLlmjBhgvbv329tK1OmjDPKAoASj5FZACgBQkJCrC9/f39ZLBaFhIQoODhY999/v9577z2b/r/99ptcXFz0xx9/SLo+sjt37ly1b99eZcqUUUREhD799FObbU6cOKEePXooICBAgYGB6tKli44cOXK7ThEAigVhFgBKMIvFon79+mnhwoU27XFxcWrRooWqV69ubRs/frwee+wx/fLLL+rVq5eeeuop7du3T5J05coVtW7dWr6+vtq0aZO2bNkiX19ftWvXTmlpabf1nADAkQizAFDC9e3bV/v379fPP/8sSUpPT9dHH32kfv362fTr3r27BgwYoFq1amnq1Klq1KiR3n77bUnSsmXL5OLiovfff1/16tVTnTp1tHDhQh07dkwbNmy43acEAA5DmAWAEi40NFQdO3ZUXFycJGnVqlW6du2aunfvbtOvadOmuZazR2bj4+N18OBBlS1bVr6+vvL19VX58uV17do161QFADAjLgADABMYMGCAnnnmGc2cOVMLFy5Ujx495O3tXeh2FotFkpSVlaXIyEgtWbIkV5+KFSs6vF4AuF0IswBgAh06dJCPj4/mzp2rr7/+Wps2bcrV58cff1R0dLTN8r333itJatiwoZYvX66goCD5+fndtroBoLgxzQAATMDV1VV9+vTR2LFjVaNGjVxTCiTp008/VVxcnH7//XdNnDhRP//8s4YOHSpJ6tmzpypUqKAuXbpo8+bNOnz4sDZu3KgRI0bo+PHjt/t0AMBhCLMAYBL9+/dXWlpargu/sk2ePFnLli1T/fr1tXjxYi1ZskT33HOPJMnb21ubNm3SXXfdpW7duqlOnTrq16+frl69ykgtAFOzGIZhOLsIAEDhtm7dqlatWun48eMKDg62WWexWPT555+ra9euzikOAJyEObMAUMKlpqYqISFB48eP1xNPPJEryALAnYxpBgBQwi1dulR33323kpKS9Prrrzu7HAAoUZhmAAAAANNiZBYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJgWYRYAAACmRZgFAACAaRFmAQAAYFqEWQAAAJjW/wMe6DImosml2wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean                count          \n",
      "Type    Asymmetric Bilateral Asymmetric Bilateral\n",
      "Group                                            \n",
      "OTC          0.533     0.515         11        12\n",
      "control      0.764     0.685         35        36\n",
      "nonOTC       0.842     0.808         18        18\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Hybrid Stability (Fixed: Adds Subject ID)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "\n",
    "def compute_hybrid_stability(functional_results, subjects, min_voxels=30):\n",
    "    # Define Dictionaries locally\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    CATEGORY_TYPES = {\n",
    "        'face': 'Asymmetric', 'word': 'Asymmetric',\n",
    "        'house': 'Bilateral', 'object': 'Bilateral'\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        if sid not in subjects: continue\n",
    "        info = subjects[sid]\n",
    "        \n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        first_ses = sessions[0]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            cat = roi_name.split('_')[1]\n",
    "            if first_ses not in roi_data: continue\n",
    "            \n",
    "            # 1. Fixed ROI from Session 1\n",
    "            mask = roi_data[first_ses]['roi_mask']\n",
    "            if np.sum(mask) < min_voxels: continue\n",
    "            \n",
    "            # 2. Extract using Robust Cope\n",
    "            patterns = {}\n",
    "            valid_extraction = True\n",
    "            \n",
    "            for ses in sessions:\n",
    "                f = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                z = f / f'cope{EXTRACTION_MAP[cat]}.feat' / 'stats' / ('zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz')\n",
    "                \n",
    "                if z.exists():\n",
    "                    try: patterns[ses] = nib.load(z).get_fdata()[mask]\n",
    "                    except: valid_extraction = False\n",
    "                else: valid_extraction = False\n",
    "            \n",
    "            # 3. Correlate\n",
    "            if valid_extraction and sessions[-1] in patterns:\n",
    "                if np.std(patterns[first_ses]) > 0 and np.std(patterns[sessions[-1]]) > 0:\n",
    "                    corr = np.corrcoef(patterns[first_ses], patterns[sessions[-1]])[0,1]\n",
    "                    \n",
    "                    data.append({\n",
    "                        'Subject': info['code'],\n",
    "                        'Group': info['group'], \n",
    "                        'Category': cat.capitalize(),\n",
    "                        'Type': CATEGORY_TYPES.get(cat, 'Other'), \n",
    "                        'Stability (r)': corr\n",
    "                    })\n",
    "                \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    if not df.empty:\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.barplot(data=df, x='Type', y='Stability (r)', hue='Group', \n",
    "                    palette={'OTC': '#ff6b6b', 'nonOTC': '#4ecdc4', 'control': '#95a5a6'},\n",
    "                    order=['Asymmetric', 'Bilateral'])\n",
    "        plt.title(\"Hybrid Stability (Fixed ROI)\", fontweight='bold')\n",
    "        plt.axhline(0, color='k', linewidth=0.5)\n",
    "        plt.show()\n",
    "        print(df.groupby(['Group', 'Type'])['Stability (r)'].agg(['mean', 'count']).unstack().round(3))\n",
    "    return df\n",
    "\n",
    "df_hybrid = compute_hybrid_stability(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b788de61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category  Face  House  Object   Word\n",
      "Group                               \n",
      "OTC       6.99   5.84    5.86  14.95\n",
      "control   7.01   6.34    4.28   9.97\n",
      "nonOTC    3.04   5.00    2.19   9.36\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Drift Analysis (Fixed: Adds Subject ID)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def analyze_drift(functional_results, subjects, min_voxels=50): # may need to change to 30 to match extraction\n",
    "    CATEGORY_TYPES = {\n",
    "        'face': 'Asymmetric', 'word': 'Asymmetric',\n",
    "        'house': 'Bilateral', 'object': 'Bilateral'\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    for sid, res in functional_results.items():\n",
    "        if sid not in subjects: continue\n",
    "        info = subjects[sid]\n",
    "        \n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            cat = roi_name.split('_')[1]\n",
    "            first, last = sessions[0], sessions[-1]\n",
    "            \n",
    "            if first in roi_data and last in roi_data:\n",
    "                if roi_data[first]['n_voxels'] >= min_voxels:\n",
    "                    c1 = np.array(roi_data[first]['centroid'])\n",
    "                    c2 = np.array(roi_data[last]['centroid'])\n",
    "                    dist = np.linalg.norm(c2 - c1)\n",
    "                    \n",
    "                    data.append({\n",
    "                        'Subject': info['code'],  # <--- ADDED THIS LINE\n",
    "                        'Group': info['group'], \n",
    "                        'Category': cat.capitalize(),\n",
    "                        'Type': CATEGORY_TYPES.get(cat, 'Other'), \n",
    "                        'Drift (mm)': dist\n",
    "                    })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    if not df.empty:\n",
    "        print(df.groupby(['Group', 'Category'])['Drift (mm)'].mean().unstack().round(2))\n",
    "    return df\n",
    "\n",
    "df_drift = analyze_drift(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41cbfca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating RDM Stability (Geometry Preservation)...\n",
      "Type     Asymmetric  Bilateral\n",
      "Group                         \n",
      "OTC           0.387      0.339\n",
      "control       0.626      0.553\n",
      "nonOTC        0.492      0.779\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: RDM Stability (Fixed: Adds Category Column)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nibabel as nib\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def analyze_rdm(functional_results, subjects, min_voxels=30):\n",
    "    print(f\"Calculating RDM Stability (Geometry Preservation)...\")\n",
    "    RDM_CATS = ['face', 'house', 'object', 'word']\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    CATEGORY_TYPES = {\n",
    "        'face': 'Asymmetric', 'word': 'Asymmetric',\n",
    "        'house': 'Bilateral', 'object': 'Bilateral'\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        if sid not in subjects: continue\n",
    "        info = subjects[sid]\n",
    "        \n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        first, last = sessions[0], sessions[-1]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            roi_cat = roi_name.split('_')[1] # e.g. 'face'\n",
    "            \n",
    "            if first not in roi_data or last not in roi_data: continue\n",
    "            \n",
    "            m1, m2 = roi_data[first]['roi_mask'], roi_data[last]['roi_mask']\n",
    "            if np.sum(m1) < min_voxels or np.sum(m2) < min_voxels: continue\n",
    "            \n",
    "            try:\n",
    "                # Build RDMs\n",
    "                feats1 = [nib.load(BASE_DIR/sid/f'ses-{first}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/'zstat1.nii.gz').get_fdata()[m1] for c in RDM_CATS]\n",
    "                feats2 = [nib.load(BASE_DIR/sid/f'ses-{last}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/f'zstat1_ses{first}.nii.gz').get_fdata()[m2] for c in RDM_CATS]\n",
    "                \n",
    "                rdm1 = 1 - np.corrcoef(np.array(feats1))\n",
    "                rdm2 = 1 - np.corrcoef(np.array(feats2))\n",
    "                \n",
    "                # Fix Symmetry\n",
    "                rdm1 = (rdm1 + rdm1.T)/2; np.fill_diagonal(rdm1, 0)\n",
    "                rdm2 = (rdm2 + rdm2.T)/2; np.fill_diagonal(rdm2, 0)\n",
    "                \n",
    "                corr = np.corrcoef(squareform(rdm1), squareform(rdm2))[0,1]\n",
    "                \n",
    "                data.append({\n",
    "                    'Subject': info['code'],\n",
    "                    'Group': info['group'], \n",
    "                    'Category': roi_cat.capitalize(), # <--- THIS WAS MISSING\n",
    "                    'Type': CATEGORY_TYPES.get(roi_cat, 'Other'),\n",
    "                    'RDM Stability (r)': corr\n",
    "                })\n",
    "            except: pass\n",
    "            \n",
    "    df = pd.DataFrame(data)\n",
    "    if not df.empty:\n",
    "        print(df.groupby(['Group', 'Type'])['RDM Stability (r)'].mean().unstack().round(3))\n",
    "    return df\n",
    "\n",
    "# Re-run to update dataframe\n",
    "df_rdm = analyze_rdm(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ea2966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 8: Print Full Data Tables\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TABLE 1: HYBRID STABILITY (Local Persistence)\")\n",
    "print(\"=\"*80)\n",
    "if 'df_hybrid' in locals():\n",
    "    print(df_hybrid.sort_values(by=['Group', 'Category', 'Subject']).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TABLE 2: DRIFT ANALYSIS (Physical Movement)\")\n",
    "print(\"=\"*80)\n",
    "if 'df_drift' in locals():\n",
    "    print(df_drift.sort_values(by=['Group', 'Category', 'Subject']).to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA TABLE 3: RDM STABILITY (Geometry)\")\n",
    "print(\"=\"*80)\n",
    "if 'df_rdm' in locals():\n",
    "    print(df_rdm.sort_values(by=['Group', 'Type', 'Subject']).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6567b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 9: Longitudinal Trajectories (Spaghetti Plots)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def plot_longitudinal_trajectories(functional_results, subjects, min_voxels=50):\n",
    "    print(\"Generating Longitudinal Trajectories...\")\n",
    "    \n",
    "    # Configurations\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    CATEGORY_TYPES = {'face': 'Asymmetric', 'word': 'Asymmetric', \n",
    "                      'house': 'Bilateral', 'object': 'Bilateral'}\n",
    "    \n",
    "    drift_data = []\n",
    "    stability_data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        if sid not in subjects: continue\n",
    "        info = subjects[sid]\n",
    "        \n",
    "        # Get all sessions sorted numerically\n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}), key=lambda x: int(x))\n",
    "        if len(sessions) < 2: continue\n",
    "        \n",
    "        # Session 1 is the Anchor\n",
    "        first_ses = sessions[0]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            cat = roi_name.split('_')[1]\n",
    "            if first_ses not in roi_data: continue\n",
    "            \n",
    "            # Get Anchor ROI\n",
    "            anchor_mask = roi_data[first_ses]['roi_mask']\n",
    "            anchor_centroid = np.array(roi_data[first_ses]['centroid'])\n",
    "            \n",
    "            # Get Anchor Pattern (for stability)\n",
    "            if np.sum(anchor_mask) < min_voxels: continue\n",
    "            \n",
    "            # Load Anchor Data\n",
    "            try:\n",
    "                f = BASE_DIR/sid/f'ses-{first_ses}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'\n",
    "                z = f/f'cope{EXTRACTION_MAP[cat]}.feat'/'stats'/'zstat1.nii.gz'\n",
    "                anchor_pattern = nib.load(z).get_fdata()[anchor_mask]\n",
    "            except: continue\n",
    "\n",
    "            # Loop through SUBSEQUENT sessions\n",
    "            for i, current_ses in enumerate(sessions):\n",
    "                if current_ses == first_ses: \n",
    "                    # Plot the 0 point\n",
    "                    drift_val = 0\n",
    "                    stab_val = 1.0\n",
    "                else:\n",
    "                    if current_ses not in roi_data: continue\n",
    "                    \n",
    "                    # --- CALC DRIFT ---\n",
    "                    if roi_data[current_ses]['n_voxels'] >= min_voxels:\n",
    "                        curr_centroid = np.array(roi_data[current_ses]['centroid'])\n",
    "                        drift_val = np.linalg.norm(curr_centroid - anchor_centroid)\n",
    "                    else: drift_val = np.nan\n",
    "                        \n",
    "                    # --- CALC STABILITY ---\n",
    "                    # Path to current session data (aligned to Ses 1)\n",
    "                    try:\n",
    "                        f = BASE_DIR/sid/f'ses-{current_ses}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'\n",
    "                        z = f/f'cope{EXTRACTION_MAP[cat]}.feat'/'stats'/f'zstat1_ses{first_ses}.nii.gz'\n",
    "                        curr_pattern = nib.load(z).get_fdata()[anchor_mask]\n",
    "                        stab_val = np.corrcoef(anchor_pattern, curr_pattern)[0,1]\n",
    "                    except: stab_val = np.nan\n",
    "\n",
    "                # Append Data\n",
    "                common_data = {\n",
    "                    'Subject': info['code'], 'Group': info['group'],\n",
    "                    'Category': cat.capitalize(), 'Type': CATEGORY_TYPES.get(cat),\n",
    "                    'Session_Index': i, 'Session_Label': current_ses\n",
    "                }\n",
    "                \n",
    "                drift_data.append({**common_data, 'Value': drift_val, 'Metric': 'Drift (mm)'})\n",
    "                stability_data.append({**common_data, 'Value': stab_val, 'Metric': 'Stability (r)'})\n",
    "\n",
    "    # Combine and Plot\n",
    "    df_long = pd.DataFrame(drift_data + stability_data)\n",
    "    \n",
    "    # Create FacetGrid: Rows = Metric, Cols = Category Type\n",
    "    g = sns.FacetGrid(df_long, row=\"Metric\", col=\"Type\", hue=\"Group\", \n",
    "                      palette={'OTC': '#ff6b6b', 'nonOTC': '#4ecdc4', 'control': '#95a5a6'},\n",
    "                      height=4, aspect=1.5, sharey=False)\n",
    "    \n",
    "    g.map(sns.lineplot, \"Session_Index\", \"Value\", alpha=0.7, marker=\"o\", errorbar=None)\n",
    "    \n",
    "    # Add titles and clean up\n",
    "    g.set_titles(\"{col_name} - {row_name}\")\n",
    "    g.set_axis_labels(\"Session Number (0=Baseline)\", \"\")\n",
    "    g.add_legend()\n",
    "    plt.subplots_adjust(top=0.9)\n",
    "    g.fig.suptitle(\"Longitudinal Trajectories (Per Subject)\", fontsize=16, fontweight='bold')\n",
    "    plt.show()\n",
    "    \n",
    "    return df_long\n",
    "\n",
    "df_traj = plot_longitudinal_trajectories(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feff64a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 10: Individual Subject Trajectories (Fixed)\n",
    "def plot_individual_trajectories(df_long):\n",
    "    print(\"Generating Individual Subject Trajectories...\")\n",
    "    \n",
    "    # Filter for the metrics we care about\n",
    "    metrics = ['Drift (mm)', 'Stability (r)']\n",
    "    \n",
    "    for metric in metrics:\n",
    "        # Initialize the Grid\n",
    "        g = sns.FacetGrid(df_long[df_long['Metric'] == metric], \n",
    "                          col=\"Type\", hue=\"Group\", \n",
    "                          palette={'OTC': '#ff6b6b', 'nonOTC': '#4ecdc4', 'control': '#95a5a6'},\n",
    "                          height=5, aspect=1.2)\n",
    "        \n",
    "        # FIX: Use map_dataframe to explicitly handle 'units'\n",
    "        g.map_dataframe(sns.lineplot, \n",
    "                        x=\"Session_Index\", \n",
    "                        y=\"Value\", \n",
    "                        units=\"Subject\", # <--- This draws one line per subject\n",
    "                        estimator=None,  # <--- This prevents averaging\n",
    "                        alpha=0.6, \n",
    "                        linewidth=1.5, \n",
    "                        marker=\"o\")\n",
    "        \n",
    "        g.add_legend()\n",
    "        g.fig.suptitle(f\"Individual {metric} over Time\", y=1.05, fontsize=16, fontweight='bold')\n",
    "        \n",
    "        # Fix X-axis to show integers\n",
    "        for ax in g.axes.flat:\n",
    "            ax.xaxis.set_major_locator(plt.MaxNLocator(integer=True))\n",
    "            \n",
    "        plt.show()\n",
    "\n",
    "# Run with the dataframe from Cell 9\n",
    "if 'df_traj' in locals():\n",
    "    plot_individual_trajectories(df_traj)\n",
    "else:\n",
    "    print(\"⚠️ df_traj not found. Please run Cell 9 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44625e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 11: Data Audit (Subject & Session Availability)\n",
    "def audit_functional_data(functional_results, subjects):\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"FUNCTIONAL DATA AUDIT: Which sessions survived extraction?\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    print(f\"{'Subject':<10} {'Group':<8} {'Category':<10} {'Sessions Found'}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Track missing sessions for specific interest\n",
    "    missing_log = []\n",
    "\n",
    "    for subject_id in sorted(subjects.keys()):\n",
    "        info = subjects[subject_id]\n",
    "        code = info['code']\n",
    "        group = info['group']\n",
    "        \n",
    "        # Check if subject exists in results\n",
    "        if subject_id not in functional_results:\n",
    "            print(f\"{code:<10} {group:<8} -- NO DATA EXTRACTED --\")\n",
    "            continue\n",
    "            \n",
    "        res = functional_results[subject_id]\n",
    "        \n",
    "        # Check each category\n",
    "        # We define the \"Expected\" sessions based on the directory structure\n",
    "        # (This requires a quick look at the filesystem or just assuming based on gaps)\n",
    "        \n",
    "        for cat in ['face', 'word', 'house', 'object']:\n",
    "            # Find the key (l_face or r_face)\n",
    "            found_key = None\n",
    "            for key in res.keys():\n",
    "                if key.endswith(f\"_{cat}\"):\n",
    "                    found_key = key\n",
    "                    break\n",
    "            \n",
    "            if found_key:\n",
    "                sessions = sorted(res[found_key].keys())\n",
    "                sess_str = \", \".join(sessions)\n",
    "                print(f\"{code:<10} {group:<8} {cat:<10} {sess_str}\")\n",
    "                \n",
    "                # Specific check for OTC079\n",
    "                if code == 'OTC079' and '2' not in sessions:\n",
    "                    missing_log.append(f\"OTC079: Missing Ses-02 for {cat}\")\n",
    "            else:\n",
    "                # ROI completely failed (size < 30 for all sessions)\n",
    "                print(f\"{code:<10} {group:<8} {cat:<10} [DROP] No valid ROIs > 30 voxels\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"SPECIFIC ALERTS\")\n",
    "    print(\"=\"*80)\n",
    "    if missing_log:\n",
    "        for msg in missing_log:\n",
    "            print(f\"⚠️ {msg}\")\n",
    "    else:\n",
    "        print(\"No specific alerts triggered.\")\n",
    "\n",
    "audit_functional_data(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2664a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 12: Statistical Significance Testing (With N and SD)\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "def run_stats(df, metric_name, measure_col):\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"STATISTICS FOR: {metric_name}\")\n",
    "    print(f\"{'='*90}\")\n",
    "    \n",
    "    groups = ['OTC', 'control'] \n",
    "    types = ['Asymmetric', 'Bilateral']\n",
    "    \n",
    "    # Helper to get data\n",
    "    def get_data(grp, typ):\n",
    "        return df[(df['Group'] == grp) & (df['Type'] == typ)][measure_col].dropna()\n",
    "\n",
    "    # --- TEST 1: DEFICIT (OTC Asym vs Control Asym) ---\n",
    "    d1 = get_data('OTC', 'Asymmetric')\n",
    "    d2 = get_data('control', 'Asymmetric')\n",
    "    \n",
    "    t, p = stats.ttest_ind(d1, d2, equal_var=False)\n",
    "    sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"ns\"\n",
    "    \n",
    "    print(f\"1. DEFICIT TEST (OTC Asym vs. Control Asym):\")\n",
    "    print(f\"   OTC     : N={len(d1):<3} | Mean={d1.mean():.3f} | SD={d1.std():.3f}\")\n",
    "    print(f\"   Control : N={len(d2):<3} | Mean={d2.mean():.3f} | SD={d2.std():.3f}\")\n",
    "    print(f\"   Result  : T={t:.3f} | p={p:.4f}  [{sig}]\")\n",
    "    \n",
    "    # --- TEST 2: DISSOCIATION (OTC Asym vs OTC Bilat) ---\n",
    "    d1 = get_data('OTC', 'Asymmetric')\n",
    "    d2 = get_data('OTC', 'Bilateral')\n",
    "    \n",
    "    t, p = stats.ttest_ind(d1, d2, equal_var=False)\n",
    "    sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"ns\"\n",
    "    \n",
    "    print(f\"\\n2. DISSOCIATION TEST (OTC Asym vs. OTC Bilat):\")\n",
    "    print(f\"   OTC Asym : N={len(d1):<3} | Mean={d1.mean():.3f} | SD={d1.std():.3f}\")\n",
    "    print(f\"   OTC Bilat: N={len(d2):<3} | Mean={d2.mean():.3f} | SD={d2.std():.3f}\")\n",
    "    print(f\"   Result   : T={t:.3f} | p={p:.4f}  [{sig}]\")\n",
    "\n",
    "    # --- TEST 3: CROWDING CHECK (OTC Bilat vs Control Bilat) ---\n",
    "    d1 = get_data('OTC', 'Bilateral')\n",
    "    d2 = get_data('control', 'Bilateral')\n",
    "    \n",
    "    t, p = stats.ttest_ind(d1, d2, equal_var=False)\n",
    "    sig = \"***\" if p < 0.001 else \"**\" if p < 0.01 else \"*\" if p < 0.05 else \"ns\"\n",
    "    \n",
    "    print(f\"\\n3. CROWDING CHECK (OTC Bilat vs. Control Bilat):\")\n",
    "    print(f\"   OTC     : N={len(d1):<3} | Mean={d1.mean():.3f} | SD={d1.std():.3f}\")\n",
    "    print(f\"   Control : N={len(d2):<3} | Mean={d2.mean():.3f} | SD={d2.std():.3f}\")\n",
    "    print(f\"   Result  : T={t:.3f} | p={p:.4f}  [{sig}]\")\n",
    "\n",
    "# Execute\n",
    "if 'df_hybrid' in locals(): run_stats(df_hybrid, \"HYBRID STABILITY (Local Anchor)\", 'Stability (r)')\n",
    "if 'df_drift' in locals(): run_stats(df_drift, \"DRIFT (Physical Movement)\", 'Drift (mm)')\n",
    "if 'df_rdm' in locals(): run_stats(df_rdm, \"RDM STABILITY (Geometry)\", 'RDM Stability (r)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce0141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 20: Master Publication Figure (Drift, Hybrid, RDM)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def plot_master_figure(df_drift, df_hybrid, df_rdm):\n",
    "    print(\"Generating Master Publication Figure...\")\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "    \n",
    "    # Shared Plot Settings\n",
    "    pal = {'OTC': '#ff6b6b', 'nonOTC': '#4ecdc4', 'control': '#95a5a6'}\n",
    "    order = ['Asymmetric', 'Bilateral']\n",
    "    \n",
    "    # --- PANEL A: DRIFT (Physical Movement) ---\n",
    "    sns.barplot(data=df_drift, x='Type', y='Drift (mm)', hue='Group', \n",
    "                palette=pal, alpha=0.8, ax=axes[0], order=order, errorbar='se', capsize=0.1)\n",
    "    # Add Stripplot for individual points\n",
    "    sns.stripplot(data=df_drift, x='Type', y='Drift (mm)', hue='Group', \n",
    "                  dodge=True, palette='dark:gray', alpha=0.5, legend=False, ax=axes[0], order=order)\n",
    "    \n",
    "    axes[0].set_title(\"A. Physical Drift (Location Change)\", fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel(\"Drift Distance (mm)\", fontsize=12)\n",
    "    axes[0].set_xlabel(\"\")\n",
    "    axes[0].legend_.remove() # Clean up legends\n",
    "    \n",
    "    # --- PANEL B: HYBRID STABILITY (Local Anchor) ---\n",
    "    sns.barplot(data=df_hybrid, x='Type', y='Stability (r)', hue='Group', \n",
    "                palette=pal, alpha=0.8, ax=axes[1], order=order, errorbar='se', capsize=0.1)\n",
    "    sns.stripplot(data=df_hybrid, x='Type', y='Stability (r)', hue='Group', \n",
    "                  dodge=True, palette='dark:gray', alpha=0.5, legend=False, ax=axes[1], order=order)\n",
    "    \n",
    "    axes[1].set_title(\"B. Local Persistence (Fixed Anchor)\", fontsize=14, fontweight='bold')\n",
    "    axes[1].set_ylabel(\"Pattern Stability (r)\", fontsize=12)\n",
    "    axes[1].set_xlabel(\"\")\n",
    "    axes[1].set_ylim(-0.2, 1.0)\n",
    "    axes[1].axhline(0, color='black', linewidth=0.5)\n",
    "    axes[1].legend_.remove()\n",
    "\n",
    "    # --- PANEL C: RDM STABILITY (Geometry) ---\n",
    "    sns.barplot(data=df_rdm, x='Type', y='RDM Stability (r)', hue='Group', \n",
    "                palette=pal, alpha=0.8, ax=axes[2], order=order, errorbar='se', capsize=0.1)\n",
    "    sns.stripplot(data=df_rdm, x='Type', y='RDM Stability (r)', hue='Group', \n",
    "                  dodge=True, palette='dark:gray', alpha=0.5, legend=False, ax=axes[2], order=order)\n",
    "    \n",
    "    axes[2].set_title(\"C. Geometric Integrity (Crowding)\", fontsize=14, fontweight='bold')\n",
    "    axes[2].set_ylabel(\"RDM Correlation (r)\", fontsize=12)\n",
    "    axes[2].set_xlabel(\"\")\n",
    "    axes[2].set_ylim(-0.2, 1.0)\n",
    "    axes[2].axhline(0, color='black', linewidth=0.5)\n",
    "    \n",
    "    # Clean up the legend\n",
    "    handles, labels = axes[2].get_legend_handles_labels()\n",
    "    # We only want the first 3 handles (Groups), not the strip plot points\n",
    "    axes[2].legend(handles[:3], labels[:3], title='Group', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Execute only if dataframes exist\n",
    "if 'df_drift' in locals() and 'df_hybrid' in locals() and 'df_rdm' in locals():\n",
    "    plot_master_figure(df_drift, df_hybrid, df_rdm)\n",
    "else:\n",
    "    print(\"Missing dataframes. Please run extraction cells first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3078eeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Add Statistics to Existing Analyses\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, permutation_test\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def compute_statistics_for_analyses(df_hybrid, df_drift, df_rdm, analysis_subjects):\n",
    "    \"\"\"\n",
    "    Add proper statistics to all three main analyses:\n",
    "    - Cell 5: Hybrid stability (fixed ROI)\n",
    "    - Cell 6: Spatial drift\n",
    "    - Cell 7: RDM stability (dynamic ROI)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"STATISTICAL ANALYSIS: CELLS 5, 6, 7\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    # ========== CELL 5: HYBRID STABILITY ==========\n",
    "    if not df_hybrid.empty:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CELL 5: HYBRID STABILITY (Fixed ROI Pattern Correlation)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # OTC vs Controls - Asymmetric\n",
    "        otc_asym = df_hybrid[(df_hybrid['Group'] == 'OTC') & (df_hybrid['Type'] == 'Asymmetric')]['Stability (r)']\n",
    "        ctrl_asym = df_hybrid[(df_hybrid['Group'] == 'control') & (df_hybrid['Type'] == 'Asymmetric')]['Stability (r)']\n",
    "        \n",
    "        if len(otc_asym) > 0 and len(ctrl_asym) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_asym, ctrl_asym)\n",
    "            d = (np.mean(otc_asym) - np.mean(ctrl_asym)) / np.sqrt((np.std(otc_asym)**2 + np.std(ctrl_asym)**2) / 2)\n",
    "            print(f\"\\nAsymmetric: OTC vs Controls\")\n",
    "            print(f\"  OTC: M={np.mean(otc_asym):.3f}, SD={np.std(otc_asym):.3f}, N={len(otc_asym)}\")\n",
    "            print(f\"  Controls: M={np.mean(ctrl_asym):.3f}, SD={np.std(ctrl_asym):.3f}, N={len(ctrl_asym)}\")\n",
    "            print(f\"  t({len(otc_asym)+len(ctrl_asym)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "        \n",
    "        # OTC vs Controls - Bilateral\n",
    "        otc_bil = df_hybrid[(df_hybrid['Group'] == 'OTC') & (df_hybrid['Type'] == 'Bilateral')]['Stability (r)']\n",
    "        ctrl_bil = df_hybrid[(df_hybrid['Group'] == 'control') & (df_hybrid['Type'] == 'Bilateral')]['Stability (r)']\n",
    "        \n",
    "        if len(otc_bil) > 0 and len(ctrl_bil) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_bil, ctrl_bil)\n",
    "            d = (np.mean(otc_bil) - np.mean(ctrl_bil)) / np.sqrt((np.std(otc_bil)**2 + np.std(ctrl_bil)**2) / 2)\n",
    "            print(f\"\\nBilateral: OTC vs Controls\")\n",
    "            print(f\"  OTC: M={np.mean(otc_bil):.3f}, SD={np.std(otc_bil):.3f}, N={len(otc_bil)}\")\n",
    "            print(f\"  Controls: M={np.mean(ctrl_bil):.3f}, SD={np.std(ctrl_bil):.3f}, N={len(ctrl_bil)}\")\n",
    "            print(f\"  t({len(otc_bil)+len(ctrl_bil)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "        \n",
    "        # Within OTC: Asymmetric vs Bilateral\n",
    "        if len(otc_asym) > 0 and len(otc_bil) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_asym, otc_bil)\n",
    "            d = (np.mean(otc_asym) - np.mean(otc_bil)) / np.sqrt((np.std(otc_asym)**2 + np.std(otc_bil)**2) / 2)\n",
    "            print(f\"\\nWithin OTC: Asymmetric vs Bilateral\")\n",
    "            print(f\"  Asymmetric: M={np.mean(otc_asym):.3f}\")\n",
    "            print(f\"  Bilateral: M={np.mean(otc_bil):.3f}\")\n",
    "            print(f\"  t({len(otc_asym)+len(otc_bil)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "    \n",
    "    # ========== CELL 6: SPATIAL DRIFT ==========\n",
    "    if not df_drift.empty:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CELL 6: SPATIAL DRIFT\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # OTC: Asymmetric vs Bilateral\n",
    "        otc_drift = df_drift[df_drift['Group'] == 'OTC']\n",
    "        otc_asym_drift = otc_drift[otc_drift['Type'] == 'Asymmetric']['Drift (mm)']\n",
    "        otc_bil_drift = otc_drift[otc_drift['Type'] == 'Bilateral']['Drift (mm)']\n",
    "        \n",
    "        if len(otc_asym_drift) > 0 and len(otc_bil_drift) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_asym_drift, otc_bil_drift)\n",
    "            d = (np.mean(otc_asym_drift) - np.mean(otc_bil_drift)) / np.sqrt((np.std(otc_asym_drift)**2 + np.std(otc_bil_drift)**2) / 2)\n",
    "            print(f\"\\nOTC: Asymmetric vs Bilateral Drift\")\n",
    "            print(f\"  Asymmetric: M={np.mean(otc_asym_drift):.2f}mm, SD={np.std(otc_asym_drift):.2f}, N={len(otc_asym_drift)}\")\n",
    "            print(f\"  Bilateral: M={np.mean(otc_bil_drift):.2f}mm, SD={np.std(otc_bil_drift):.2f}, N={len(otc_bil_drift)}\")\n",
    "            print(f\"  t({len(otc_asym_drift)+len(otc_bil_drift)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "            \n",
    "            if p_val < 0.05:\n",
    "                print(f\"  ✓ SIGNIFICANT: Asymmetric drifts MORE than bilateral\")\n",
    "    \n",
    "    # ========== CELL 7: RDM STABILITY ==========\n",
    "    if not df_rdm.empty:\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"CELL 7: RDM STABILITY (Representational Geometry)\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # OTC: Asymmetric vs Bilateral\n",
    "        otc_rdm = df_rdm[df_rdm['Group'] == 'OTC']\n",
    "        otc_asym_rdm = otc_rdm[otc_rdm['Type'] == 'Asymmetric']['RDM Stability (r)']\n",
    "        otc_bil_rdm = otc_rdm[otc_rdm['Type'] == 'Bilateral']['RDM Stability (r)']\n",
    "        \n",
    "        if len(otc_asym_rdm) > 0 and len(otc_bil_rdm) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_asym_rdm, otc_bil_rdm)\n",
    "            d = (np.mean(otc_asym_rdm) - np.mean(otc_bil_rdm)) / np.sqrt((np.std(otc_asym_rdm)**2 + np.std(otc_bil_rdm)**2) / 2)\n",
    "            print(f\"\\nOTC: Asymmetric vs Bilateral RDM Stability\")\n",
    "            print(f\"  Asymmetric: M={np.mean(otc_asym_rdm):.3f}, SD={np.std(otc_asym_rdm):.3f}, N={len(otc_asym_rdm)}\")\n",
    "            print(f\"  Bilateral: M={np.mean(otc_bil_rdm):.3f}, SD={np.std(otc_bil_rdm):.3f}, N={len(otc_bil_rdm)}\")\n",
    "            print(f\"  t({len(otc_asym_rdm)+len(otc_bil_rdm)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "            \n",
    "            if p_val < 0.05:\n",
    "                print(f\"  ✓ SIGNIFICANT: Bilateral shows LOWER stability (more reorganization)\")\n",
    "        \n",
    "        # OTC vs Controls - Bilateral\n",
    "        ctrl_bil_rdm = df_rdm[(df_rdm['Group'] == 'control') & (df_rdm['Type'] == 'Bilateral')]['RDM Stability (r)']\n",
    "        \n",
    "        if len(otc_bil_rdm) > 0 and len(ctrl_bil_rdm) > 0:\n",
    "            t_stat, p_val = ttest_ind(otc_bil_rdm, ctrl_bil_rdm)\n",
    "            d = (np.mean(otc_bil_rdm) - np.mean(ctrl_bil_rdm)) / np.sqrt((np.std(otc_bil_rdm)**2 + np.std(ctrl_bil_rdm)**2) / 2)\n",
    "            print(f\"\\nBilateral: OTC vs Controls\")\n",
    "            print(f\"  OTC: M={np.mean(otc_bil_rdm):.3f}, SD={np.std(otc_bil_rdm):.3f}, N={len(otc_bil_rdm)}\")\n",
    "            print(f\"  Controls: M={np.mean(ctrl_bil_rdm):.3f}, SD={np.std(ctrl_bil_rdm):.3f}, N={len(ctrl_bil_rdm)}\")\n",
    "            print(f\"  t({len(otc_bil_rdm)+len(ctrl_bil_rdm)-2})={t_stat:.2f}, p={p_val:.4f}, d={d:.2f}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STATISTICAL SUMMARY COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\\nNOTE: With small N and heterogeneity, interpret with caution.\")\n",
    "    print(\"Consider bootstrapping or permutation tests for robustness.\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run statistics\n",
    "stats_results = compute_statistics_for_analyses(df_hybrid, df_drift, df_rdm, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08795dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Bootstrap & Permutation Statistics\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "\n",
    "def bootstrap_case_series(df, n_boot=10000):\n",
    "    \"\"\"Bootstrap confidence intervals for heterogeneous case data\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        for cat_type in ['Asymmetric', 'Bilateral']:\n",
    "            data = df[(df['Group'] == group) & (df['Type'] == cat_type)]['Stability (r)'].values\n",
    "            \n",
    "            if len(data) < 3:\n",
    "                continue\n",
    "            \n",
    "            # Bootstrap individual subjects with replacement\n",
    "            boot_means = []\n",
    "            for _ in range(n_boot):\n",
    "                # Resample subjects, not observations\n",
    "                subjects = df[(df['Group'] == group) & (df['Type'] == cat_type)]['Subject'].unique()\n",
    "                boot_subjects = np.random.choice(subjects, size=len(subjects), replace=True)\n",
    "                \n",
    "                boot_data = []\n",
    "                for subj in boot_subjects:\n",
    "                    subj_data = df[(df['Subject'] == subj) & (df['Type'] == cat_type)]['Stability (r)'].values\n",
    "                    if len(subj_data) > 0:\n",
    "                        boot_data.extend(subj_data)\n",
    "                \n",
    "                if boot_data:\n",
    "                    boot_means.append(np.mean(boot_data))\n",
    "            \n",
    "            if boot_means:\n",
    "                results[f\"{group}_{cat_type}\"] = {\n",
    "                    'mean': np.mean(data),\n",
    "                    'CI_2.5': np.percentile(boot_means, 2.5),\n",
    "                    'CI_97.5': np.percentile(boot_means, 97.5),\n",
    "                    'SE': np.std(boot_means)\n",
    "                }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def permutation_test_cases(df, group1='OTC', group2='control', n_perm=10000):\n",
    "    \"\"\"Permutation test for case-control differences\"\"\"\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for cat_type in ['Asymmetric', 'Bilateral']:\n",
    "        g1_data = df[(df['Group'] == group1) & (df['Type'] == cat_type)]['Stability (r)'].values\n",
    "        g2_data = df[(df['Group'] == group2) & (df['Type'] == cat_type)]['Stability (r)'].values\n",
    "        \n",
    "        if len(g1_data) < 2 or len(g2_data) < 2:\n",
    "            continue\n",
    "        \n",
    "        obs_diff = np.mean(g1_data) - np.mean(g2_data)\n",
    "        combined = np.concatenate([g1_data, g2_data])\n",
    "        \n",
    "        perm_diffs = []\n",
    "        for _ in range(n_perm):\n",
    "            np.random.shuffle(combined)\n",
    "            perm_g1 = combined[:len(g1_data)]\n",
    "            perm_g2 = combined[len(g1_data):]\n",
    "            perm_diffs.append(np.mean(perm_g1) - np.mean(perm_g2))\n",
    "        \n",
    "        p_value = np.mean(np.abs(perm_diffs) >= np.abs(obs_diff))\n",
    "        \n",
    "        results[cat_type] = {\n",
    "            'observed_diff': obs_diff,\n",
    "            'p_value': p_value,\n",
    "            'effect_size': obs_diff / np.std(combined)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run analyses\n",
    "boot_results = bootstrap_case_series(df_hybrid)\n",
    "perm_results = permutation_test_cases(df_hybrid)\n",
    "\n",
    "print(\"BOOTSTRAP 95% CIs:\")\n",
    "for key, vals in boot_results.items():\n",
    "    print(f\"{key}: {vals['mean']:.3f} [{vals['CI_2.5']:.3f}, {vals['CI_97.5']:.3f}]\")\n",
    "\n",
    "print(\"\\nPERMUTATION TESTS (OTC vs Control):\")\n",
    "for cat, vals in perm_results.items():\n",
    "    print(f\"{cat}: diff={vals['observed_diff']:.3f}, p={vals['p_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ecce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Individual Trajectory Modeling\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def model_individual_trajectories(functional_results, subjects, df_hybrid):\n",
    "    \"\"\"Model each patient's trajectory separately\"\"\"\n",
    "    \n",
    "    individual_slopes = []\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (sid, info) in enumerate(list(subjects.items())[:8]):\n",
    "        if info['group'] != 'OTC':\n",
    "            continue\n",
    "            \n",
    "        # Get this subject's data across sessions\n",
    "        subj_data = df_hybrid[df_hybrid['Subject'] == info['code']]\n",
    "        \n",
    "        if len(subj_data) < 2:\n",
    "            continue\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        for cat_type, color in [('Asymmetric', 'red'), ('Bilateral', 'blue')]:\n",
    "            type_data = subj_data[subj_data['Type'] == cat_type]\n",
    "            \n",
    "            if len(type_data) > 1:\n",
    "                # Simple linear model per category\n",
    "                X = np.arange(len(type_data)).reshape(-1, 1)\n",
    "                y = type_data['Stability (r)'].values\n",
    "                \n",
    "                model = LinearRegression()\n",
    "                model.fit(X, y)\n",
    "                slope = model.coef_[0]\n",
    "                \n",
    "                ax.scatter(X, y, color=color, s=50)\n",
    "                ax.plot(X, model.predict(X), color=color, alpha=0.5, \n",
    "                       label=f\"{cat_type[:4]}: slope={slope:.3f}\")\n",
    "                \n",
    "                individual_slopes.append({\n",
    "                    'Subject': info['code'],\n",
    "                    'Type': cat_type,\n",
    "                    'Slope': slope,\n",
    "                    'N_sessions': len(type_data)\n",
    "                })\n",
    "        \n",
    "        ax.set_title(f\"{info['code']}\")\n",
    "        ax.set_ylabel(\"Stability (r)\")\n",
    "        ax.set_xlabel(\"Session\")\n",
    "        ax.legend(fontsize=8)\n",
    "        ax.set_ylim(-0.2, 1.0)\n",
    "    \n",
    "    plt.suptitle(\"Individual Patient Trajectories\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Summary of slopes\n",
    "    slopes_df = pd.DataFrame(individual_slopes)\n",
    "    print(\"\\nINDIVIDUAL TRAJECTORY SLOPES:\")\n",
    "    print(slopes_df.pivot(index='Subject', columns='Type', values='Slope'))\n",
    "    \n",
    "    return slopes_df\n",
    "\n",
    "slopes = model_individual_trajectories(golarai_functional_final, ANALYSIS_SUBJECTS, df_hybrid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63784521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Hierarchical Linear Model\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.regression.mixed_linear_model import MixedLM\n",
    "\n",
    "def hierarchical_model(df_traj):\n",
    "    \"\"\"Mixed-effects model accounting for within-subject correlation\"\"\"\n",
    "    \n",
    "    # Prepare data\n",
    "    model_data = df_traj[df_traj['Group'] == 'OTC'].copy()\n",
    "    model_data['Session_Num'] = model_data['Session_Index']\n",
    "    model_data['Is_Bilateral'] = (model_data['Type'] == 'Bilateral').astype(int)\n",
    "    \n",
    "    # Mixed model: Value ~ Session + Type + (1|Subject)\n",
    "    model = MixedLM.from_formula(\n",
    "        'Value ~ Session_Num * Is_Bilateral', \n",
    "        model_data[model_data['Metric'] == 'Stability (r)'],\n",
    "        groups=model_data[model_data['Metric'] == 'Stability (r)']['Subject']\n",
    "    )\n",
    "    \n",
    "    result = model.fit()\n",
    "    print(result.summary())\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run if longitudinal data exists\n",
    "if 'df_traj' in locals():\n",
    "    hlm_result = hierarchical_model(df_traj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7de08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 24: Generate Detailed Category Table (Group x Hemi x Category)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def generate_detailed_marlene_table(df_drift, df_hybrid, df_rdm, subjects):\n",
    "    print(\"Generating Detailed Category Breakdown...\")\n",
    "    \n",
    "    # 1. Helper to define \"Hemisphere\" logic\n",
    "    def get_hemi_label(row):\n",
    "        code = row['Subject']\n",
    "        # Find subject info\n",
    "        for sid, info in subjects.items():\n",
    "            if info['code'] == code:\n",
    "                if info['group'] == 'control':\n",
    "                    return \"Control (Both)\" # Controls use both hemis\n",
    "                elif info['group'] == 'OTC':\n",
    "                    # Return the PRESERVED hemisphere\n",
    "                    return f\"OTC {info['hemi'].upper()} (Preserved)\"\n",
    "                elif info['group'] == 'nonOTC':\n",
    "                    return f\"nonOTC {info['hemi'].upper()} (Preserved)\"\n",
    "        return \"Unknown\"\n",
    "\n",
    "    # 2. Process Dataframes\n",
    "    # We create a unified list of metrics to merge later\n",
    "    dfs_to_process = [\n",
    "        (df_drift, 'Drift (mm)'),\n",
    "        (df_hybrid, 'Stability (r)'),\n",
    "        (df_rdm, 'RDM Stability (r)')\n",
    "    ]\n",
    "    \n",
    "    summary_parts = []\n",
    "    \n",
    "    for df, metric_name in dfs_to_process:\n",
    "        if df is None or df.empty: continue\n",
    "        \n",
    "        # Add Hemi Label\n",
    "        df_mod = df.copy()\n",
    "        df_mod['Sub_Group'] = df_mod.apply(get_hemi_label, axis=1)\n",
    "        \n",
    "        # Group by Sub_Group and Category\n",
    "        # Calculate Mean and Count (N)\n",
    "        agg = df_mod.groupby(['Sub_Group', 'Category'])[metric_name].agg(['mean', 'std', 'count']).round(3)\n",
    "        \n",
    "        # Rename columns to include the metric name\n",
    "        agg = agg.rename(columns={\n",
    "            'mean': f'{metric_name}_Mean',\n",
    "            'std': f'{metric_name}_SD',\n",
    "            'count': f'{metric_name}_N'\n",
    "        })\n",
    "        \n",
    "        summary_parts.append(agg)\n",
    "    \n",
    "    # 3. Merge everything into one Master Table\n",
    "    if summary_parts:\n",
    "        final_table = pd.concat(summary_parts, axis=1)\n",
    "        \n",
    "        # 4. Display\n",
    "        print(\"\\n\" + \"=\"*120)\n",
    "        print(\"FINAL DETAILED RESULTS: Group x Hemisphere x Category\")\n",
    "        print(\"=\"*120)\n",
    "        print(final_table)\n",
    "        \n",
    "        # 5. Export for Marlene (Optional CSV)\n",
    "        # final_table.to_csv(OUTPUT_DIR / \"summary_results_category_breakdown.csv\")\n",
    "        return final_table\n",
    "    else:\n",
    "        print(\"No dataframes available to summarize.\")\n",
    "\n",
    "# Execute\n",
    "if 'df_drift' in locals() and 'df_hybrid' in locals() and 'df_rdm' in locals():\n",
    "    detailed_table = generate_detailed_marlene_table(df_drift, df_hybrid, df_rdm, ANALYSIS_SUBJECTS)\n",
    "else:\n",
    "    print(\"⚠️ Missing dataframes. Please run Cells 5, 6, and 7 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b86767b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL 27: Nordt-Style Analysis (Drift, RSA, Volume, Selectivity)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "def analyze_nordt_pipeline(functional_results, subjects, min_voxels=30):\n",
    "    print(\"Running Full Nordt Pipeline (Dynamic ROIs)...\")\n",
    "    \n",
    "    # Config\n",
    "    RDM_CATS = ['face', 'house', 'object', 'word']\n",
    "    EXTRACTION_MAP = {'face': 10, 'house': 11, 'object': 3, 'word': 12}\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for sid, res in functional_results.items():\n",
    "        if sid not in subjects: continue\n",
    "        info = subjects[sid]\n",
    "        \n",
    "        # Determine Hemi Label\n",
    "        if info['group'] == 'control':\n",
    "            hemi_label = 'Both'\n",
    "        else:\n",
    "            hemi_label = info['hemi'].upper() # Preserved Hemi\n",
    "            \n",
    "        sessions = sorted(list({s for r in res.values() for s in r.keys()}))\n",
    "        if len(sessions) < 2: continue\n",
    "        first, last = sessions[0], sessions[-1]\n",
    "        \n",
    "        for roi_name, roi_data in res.items():\n",
    "            hemi_prefix, cat = roi_name.split('_')\n",
    "            \n",
    "            # Filter for Preserved Hemi in patients\n",
    "            if info['group'] != 'control' and hemi_prefix != info['hemi']:\n",
    "                continue\n",
    "            \n",
    "            if first not in roi_data or last not in roi_data: continue\n",
    "            \n",
    "            # DYNAMIC MASKS\n",
    "            m1 = roi_data[first]['roi_mask']\n",
    "            m2 = roi_data[last]['roi_mask']\n",
    "            if np.sum(m1) < min_voxels or np.sum(m2) < min_voxels: continue\n",
    "            \n",
    "            try:\n",
    "                # 1. DRIFT (Spatial)\n",
    "                c1 = np.array(roi_data[first]['centroid'])\n",
    "                c2 = np.array(roi_data[last]['centroid'])\n",
    "                drift = np.linalg.norm(c2 - c1)\n",
    "                \n",
    "                # 2. UNIVARIATE: VOLUME (Voxels)\n",
    "                vol1 = np.sum(m1)\n",
    "                vol2 = np.sum(m2)\n",
    "                vol_change = vol2 - vol1\n",
    "                \n",
    "                # 3. UNIVARIATE: SELECTIVITY (Mean Z of Preferred Category)\n",
    "                # Load First\n",
    "                f1 = BASE_DIR/sid/f'ses-{first}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[cat]}.feat'/'stats'/'zstat1.nii.gz'\n",
    "                z1 = nib.load(f1).get_fdata()[m1]\n",
    "                sel1 = np.mean(z1)\n",
    "                \n",
    "                # Load Last\n",
    "                f2 = BASE_DIR/sid/f'ses-{last}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[cat]}.feat'/'stats'/f'zstat1_ses{first}.nii.gz'\n",
    "                z2 = nib.load(f2).get_fdata()[m2] # Use NEW mask\n",
    "                sel2 = np.mean(z2)\n",
    "                sel_change = sel2 - sel1\n",
    "                \n",
    "                # 4. MULTIVARIATE: RSA STABILITY (Geometry)\n",
    "                # (Same logic as Cell 7/24)\n",
    "                feats1 = []\n",
    "                feats2 = []\n",
    "                for c in RDM_CATS:\n",
    "                    f = BASE_DIR/sid/f'ses-{first}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/'zstat1.nii.gz'\n",
    "                    feats1.append(nib.load(f).get_fdata()[m1])\n",
    "                    \n",
    "                    z_name = f'zstat1_ses{first}.nii.gz'\n",
    "                    f = BASE_DIR/sid/f'ses-{last}'/'derivatives'/'fsl'/'loc'/'HighLevel.gfeat'/f'cope{EXTRACTION_MAP[c]}.feat'/'stats'/z_name\n",
    "                    feats2.append(nib.load(f).get_fdata()[m2])\n",
    "                \n",
    "                rdm1 = 1 - np.corrcoef(np.array(feats1))\n",
    "                rdm2 = 1 - np.corrcoef(np.array(feats2))\n",
    "                # Fix Symmetry\n",
    "                rdm1 = (rdm1 + rdm1.T)/2; np.fill_diagonal(rdm1, 0)\n",
    "                rdm2 = (rdm2 + rdm2.T)/2; np.fill_diagonal(rdm2, 0)\n",
    "                \n",
    "                rsa_stab = np.corrcoef(squareform(rdm1), squareform(rdm2))[0,1]\n",
    "                \n",
    "                # STORE\n",
    "                data.append({\n",
    "                    'Subject': info['code'],\n",
    "                    'Group': info['group'],\n",
    "                    'Preserved Hemi': hemi_label,\n",
    "                    'Category': cat.capitalize(),\n",
    "                    'Drift (mm)': drift,\n",
    "                    'RSA Stability (r)': rsa_stab,\n",
    "                    'Vol S1': vol1, 'Vol SLast': vol2, 'Vol Change': vol_change,\n",
    "                    'Sel S1': sel1, 'Sel SLast': sel2, 'Sel Change': sel_change\n",
    "                })\n",
    "                \n",
    "            except: pass\n",
    "\n",
    "    # --- SUMMARY TABLE ---\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # We want Mean of metrics\n",
    "    summary = df.groupby(['Group', 'Preserved Hemi', 'Category'])[['Drift (mm)', 'RSA Stability (r)', 'Vol Change', 'Sel Change']].mean().round(3)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"NORDT PIPELINE SUMMARY (Dynamic ROIs)\")\n",
    "    print(\"Metrics: Drift, RSA Stability, Volume Change, Selectivity Change\")\n",
    "    print(\"=\"*100)\n",
    "    print(summary)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Run it\n",
    "df_nordt = analyze_nordt_pipeline(golarai_functional_final, ANALYSIS_SUBJECTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c44f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Standard Statistics - Group Comparisons\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load data and clean\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "\n",
    "# Remove control duplicates (average hemispheres)\n",
    "df_clean = df.groupby(['Subject', 'Category', 'Category_Type', 'Group']).agg({\n",
    "    'Hybrid_Stability': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean', \n",
    "    'RDM_Stability': 'mean',\n",
    "    'Liu_Distinctiveness': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Group means and SEM\n",
    "def group_stats(df, metric):\n",
    "    stats_table = df.groupby(['Group', 'Category_Type'])[metric].agg([\n",
    "        'count', 'mean', 'std', lambda x: stats.sem(x)\n",
    "    ]).round(3)\n",
    "    stats_table.columns = ['n', 'mean', 'sd', 'sem']\n",
    "    return stats_table\n",
    "\n",
    "# T-tests: OTC vs Controls, Bilateral vs Unilateral\n",
    "def run_ttests(df, metric):\n",
    "    results = {}\n",
    "    \n",
    "    # OTC bilateral vs control bilateral  \n",
    "    otc_bil = df[(df['Group']=='OTC') & (df['Category_Type']=='Bilateral')][metric].dropna()\n",
    "    ctrl_bil = df[(df['Group']=='control') & (df['Category_Type']=='Bilateral')][metric].dropna()\n",
    "    t1, p1 = stats.ttest_ind(otc_bil, ctrl_bil)\n",
    "    \n",
    "    # OTC unilateral vs control unilateral\n",
    "    otc_uni = df[(df['Group']=='OTC') & (df['Category_Type']=='Asymmetric')][metric].dropna() \n",
    "    ctrl_uni = df[(df['Group']=='control') & (df['Category_Type']=='Asymmetric')][metric].dropna()\n",
    "    t2, p2 = stats.ttest_ind(otc_uni, ctrl_uni)\n",
    "    \n",
    "    # Within OTC: bilateral vs unilateral\n",
    "    t3, p3 = stats.ttest_ind(otc_bil, otc_uni)\n",
    "    \n",
    "    return {\n",
    "        'OTC_bil_vs_ctrl_bil': (t1, p1),\n",
    "        'OTC_uni_vs_ctrl_uni': (t2, p2), \n",
    "        'OTC_bil_vs_uni': (t3, p3)\n",
    "    }\n",
    "\n",
    "# Run for Liu Distinctiveness\n",
    "print(\"LIU DISTINCTIVENESS ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "print(\"\\nGroup Means:\")\n",
    "print(group_stats(df_clean, 'Liu_Distinctiveness'))\n",
    "\n",
    "print(\"\\nT-tests:\")\n",
    "ttests = run_ttests(df_clean, 'Liu_Distinctiveness')\n",
    "for test, (t, p) in ttests.items():\n",
    "    sig = \"*\" if p < 0.05 else \"ns\"\n",
    "    print(f\"{test}: t={t:.2f}, p={p:.3f} {sig}\")\n",
    "\n",
    "# Simple bar plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(data=df_clean, x='Category_Type', y='Liu_Distinctiveness', hue='Group',\n",
    "           palette={'OTC': 'red', 'nonOTC': 'orange', 'control': 'blue'})\n",
    "plt.title('Representational Change by Group and Category Type')\n",
    "plt.ylabel('Liu Distinctiveness Change')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba468d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Comprehensive Statistics - All Metrics + Demographics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load and clean data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "\n",
    "# Demographics from CSV\n",
    "demographics_raw = \"\"\"sub,DOB,age_1,age_2,age_3,age_4,age_5,group,Sex,SurgerySide,intact_hemi,loc,OTC,scanner,pre_post_sx,patient\n",
    "sub-004,4/12/06,7.808,8.369,8.825,10.825,13.075,OTC,Male,right,left,3,1,verio,0,1\n",
    "sub-008,11/13/99,14.775,17.897,,,,OTC,Female,right,left,2,1,verio,0,1\n",
    "sub-010,12/17/04,12.8,14.3,,,,OTC,Male,left,right,3,1,verio,0,1\n",
    "sub-017,11/3/99,15.7,15.7,16.2,18.6,,OTC,Male,left,right,3,1,verio,0,1\n",
    "sub-021,11/3/99,13.3,13.9,,,,OTC,Female,left,right,3,1,verio,1,1\n",
    "sub-007,8/27/99,14.703,17.614,18.428,,,nonOTC,Male,left,right,2,0,verio,0,1\n",
    "sub-045,11/3/99,15.29166667,15.67777778,16.29166667,,,nonOTC,Male,left,right,3,0,verio,1,1\n",
    "sub-047,1/10/04,14.9,15.4,,,,nonOTC,Male,right,left,3,0,verio,1,1\n",
    "sub-049,5/20/05,13.6,14.4,,,,nonOTC,Female,right,left,3,0,verio,1,1\n",
    "sub-070,3/27/04,15.7,16.7,,,,nonOTC,Female,left,right,3,0,prisma,1,1\n",
    "sub-072,5/5/01,18.7,20,,,,nonOTC,Male,right,left,3,0,prisma,1,1\n",
    "sub-073,11/18/09,10.3,10.9,,,,nonOTC,Female,right,left,3,0,prisma,1,1\n",
    "sub-081,8/24/06,14.6,15,,,,nonOTC,Female,left,right,3,0,prisma,1,1\n",
    "sub-086,3/22/06,15.3,15.9,,,,nonOTC,Female,right,left,3,0,prisma,1,1\n",
    "sub-018,1/28/03,12.9,15.4,,,,control,Male,control,control,3,0,verio,0,0\n",
    "sub-022,10/17/05,11.5,15,,,,control,Male,control,control,3,0,verio,0,0\n",
    "sub-025,5/13/08,9,11,,,,control,Male,control,control,3,0,3rd in prisma,0,0\n",
    "sub-027,5/19/09,7.9,10.4,,,,control,Male,control,control,3,0,verio,0,0\n",
    "sub-052,8/21/04,14.4,16,,,,control,Male,control,control,3,0,verio,0,0\n",
    "sub-058,2/2/98,10.2,11.5,,,,control,Female,control,control,3,0,verio,0,0\n",
    "sub-062,9/26/04,14.9,15.9,,,,control,Female,control,control,3,0,verio,0,0\n",
    "sub-064,11/28/07,11.8,12.8,,,,control,Female,control,control,3,0,verio,0,0\n",
    "sub-068,1/18/09,12.9,13.4,,,,control,Female,control,control,3,0,prisma_verio,0,0\"\"\"\n",
    "\n",
    "from io import StringIO\n",
    "demo_df = pd.read_csv(StringIO(demographics_raw))\n",
    "\n",
    "# Clean data - average control hemispheres\n",
    "df_clean = df.groupby(['Subject', 'Category', 'Category_Type', 'Group']).agg({\n",
    "    'Hybrid_Stability': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean', \n",
    "    'RDM_Stability': 'mean',\n",
    "    'Liu_Distinctiveness': 'mean',\n",
    "    'Surgery_Side': 'first',\n",
    "    'Sex': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "def comprehensive_stats(df, metric):\n",
    "    \"\"\"Complete statistical analysis for one metric\"\"\"\n",
    "    print(f\"\\n{metric.upper()} ANALYSIS\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Group means\n",
    "    print(\"GROUP × CATEGORY TYPE MEANS (SEM):\")\n",
    "    for group in ['OTC', 'nonOTC', 'control']:\n",
    "        for cat_type in ['Asymmetric', 'Bilateral']:\n",
    "            data = df[(df['Group']==group) & (df['Category_Type']==cat_type)][metric].dropna()\n",
    "            if len(data) > 0:\n",
    "                mean_val = data.mean()\n",
    "                sem_val = stats.sem(data)\n",
    "                print(f\"  {group} {cat_type}: {mean_val:.3f} (±{sem_val:.3f}), n={len(data)}\")\n",
    "    \n",
    "    # T-tests\n",
    "    print(\"\\nSTATISTICAL TESTS:\")\n",
    "    \n",
    "    # 1. OTC bilateral vs unilateral\n",
    "    otc_bil = df[(df['Group']=='OTC') & (df['Category_Type']=='Bilateral')][metric].dropna()\n",
    "    otc_uni = df[(df['Group']=='OTC') & (df['Category_Type']=='Asymmetric')][metric].dropna()\n",
    "    t1, p1 = stats.ttest_ind(otc_bil, otc_uni)\n",
    "    d1 = (otc_bil.mean() - otc_uni.mean()) / np.sqrt((otc_bil.var() + otc_uni.var()) / 2)\n",
    "    print(f\"  OTC Bilateral vs Unilateral: t={t1:.2f}, p={p1:.3f}, d={d1:.2f}\")\n",
    "    \n",
    "    # 2. Controls bilateral vs unilateral  \n",
    "    ctrl_bil = df[(df['Group']=='control') & (df['Category_Type']=='Bilateral')][metric].dropna()\n",
    "    ctrl_uni = df[(df['Group']=='control') & (df['Category_Type']=='Asymmetric')][metric].dropna()\n",
    "    t2, p2 = stats.ttest_ind(ctrl_bil, ctrl_uni)\n",
    "    d2 = (ctrl_bil.mean() - ctrl_uni.mean()) / np.sqrt((ctrl_bil.var() + ctrl_uni.var()) / 2)\n",
    "    print(f\"  Control Bilateral vs Unilateral: t={t2:.2f}, p={p2:.3f}, d={d2:.2f}\")\n",
    "    \n",
    "    # 3. OTC vs controls (bilateral)\n",
    "    t3, p3 = stats.ttest_ind(otc_bil, ctrl_bil)\n",
    "    d3 = (otc_bil.mean() - ctrl_bil.mean()) / np.sqrt((otc_bil.var() + ctrl_bil.var()) / 2)\n",
    "    print(f\"  OTC vs Control (Bilateral): t={t3:.2f}, p={p3:.3f}, d={d3:.2f}\")\n",
    "    \n",
    "    # 4. OTC vs controls (unilateral)\n",
    "    t4, p4 = stats.ttest_ind(otc_uni, ctrl_uni) \n",
    "    d4 = (otc_uni.mean() - ctrl_uni.mean()) / np.sqrt((otc_uni.var() + ctrl_uni.var()) / 2)\n",
    "    print(f\"  OTC vs Control (Unilateral): t={t4:.2f}, p={p4:.3f}, d={d4:.2f}\")\n",
    "\n",
    "# DEMOGRAPHICS TABLE\n",
    "print(\"DEMOGRAPHICS\")\n",
    "print(\"=\"*50)\n",
    "print(\"GROUP BREAKDOWN:\")\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    group_demo = demo_df[demo_df['group'] == group]\n",
    "    n_total = len(group_demo)\n",
    "    n_female = len(group_demo[group_demo['Sex'] == 'Female'])\n",
    "    n_male = len(group_demo[group_demo['Sex'] == 'Male'])\n",
    "    \n",
    "    if group != 'control':\n",
    "        n_left_resect = len(group_demo[group_demo['SurgerySide'] == 'left'])\n",
    "        n_right_resect = len(group_demo[group_demo['SurgerySide'] == 'right'])\n",
    "        ages = [group_demo['age_1'].mean(), group_demo['age_1'].std()]\n",
    "        print(f\"  {group}: n={n_total}, {n_female}F/{n_male}M, {n_left_resect}L/{n_right_resect}R resection\")\n",
    "        print(f\"    Baseline age: {ages[0]:.1f}±{ages[1]:.1f}\")\n",
    "    else:\n",
    "        ages = [group_demo['age_1'].mean(), group_demo['age_1'].std()]\n",
    "        print(f\"  {group}: n={n_total}, {n_female}F/{n_male}M\")\n",
    "        print(f\"    Baseline age: {ages[0]:.1f}±{ages[1]:.1f}\")\n",
    "\n",
    "print(\"\\nHEMISPHERE BREAKDOWN (for Marlene's request):\")\n",
    "print(\"  Controls: Both hemispheres analyzed\")\n",
    "print(\"  OTC Left resection (right hemisphere intact): n=3\")  \n",
    "print(\"  OTC Right resection (left hemisphere intact): n=2\")\n",
    "print(\"  nonOTC Left resection: n=4, Right resection: n=5\")\n",
    "\n",
    "# RUN ALL ANALYSES\n",
    "for metric in ['Liu_Distinctiveness', 'Spatial_Drift_mm', 'Hybrid_Stability', 'RDM_Stability']:\n",
    "    if metric in df_clean.columns and df_clean[metric].notna().sum() > 0:\n",
    "        comprehensive_stats(df_clean, metric)\n",
    "\n",
    "# HEMISPHERE-SPECIFIC ANALYSIS (Marlene's request)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"HEMISPHERE × CATEGORY ANALYSIS (Marlene's request)\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Face and Word by hemisphere\n",
    "for metric in ['Liu_Distinctiveness', 'Spatial_Drift_mm']:\n",
    "    if metric not in df.columns:\n",
    "        continue\n",
    "    print(f\"\\n{metric}:\")\n",
    "    \n",
    "    for category in ['Face', 'Word']:\n",
    "        cat_data = df[df['Category'] == category]\n",
    "        \n",
    "        print(f\"  {category}:\")\n",
    "        \n",
    "        # OTC by surgery side\n",
    "        for side in ['left', 'right']:\n",
    "            otc_data = cat_data[(cat_data['Group']=='OTC') & (cat_data['Surgery_Side']==side)][metric].dropna()\n",
    "            if len(otc_data) > 0:\n",
    "                print(f\"    OTC {side} resection: {otc_data.mean():.3f} (n={len(otc_data)})\")\n",
    "        \n",
    "        # Controls (both hemispheres)\n",
    "        ctrl_data = cat_data[cat_data['Group']=='control'][metric].dropna()\n",
    "        if len(ctrl_data) > 0:\n",
    "            print(f\"    Controls: {ctrl_data.mean():.3f} (n={len(ctrl_data)})\")\n",
    "\n",
    "print(\"\\n✓ Comprehensive analysis complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3963952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Comprehensive Plotting - All Four Metrics by Category and Group\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "\n",
    "# Clean data - average control hemispheres\n",
    "df_plot = df.groupby(['Subject', 'Category', 'Group']).agg({\n",
    "    'Liu_Distinctiveness': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean',\n",
    "    'Hybrid_Stability': 'mean', \n",
    "    'RDM_Stability': 'mean'\n",
    "}).reset_index().dropna()\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Plot parameters\n",
    "colors = {'OTC': '#ff6b6b', 'nonOTC': '#4ecdc4', 'control': '#95a5a6'}\n",
    "metrics = [\n",
    "    ('Liu_Distinctiveness', 'Between-Category RSA Change'),\n",
    "    ('Spatial_Drift_mm', 'Spatial Drift (mm)'),\n",
    "    ('Hybrid_Stability', 'Pattern Stability (Fixed ROI)'),\n",
    "    ('RDM_Stability', 'RDM Stability (Geometry)')\n",
    "]\n",
    "\n",
    "for i, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    # Create barplot\n",
    "    sns.barplot(data=df_plot, x='Category', y=metric, hue='Group', \n",
    "               palette=colors, ax=ax, errorbar='se', capsize=0.1)\n",
    "    \n",
    "    # Customize\n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Visual Category', fontsize=12)\n",
    "    ax.set_ylabel(title.split('(')[0], fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Add significance indicators for bilateral categories\n",
    "    if i == 0:  # RSA plot\n",
    "        ax.text(2.5, ax.get_ylim()[1]*0.9, 'Bilateral > Unilateral\\nin OTC (p=0.019)', \n",
    "                ha='center', fontweight='bold', bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics table\n",
    "print(\"CATEGORY-SPECIFIC MEANS BY GROUP\")\n",
    "print(\"=\"*50)\n",
    "for metric, title in metrics:\n",
    "    print(f\"\\n{title}:\")\n",
    "    summary = df_plot.groupby(['Group', 'Category'])[metric].agg(['mean', 'std', 'count']).round(3)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c918946b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Individual OTC Subject Plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "df_plot = df.groupby(['Subject', 'Category', 'Group']).agg({\n",
    "    'Liu_Distinctiveness': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean',\n",
    "    'Hybrid_Stability': 'mean', \n",
    "    'RDM_Stability': 'mean'\n",
    "}).reset_index().dropna()\n",
    "\n",
    "# Create modified group labels - individual OTC subjects\n",
    "df_plot['Plot_Group'] = df_plot['Group'].copy()\n",
    "df_plot.loc[df_plot['Group'] == 'OTC', 'Plot_Group'] = df_plot.loc[df_plot['Group'] == 'OTC', 'Subject']\n",
    "\n",
    "# Color mapping\n",
    "colors = {'nonOTC': '#4ecdc4', 'control': '#95a5a6', \n",
    "         'OTC004': '#ff4444', 'OTC008': '#ff6b6b', 'OTC010': '#ff9999', \n",
    "         'OTC017': '#ffaaaa', 'OTC021': '#ffcccc'}\n",
    "\n",
    "metrics = [\n",
    "    ('Liu_Distinctiveness', 'Between-Category RSA Change'),\n",
    "    ('Spatial_Drift_mm', 'Spatial Drift (mm)'),\n",
    "    ('Hybrid_Stability', 'Pattern Stability (Fixed ROI)'),\n",
    "    ('RDM_Stability', 'RDM Stability (Geometry)')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    sns.barplot(data=df_plot, x='Category', y=metric, hue='Plot_Group', \n",
    "               palette=colors, ax=ax, errorbar='se', capsize=0.05)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Visual Category', fontsize=12)\n",
    "    ax.set_ylabel(title.split('(')[0], fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Move legend outside\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print individual OTC values\n",
    "print(\"INDIVIDUAL OTC SUBJECT VALUES\")\n",
    "print(\"=\"*40)\n",
    "otc_data = df_plot[df_plot['Group'] == 'OTC']\n",
    "for metric, title in metrics:\n",
    "    print(f\"\\n{title}:\")\n",
    "    for subject in ['OTC004', 'OTC008', 'OTC010', 'OTC017', 'OTC021']:\n",
    "        subj_data = otc_data[otc_data['Subject'] == subject]\n",
    "        if len(subj_data) > 0:\n",
    "            print(f\"  {subject}: {subj_data.groupby('Category')[metric].mean().round(3).to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d448aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Hemisphere-Split Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Load and prepare data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "\n",
    "# Clean data - average control hemispheres\n",
    "df_plot = df.groupby(['Subject', 'Category', 'Group', 'Surgery_Side']).agg({\n",
    "    'Liu_Distinctiveness': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean',\n",
    "    'Hybrid_Stability': 'mean', \n",
    "    'RDM_Stability': 'mean'\n",
    "}).reset_index().dropna()\n",
    "\n",
    "# Create hemisphere-specific groups\n",
    "df_plot['Hemi_Group'] = df_plot['Group'].copy()\n",
    "df_plot.loc[df_plot['Group'].isin(['OTC', 'nonOTC']), 'Hemi_Group'] = (\n",
    "    df_plot.loc[df_plot['Group'].isin(['OTC', 'nonOTC']), 'Group'] + '_' + \n",
    "    df_plot.loc[df_plot['Group'].isin(['OTC', 'nonOTC']), 'Surgery_Side']\n",
    ")\n",
    "\n",
    "# Color mapping\n",
    "colors = {\n",
    "    'OTC_left': '#ff4444',    # Dark red\n",
    "    'OTC_right': '#ff9999',   # Light red  \n",
    "    'nonOTC_left': '#0099cc', # Dark blue\n",
    "    'nonOTC_right': '#66ccff', # Light blue\n",
    "    'control': '#95a5a6'       # Gray\n",
    "}\n",
    "\n",
    "# Create 2x2 subplot layout\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "metrics = [\n",
    "    ('Liu_Distinctiveness', 'Between-Category RSA Change'),\n",
    "    ('Spatial_Drift_mm', 'Spatial Drift (mm)'),\n",
    "    ('Hybrid_Stability', 'Pattern Stability (Fixed ROI)'),\n",
    "    ('RDM_Stability', 'RDM Stability (Geometry)')\n",
    "]\n",
    "\n",
    "for i, (metric, title) in enumerate(metrics):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    sns.barplot(data=df_plot, x='Category', y=metric, hue='Hemi_Group', \n",
    "               palette=colors, ax=ax, errorbar='se', capsize=0.1)\n",
    "    \n",
    "    ax.set_title(title, fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Visual Category', fontsize=12)\n",
    "    ax.set_ylabel(title.split('(')[0], fontsize=12)\n",
    "    ax.tick_params(axis='x', rotation=45)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics by hemisphere\n",
    "print(\"HEMISPHERE-SPECIFIC MEANS\")\n",
    "print(\"=\"*40)\n",
    "for metric, title in metrics:\n",
    "    print(f\"\\n{title}:\")\n",
    "    summary = df_plot.groupby(['Hemi_Group', 'Category'])[metric].agg(['mean', 'count']).round(3)\n",
    "    print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5482cb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Rigorous RDM Investigation for Publication\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load raw CSV data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "\n",
    "# Extract RDM data only\n",
    "rdm_data = df[['Subject', 'Group', 'Category', 'Category_Type', 'RDM_Stability']].dropna()\n",
    "\n",
    "print(\"COMPREHENSIVE RDM STABILITY INVESTIGATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"1. RAW RDM VALUES BY SUBJECT AND CATEGORY:\")\n",
    "print(\"-\" * 45)\n",
    "pivot_table = rdm_data.pivot_table(values='RDM_Stability', \n",
    "                                  index=['Group', 'Subject'], \n",
    "                                  columns='Category', \n",
    "                                  aggfunc='mean')\n",
    "print(pivot_table.round(3))\n",
    "\n",
    "print(\"\\n2. NEGATIVE VALUES BREAKDOWN:\")\n",
    "print(\"-\" * 30)\n",
    "negatives = rdm_data[rdm_data['RDM_Stability'] < 0]\n",
    "print(f\"Total negative values: {len(negatives)}/{len(rdm_data)} ({len(negatives)/len(rdm_data)*100:.1f}%)\")\n",
    "\n",
    "for group in ['OTC', 'nonOTC', 'control']:\n",
    "    group_negs = negatives[negatives['Group'] == group]\n",
    "    group_total = rdm_data[rdm_data['Group'] == group]\n",
    "    print(f\"{group}: {len(group_negs)}/{len(group_total)} ({len(group_negs)/len(group_total)*100:.1f}%)\")\n",
    "    \n",
    "    if len(group_negs) > 0:\n",
    "        for _, row in group_negs.iterrows():\n",
    "            print(f\"  {row['Subject']} {row['Category']}: {row['RDM_Stability']:.3f}\")\n",
    "\n",
    "print(\"\\n3. DISTRIBUTION STATISTICS:\")\n",
    "print(\"-\" * 25)\n",
    "stats_by_group = rdm_data.groupby('Group')['RDM_Stability'].describe().round(3)\n",
    "print(stats_by_group)\n",
    "\n",
    "print(\"\\n4. CATEGORY TYPE ANALYSIS:\")\n",
    "print(\"-\" * 22)\n",
    "category_stats = rdm_data.groupby(['Group', 'Category_Type'])['RDM_Stability'].agg(['mean', 'std', 'min', 'max', 'count']).round(3)\n",
    "print(category_stats)\n",
    "\n",
    "print(\"\\n5. EXTREME VALUES (|r| > 0.8):\")\n",
    "print(\"-\" * 25)\n",
    "extreme = rdm_data[(rdm_data['RDM_Stability'] > 0.8) | (rdm_data['RDM_Stability'] < -0.5)]\n",
    "if len(extreme) > 0:\n",
    "    for _, row in extreme.iterrows():\n",
    "        print(f\"{row['Subject']} {row['Category']}: {row['RDM_Stability']:.3f}\")\n",
    "else:\n",
    "    print(\"None found\")\n",
    "\n",
    "# Visual analysis\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Distribution by group\n",
    "sns.boxplot(data=rdm_data, x='Group', y='RDM_Stability', ax=axes[0])\n",
    "axes[0].axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "axes[0].set_title('RDM Stability by Group')\n",
    "\n",
    "# Distribution by category type\n",
    "sns.boxplot(data=rdm_data, x='Group', y='RDM_Stability', hue='Category_Type', ax=axes[1])\n",
    "axes[1].axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "axes[1].set_title('RDM Stability by Category Type')\n",
    "\n",
    "# Individual category breakdown\n",
    "sns.boxplot(data=rdm_data, x='Category', y='RDM_Stability', hue='Group', ax=axes[2])\n",
    "axes[2].axhline(0, color='red', linestyle='--', alpha=0.7)\n",
    "axes[2].set_title('RDM Stability by Category')\n",
    "axes[2].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n6. VALIDATION AGAINST OTHER MEASURES:\")\n",
    "print(\"-\" * 35)\n",
    "# Merge with other measures\n",
    "validation_df = df.groupby(['Subject', 'Group']).agg({\n",
    "    'RDM_Stability': 'mean',\n",
    "    'Liu_Distinctiveness': 'mean', \n",
    "    'Hybrid_Stability': 'mean',\n",
    "    'Spatial_Drift_mm': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "correlations = validation_df[['RDM_Stability', 'Liu_Distinctiveness', 'Hybrid_Stability', 'Spatial_Drift_mm']].corr()\n",
    "print(\"Correlations with other measures:\")\n",
    "print(correlations['RDM_Stability'].drop('RDM_Stability').round(3))\n",
    "\n",
    "print(f\"\\nMETHODOLOGICAL VALIDITY:\")\n",
    "print(f\"- Range: {rdm_data['RDM_Stability'].min():.3f} to {rdm_data['RDM_Stability'].max():.3f}\")\n",
    "print(f\"- Negatives concentrated in OTC: {len(negatives[negatives['Group']=='OTC'])}/{len(negatives)} ({len(negatives[negatives['Group']=='OTC'])/len(negatives)*100:.0f}%)\")\n",
    "print(f\"- Systematic pattern supports genuine reorganization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21fb1043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CELL: Publication-Quality Heatmaps for RSA/RDM Results\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('/user_data/csimmon2/git_repos/long_pt/B_analyses/compiled_results.csv')\n",
    "df_clean = df.groupby(['Subject', 'Category', 'Group']).agg({\n",
    "    'Liu_Distinctiveness': 'mean',\n",
    "    'RDM_Stability': 'mean', \n",
    "    'Hybrid_Stability': 'mean'\n",
    "}).reset_index()\n",
    "\n",
    "# Create heatmap data for each metric\n",
    "metrics = [\n",
    "    ('Liu_Distinctiveness', 'RSA: Between-Category Change'),\n",
    "    ('RDM_Stability', 'RDM: Representational Geometry Stability'), \n",
    "    ('Hybrid_Stability', 'Pattern Stability: Fixed ROI')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 8))\n",
    "\n",
    "for i, (metric, title) in enumerate(metrics):\n",
    "    # Create pivot table\n",
    "    heatmap_data = df_clean.pivot_table(\n",
    "        values=metric, \n",
    "        index=['Group', 'Subject'], \n",
    "        columns='Category', \n",
    "        aggfunc='mean'\n",
    "    )\n",
    "    \n",
    "    # Custom colormap - diverging for RDM (has negatives), sequential for others\n",
    "    if metric == 'RDM_Stability':\n",
    "        cmap = 'RdBu_r'\n",
    "        center = 0\n",
    "        vmin, vmax = -0.8, 1.0\n",
    "    else:\n",
    "        cmap = 'viridis'\n",
    "        center = None\n",
    "        vmin, vmax = None, None\n",
    "    \n",
    "    # Create heatmap\n",
    "    sns.heatmap(heatmap_data, \n",
    "                annot=True, \n",
    "                fmt='.2f', \n",
    "                cmap=cmap,\n",
    "                center=center,\n",
    "                vmin=vmin, vmax=vmax,\n",
    "                cbar_kws={'label': metric.replace('_', ' ')},\n",
    "                ax=axes[i],\n",
    "                annot_kws={'size': 8})\n",
    "    \n",
    "    axes[i].set_title(title, fontsize=14, fontweight='bold')\n",
    "    axes[i].set_xlabel('Visual Category', fontsize=12)\n",
    "    axes[i].set_ylabel('Group | Subject', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table of negative values for publication\n",
    "print(\"NEGATIVE RDM VALUES FOR PUBLICATION:\")\n",
    "print(\"=\"*40)\n",
    "negatives = df_clean[df_clean['RDM_Stability'] < 0]\n",
    "print(f\"Frequency: {len(negatives)}/{len(df_clean[df_clean['RDM_Stability'].notna()])} ({len(negatives)/len(df_clean[df_clean['RDM_Stability'].notna()])*100:.1f}%)\")\n",
    "print(f\"Group distribution: OTC {len(negatives[negatives['Group']=='OTC'])}/18 (27.8%), Others {len(negatives[negatives['Group']!='OTC'])}/106 (9.4%)\")\n",
    "print(\"Interpretation: Representational geometry inversion indicating severe reorganization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc3148a",
   "metadata": {},
   "source": [
    "## Below is a playground"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

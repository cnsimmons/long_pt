{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal RSA Analysis: VOTC Category Selectivity\n",
    "\n",
    "**Contrasts**: COPE_MAP_SCRAMBLE (Category > Scrambled baseline)\n",
    "**ROI Threshold**: Top 10% of voxels (percentile=90) for better SNR\n",
    "\n",
    "**Measures**:\n",
    "- Geometry Preservation: RDM correlation T1↔T2 (higher = more stable)\n",
    "- Distinctiveness: Mean correlation preferred↔non-preferred (lower = more selective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Config loaded (SCRAMBLE, top-10%)\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Setup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, ttest_ind\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Paths\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "BASE_DIR = Path('/user_data/csimmon2/long_pt')\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# SCRAMBLE contrasts - all Category > Scrambled (consistent rationale)\n",
    "COPE_MAP = {\n",
    "    'face': (10, 1),\n",
    "    'word': (12, 1),\n",
    "    'object': (3, 1),\n",
    "    'house': (11, 1)\n",
    "}\n",
    "\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "SPHERE_RADIUS = 6\n",
    "ROI_PERCENTILE = 90  # Top 10% for better SNR\n",
    "MIN_CLUSTER = 20\n",
    "MIN_Z = 1.64\n",
    "\n",
    "print(\"✓ Config loaded (SCRAMBLE, top-10%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 25 subjects\n",
      "  OTC: 7\n",
      "  nonOTC: 9\n",
      "  control: 9\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load Subjects\n",
    "def load_subjects():\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sub']\n",
    "        subj_dir = BASE_DIR / sid\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        sessions = sorted([d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()], key=int)\n",
    "        start = SESSION_START.get(sid, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start]\n",
    "        if not sessions:\n",
    "            continue\n",
    "        \n",
    "        is_patient = row.get('patient', 0) == 1\n",
    "        if is_patient:\n",
    "            hemi = 'l' if row.get('intact_hemi', 'left') == 'left' else 'r'\n",
    "            group = row.get('group', 'unknown')\n",
    "        else:\n",
    "            hemi = 'l'\n",
    "            group = 'control'\n",
    "        \n",
    "        subjects[sid] = {\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemi,\n",
    "            'group': group,\n",
    "            'is_patient': is_patient\n",
    "        }\n",
    "    return subjects\n",
    "\n",
    "SUBJECTS = load_subjects()\n",
    "print(f\"✓ Loaded {len(SUBJECTS)} subjects\")\n",
    "for g in ['OTC', 'nonOTC', 'control']:\n",
    "    print(f\"  {g}: {sum(1 for v in SUBJECTS.values() if v['group'] == g)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Functions defined\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Core Functions\n",
    "\n",
    "def create_sphere(center_mni, affine, shape, radius=6):\n",
    "    i, j, k = np.meshgrid(np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]), indexing='ij')\n",
    "    voxel_coords = np.stack([i, j, k], axis=-1).reshape(-1, 3)\n",
    "    world_coords = nib.affines.apply_affine(affine, voxel_coords)\n",
    "    distances = np.linalg.norm(world_coords - center_mni, axis=1)\n",
    "    return (distances <= radius).reshape(shape)\n",
    "\n",
    "\n",
    "def extract_rois(cope_map, percentile=90, min_cluster=20, min_z=1.64):\n",
    "    \"\"\"Extract ROIs using top-N% threshold.\"\"\"\n",
    "    all_rois = {}\n",
    "    \n",
    "    for sid, info in SUBJECTS.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        if not roi_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        subject_rois = {}\n",
    "        \n",
    "        for hemi in ['l', 'r']:\n",
    "            for cat, (cope_num, mult) in cope_map.items():\n",
    "                mask_file = roi_dir / f'{hemi}_{cat}_searchmask.nii.gz'\n",
    "                if not mask_file.exists():\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mask_img = nib.load(mask_file)\n",
    "                    search_mask = mask_img.get_fdata() > 0\n",
    "                    affine = mask_img.affine\n",
    "                    shape = mask_img.shape\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                roi_key = f'{hemi}_{cat}'\n",
    "                subject_rois[roi_key] = {}\n",
    "                \n",
    "                for ses in info['sessions']:\n",
    "                    feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    z_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not z_file.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        z_data = nib.load(z_file).get_fdata() * mult\n",
    "                        pos_mask = search_mask & (z_data > 0)\n",
    "                        pos_voxels = z_data[pos_mask]\n",
    "                        \n",
    "                        if len(pos_voxels) < min_cluster:\n",
    "                            continue\n",
    "                        \n",
    "                        thresh = max(np.percentile(pos_voxels, percentile), min_z)\n",
    "                        suprathresh = (z_data > thresh) & search_mask\n",
    "                        labeled, n_clusters = label(suprathresh)\n",
    "                        \n",
    "                        if n_clusters == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        sizes = [(i, np.sum(labeled == i)) for i in range(1, n_clusters + 1)]\n",
    "                        best_idx, best_size = max(sizes, key=lambda x: x[1])\n",
    "                        \n",
    "                        if best_size < min_cluster:\n",
    "                            continue\n",
    "                        \n",
    "                        cluster_mask = (labeled == best_idx)\n",
    "                        centroid = nib.affines.apply_affine(affine, center_of_mass(cluster_mask))\n",
    "                        peak_idx = np.unravel_index(np.argmax(z_data * cluster_mask), shape)\n",
    "                        \n",
    "                        subject_rois[roi_key][ses] = {\n",
    "                            'centroid': centroid,\n",
    "                            'n_voxels': int(best_size),\n",
    "                            'peak_z': float(z_data[peak_idx]),\n",
    "                            'threshold': float(thresh),\n",
    "                            'affine': affine,\n",
    "                            'shape': shape\n",
    "                        }\n",
    "                    except:\n",
    "                        continue\n",
    "        \n",
    "        if subject_rois:\n",
    "            all_rois[sid] = subject_rois\n",
    "    \n",
    "    return all_rois\n",
    "\n",
    "\n",
    "def compute_rdm(patterns):\n",
    "    \"\"\"Compute RDM using 1 - Pearson correlation.\"\"\"\n",
    "    n = len(patterns)\n",
    "    rdm = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                r, _ = pearsonr(patterns[i], patterns[j])\n",
    "                rdm[i, j] = 1 - r\n",
    "    return rdm\n",
    "\n",
    "print(\"✓ Functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ROIs (top-10%, SCRAMBLE contrasts)...\n",
      "✓ 24 subjects\n",
      "\n",
      "Sample thresholds:\n",
      "  sub-004 l_face: z>2.16, n=448\n",
      "  sub-007 r_face: z>4.99, n=1228\n",
      "  sub-008 l_face: z>9.68, n=1296\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Extract ROIs\n",
    "print(f\"Extracting ROIs (top-{100-ROI_PERCENTILE}%, SCRAMBLE contrasts)...\")\n",
    "\n",
    "rois = extract_rois(COPE_MAP, percentile=ROI_PERCENTILE, min_cluster=MIN_CLUSTER, min_z=MIN_Z)\n",
    "\n",
    "print(f\"✓ {len(rois)} subjects\")\n",
    "\n",
    "# Verify thresholds\n",
    "print(\"\\nSample thresholds:\")\n",
    "for sid in list(rois.keys())[:3]:\n",
    "    for roi_key, sessions in rois[sid].items():\n",
    "        for ses, data in sessions.items():\n",
    "            print(f\"  {sid} {roi_key}: z>{data['threshold']:.2f}, n={data['n_voxels']}\")\n",
    "            break\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Geometry Preservation...\n",
      "✓ 132 measurements\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Geometry Preservation\n",
    "\n",
    "def compute_geometry_preservation(rois_dict, cope_map, radius=6):\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois_dict.items():\n",
    "        info = SUBJECTS.get(sid)\n",
    "        if not info:\n",
    "            continue\n",
    "        \n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        \n",
    "        # Get reference\n",
    "        ref_file = None\n",
    "        for cat in CATEGORIES:\n",
    "            for h in ['l', 'r']:\n",
    "                test = roi_dir / f'{h}_{cat}_searchmask.nii.gz'\n",
    "                if test.exists():\n",
    "                    ref_file = test\n",
    "                    break\n",
    "            if ref_file:\n",
    "                break\n",
    "        if not ref_file:\n",
    "            continue\n",
    "        \n",
    "        ref_img = nib.load(ref_file)\n",
    "        affine, shape = ref_img.affine, ref_img.shape\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            first_s, last_s = sessions[0], sessions[-1]\n",
    "            sphere_t1 = create_sphere(sessions_data[first_s]['centroid'], affine, shape, radius)\n",
    "            sphere_t2 = create_sphere(sessions_data[last_s]['centroid'], affine, shape, radius)\n",
    "            \n",
    "            rdms = {}\n",
    "            for ses, sphere in [(first_s, sphere_t1), (last_s, sphere_t2)]:\n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if valid and len(patterns) == 4:\n",
    "                    try:\n",
    "                        rdms[ses] = compute_rdm(patterns)\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "            if len(rdms) == 2:\n",
    "                triu_idx = np.triu_indices(4, k=1)\n",
    "                r, p = pearsonr(rdms[first_s][triu_idx], rdms[last_s][triu_idx])\n",
    "                \n",
    "                hemi, cat = roi_key.split('_')\n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'group': info['group'],\n",
    "                    'roi': roi_key,\n",
    "                    'hemi': hemi,\n",
    "                    'category': cat,\n",
    "                    'category_type': 'Bilateral' if cat in ['object', 'house'] else 'Unilateral',\n",
    "                    'geometry_preservation': r,\n",
    "                    'p_value': p\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Computing Geometry Preservation...\")\n",
    "geometry_df = compute_geometry_preservation(rois, COPE_MAP, radius=SPHERE_RADIUS)\n",
    "print(f\"✓ {len(geometry_df)} measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GEOMETRY PRESERVATION (SCRAMBLE, top-10%)\n",
      "============================================================\n",
      "\n",
      "By Group & Category Type:\n",
      "                        mean    std  count\n",
      "group   category_type                     \n",
      "OTC     Bilateral      0.226  0.471     12\n",
      "        Unilateral     0.039  0.554     12\n",
      "control Bilateral      0.547  0.499     36\n",
      "        Unilateral     0.551  0.449     36\n",
      "nonOTC  Bilateral      0.752  0.318     18\n",
      "        Unilateral     0.551  0.420     18\n",
      "\n",
      "OTC Bilateral vs Unilateral:\n",
      "  Bilateral: 0.226 ± 0.471 (n=12)\n",
      "  Unilateral: 0.039 ± 0.554 (n=12)\n",
      "  t=0.895, p=0.3807\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Geometry Results\n",
    "\n",
    "if len(geometry_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"GEOMETRY PRESERVATION (SCRAMBLE, top-10%)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nBy Group & Category Type:\")\n",
    "    summary = geometry_df.groupby(['group', 'category_type'])['geometry_preservation'].agg(['mean', 'std', 'count'])\n",
    "    print(summary.round(3))\n",
    "    \n",
    "    # OTC test\n",
    "    print(\"\\nOTC Bilateral vs Unilateral:\")\n",
    "    otc = geometry_df[geometry_df['group'] == 'OTC']\n",
    "    if len(otc) > 0:\n",
    "        bil = otc[otc['category_type'] == 'Bilateral']['geometry_preservation']\n",
    "        uni = otc[otc['category_type'] == 'Unilateral']['geometry_preservation']\n",
    "        if len(bil) > 1 and len(uni) > 1:\n",
    "            t, p = ttest_ind(bil, uni)\n",
    "            print(f\"  Bilateral: {bil.mean():.3f} ± {bil.std():.3f} (n={len(bil)})\")\n",
    "            print(f\"  Unilateral: {uni.mean():.3f} ± {uni.std():.3f} (n={len(uni)})\")\n",
    "            print(f\"  t={t:.3f}, p={p:.4f}\")\n",
    "else:\n",
    "    print(\"No results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Distinctiveness...\n",
      "✓ 296 measurements\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Distinctiveness\n",
    "\n",
    "def compute_distinctiveness(rois_dict, cope_map, radius=6):\n",
    "    roi_preferred = {f'{h}_{c}': c for h in ['l','r'] for c in CATEGORIES}\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois_dict.items():\n",
    "        info = SUBJECTS.get(sid)\n",
    "        if not info:\n",
    "            continue\n",
    "        \n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        \n",
    "        ref_file = None\n",
    "        for cat in CATEGORIES:\n",
    "            for h in ['l', 'r']:\n",
    "                test = roi_dir / f'{h}_{cat}_searchmask.nii.gz'\n",
    "                if test.exists():\n",
    "                    ref_file = test\n",
    "                    break\n",
    "            if ref_file:\n",
    "                break\n",
    "        if not ref_file:\n",
    "            continue\n",
    "        \n",
    "        ref_img = nib.load(ref_file)\n",
    "        affine, shape = ref_img.affine, ref_img.shape\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            if roi_key not in roi_preferred:\n",
    "                continue\n",
    "            \n",
    "            pref_cat = roi_preferred[roi_key]\n",
    "            pref_idx = CATEGORIES.index(pref_cat)\n",
    "            nonpref_idx = [i for i, c in enumerate(CATEGORIES) if c != pref_cat]\n",
    "            \n",
    "            for ses, ses_data in sessions_data.items():\n",
    "                sphere = create_sphere(ses_data['centroid'], affine, shape, radius)\n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = cope_map[cat]\n",
    "                    z_name = 'zstat1.nii.gz' if ses == first_ses else f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if not valid or len(patterns) != 4:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    corr = np.corrcoef(patterns)\n",
    "                    corr_fisher = np.arctanh(np.clip(corr, -0.999, 0.999))\n",
    "                    distinctiveness = np.mean([corr_fisher[pref_idx, i] for i in nonpref_idx])\n",
    "                    \n",
    "                    results.append({\n",
    "                        'subject': sid,\n",
    "                        'group': info['group'],\n",
    "                        'roi': roi_key,\n",
    "                        'category': pref_cat,\n",
    "                        'session': ses,\n",
    "                        'distinctiveness': distinctiveness\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "print(\"Computing Distinctiveness...\")\n",
    "distinctiveness_df = compute_distinctiveness(rois, COPE_MAP, radius=SPHERE_RADIUS)\n",
    "print(f\"✓ {len(distinctiveness_df)} measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DISTINCTIVENESS (lower = more selective)\n",
      "============================================================\n",
      "                   mean    std  count\n",
      "group   category                     \n",
      "OTC     face      0.549  0.144      6\n",
      "        house     0.238  0.376      6\n",
      "        object    0.385  0.340      6\n",
      "        word      0.439  0.201      6\n",
      "control face      0.669  0.205      9\n",
      "        house     0.168  0.213      9\n",
      "        object    0.503  0.177      9\n",
      "        word      0.520  0.140      9\n",
      "nonOTC  face      0.447  0.182      9\n",
      "        house     0.117  0.269      9\n",
      "        object    0.405  0.414      9\n",
      "        word      0.370  0.195      9\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Distinctiveness Results\n",
    "\n",
    "if len(distinctiveness_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DISTINCTIVENESS (lower = more selective)\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    avg = distinctiveness_df.groupby(['subject', 'group', 'category'])['distinctiveness'].mean().reset_index()\n",
    "    summary = avg.groupby(['group', 'category'])['distinctiveness'].agg(['mean', 'std', 'count'])\n",
    "    print(summary.round(3))\n",
    "else:\n",
    "    print(\"No results.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSTIC: RDM structure check\n",
      "\n",
      "Subject: sub-004, ROI: l_face, Voxels: 914\n",
      "\n",
      "face: cope10, mean=1.82, std=0.77\n",
      "word: cope12, mean=-0.24, std=1.05\n",
      "object: cope3, mean=1.42, std=0.87\n",
      "house: cope11, mean=0.66, std=0.74\n",
      "\n",
      "RDM upper tri: [1.096 1.158 0.863 0.729 0.761 0.795]\n",
      "Range: [0.729, 1.158]\n",
      "✓ Valid RDM (all values in [0, 2])\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Diagnostic - Check RDM values\n",
    "\n",
    "print(\"DIAGNOSTIC: RDM structure check\\n\")\n",
    "\n",
    "test_sid = list(rois.keys())[0]\n",
    "test_info = SUBJECTS[test_sid]\n",
    "first_ses = test_info['sessions'][0]\n",
    "roi_key = list(rois[test_sid].keys())[0]\n",
    "centroid = rois[test_sid][roi_key][first_ses]['centroid']\n",
    "\n",
    "roi_dir = BASE_DIR / test_sid / f'ses-{first_ses}' / 'ROIs'\n",
    "ref_file = roi_dir / f'{roi_key.split(\"_\")[0]}_face_searchmask.nii.gz'\n",
    "ref_img = nib.load(ref_file)\n",
    "affine, shape = ref_img.affine, ref_img.shape\n",
    "\n",
    "sphere = create_sphere(centroid, affine, shape, radius=SPHERE_RADIUS)\n",
    "feat_dir = BASE_DIR / test_sid / f'ses-{first_ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "\n",
    "print(f\"Subject: {test_sid}, ROI: {roi_key}, Voxels: {sphere.sum()}\\n\")\n",
    "\n",
    "patterns = []\n",
    "for cat in CATEGORIES:\n",
    "    cope_num, mult = COPE_MAP[cat]\n",
    "    cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "    data = nib.load(cope_file).get_fdata() * mult\n",
    "    pattern = data[sphere]\n",
    "    patterns.append(pattern)\n",
    "    print(f\"{cat}: cope{cope_num}, mean={pattern.mean():.2f}, std={pattern.std():.2f}\")\n",
    "\n",
    "rdm = compute_rdm(patterns)\n",
    "triu = rdm[np.triu_indices(4, k=1)]\n",
    "print(f\"\\nRDM upper tri: {np.round(triu, 3)}\")\n",
    "print(f\"Range: [{triu.min():.3f}, {triu.max():.3f}]\")\n",
    "if triu.max() <= 2.0 and triu.min() >= 0:\n",
    "    print(\"✓ Valid RDM (all values in [0, 2])\")\n",
    "else:\n",
    "    print(\"⚠ Unexpected RDM values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved: /user_data/csimmon2/git_repos/long_pt/B_analyses/geometry_preservation_scramble_top10.csv\n",
      "✓ Saved: /user_data/csimmon2/git_repos/long_pt/B_analyses/distinctiveness_scramble_top10.csv\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Save Results\n",
    "\n",
    "output_dir = Path('/user_data/csimmon2/git_repos/long_pt/B_analyses')\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "if len(geometry_df) > 0:\n",
    "    f = output_dir / 'geometry_preservation_scramble_top10.csv'\n",
    "    geometry_df.to_csv(f, index=False)\n",
    "    print(f\"✓ Saved: {f}\")\n",
    "\n",
    "if len(distinctiveness_df) > 0:\n",
    "    f = output_dir / 'distinctiveness_scramble_top10.csv'\n",
    "    distinctiveness_df.to_csv(f, index=False)\n",
    "    print(f\"✓ Saved: {f}\")\n",
    "\n",
    "print(\"\\nDone.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

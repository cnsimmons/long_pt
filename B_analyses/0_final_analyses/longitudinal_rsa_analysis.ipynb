{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Longitudinal RSA Analysis: VOTC Category Selectivity\n",
    "\n",
    "**Purpose**: Analyze representational geometry stability in ventral occipitotemporal cortex (VOTC) following pediatric resection.\n",
    "\n",
    "**Key Measures**:\n",
    "- Geometry Preservation: RDM correlation between T1 and T2 (higher = more stable)\n",
    "- Distinctiveness: Mean correlation between preferred and non-preferred categories (lower = more selective)\n",
    "\n",
    "**Methodology** (based on Kriegeskorte et al. 2008; Nili et al. 2014; Liu et al. 2018):\n",
    "1. Extract category-selective ROIs using top-20% voxel thresholding\n",
    "2. Build RDM using 1 - Pearson correlation of beta patterns\n",
    "3. Compare RDMs across sessions using Pearson correlation of vectorized upper triangles\n",
    "\n",
    "**Critical Note**: ROI extraction and pattern extraction must use CONSISTENT contrast maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cell 1: Configuration loaded\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Setup and Configuration\n",
    "# ================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, spearmanr, ttest_ind\n",
    "from scipy.spatial.distance import squareform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# === FILE PATHS ===\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "BASE_DIR = Path('/user_data/csimmon2/long_pt')\n",
    "\n",
    "# === SESSION START OVERRIDES ===\n",
    "# Some subjects have unusable early sessions\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# === CONTRAST MAPS ===\n",
    "# These define which cope files to use for each category\n",
    "# CRITICAL: Use the SAME map for ROI extraction AND pattern extraction\n",
    "\n",
    "COPE_MAP_DIFFERENTIAL = {\n",
    "    # Category > Other categories (differential contrasts)\n",
    "    'face': (10, 1),    # Face > Objects (cope10)\n",
    "    'word': (13, -1),   # Word > Scrambled (cope13, sign-flipped to match direction)\n",
    "    'object': (3, 1),   # Object > Scrambled (cope3)\n",
    "    'house': (11, 1)    # House > Objects (cope11)\n",
    "}\n",
    "\n",
    "COPE_MAP_SCRAMBLE = {\n",
    "    # Category > Scrambled baseline (simpler contrasts)\n",
    "    'face': (10, 1),    # Face > Scrambled\n",
    "    'word': (12, 1),    # Word > Scrambled\n",
    "    'object': (3, 1),   # Object > Scrambled\n",
    "    'house': (11, 1)    # House > Scrambled\n",
    "}\n",
    "\n",
    "# === ANALYSIS PARAMETERS ===\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "SPHERE_RADIUS = 6  # mm, for pattern extraction\n",
    "ROI_PERCENTILE = 80  # Top 20% of voxels\n",
    "MIN_CLUSTER_SIZE = 20  # Minimum voxels for valid ROI\n",
    "MIN_Z_THRESHOLD = 1.64  # Floor for adaptive threshold (~p<0.05 one-tailed)\n",
    "\n",
    "print(\"✓ Cell 1: Configuration loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 25 subjects\n",
      "  OTC: 7\n",
      "  nonOTC: 9\n",
      "  control: 9\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Load Subject Information\n",
    "# =================================\n",
    "\n",
    "def load_subjects():\n",
    "    \"\"\"Load all subjects from CSV and organize by group.\"\"\"\n",
    "    df = pd.read_csv(CSV_FILE)\n",
    "    subjects = {}\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        sid = row['sub']\n",
    "        subj_dir = BASE_DIR / sid\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # Get available sessions\n",
    "        sessions = sorted(\n",
    "            [d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()],\n",
    "            key=int\n",
    "        )\n",
    "        \n",
    "        # Apply session start override\n",
    "        start = SESSION_START.get(sid, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start]\n",
    "        if not sessions:\n",
    "            continue\n",
    "        \n",
    "        # Determine hemisphere (for patients: intact hemisphere)\n",
    "        is_patient = row.get('patient', 0) == 1\n",
    "        if is_patient:\n",
    "            intact_hemi = row.get('intact_hemi', 'left')\n",
    "            hemi = 'l' if intact_hemi == 'left' else 'r'\n",
    "        else:\n",
    "            hemi = 'l'  # Default for controls (will extract both anyway)\n",
    "        \n",
    "        # Determine group\n",
    "        if is_patient:\n",
    "            group = row.get('group', 'unknown')\n",
    "        else:\n",
    "            group = 'control'\n",
    "        \n",
    "        subjects[sid] = {\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemi,\n",
    "            'group': group,\n",
    "            'is_patient': is_patient\n",
    "        }\n",
    "    \n",
    "    return subjects\n",
    "\n",
    "SUBJECTS = load_subjects()\n",
    "\n",
    "# Print summary\n",
    "print(f\"✓ Loaded {len(SUBJECTS)} subjects\")\n",
    "for g in ['OTC', 'nonOTC', 'control']:\n",
    "    n = sum(1 for v in SUBJECTS.values() if v['group'] == g)\n",
    "    print(f\"  {g}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cell 3: Core functions defined\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Core Functions\n",
    "# ======================\n",
    "\n",
    "def create_sphere(center_mni, affine, shape, radius=6):\n",
    "    \"\"\"\n",
    "    Create a spherical mask centered at MNI coordinates.\n",
    "    \n",
    "    Parameters:\n",
    "        center_mni: [x, y, z] in MNI/world coordinates\n",
    "        affine: 4x4 affine matrix from reference image\n",
    "        shape: (nx, ny, nz) shape of brain volume\n",
    "        radius: sphere radius in mm\n",
    "    \n",
    "    Returns:\n",
    "        3D boolean mask\n",
    "    \"\"\"\n",
    "    # Create grid of voxel coordinates\n",
    "    i, j, k = np.meshgrid(\n",
    "        np.arange(shape[0]),\n",
    "        np.arange(shape[1]),\n",
    "        np.arange(shape[2]),\n",
    "        indexing='ij'\n",
    "    )\n",
    "    voxel_coords = np.stack([i, j, k], axis=-1).reshape(-1, 3)\n",
    "    \n",
    "    # Convert to world coordinates\n",
    "    world_coords = nib.affines.apply_affine(affine, voxel_coords)\n",
    "    \n",
    "    # Calculate distances from center\n",
    "    distances = np.linalg.norm(world_coords - center_mni, axis=1)\n",
    "    \n",
    "    # Create mask\n",
    "    mask = (distances <= radius).reshape(shape)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def extract_top20_rois(cope_map, percentile=80, min_cluster=20, min_z=1.64):\n",
    "    \"\"\"\n",
    "    Extract ROIs using top-N% voxel thresholding.\n",
    "    \n",
    "    Methodology (following Liu et al. 2018):\n",
    "    1. Load z-stat map within category-specific search mask\n",
    "    2. Compute adaptive threshold: max(percentile of positive voxels, min_z)\n",
    "    3. Find largest suprathreshold cluster\n",
    "    4. Return centroid and metadata\n",
    "    \n",
    "    Parameters:\n",
    "        cope_map: dict mapping category -> (cope_num, multiplier)\n",
    "        percentile: percentile threshold (80 = top 20%)\n",
    "        min_cluster: minimum voxels for valid cluster\n",
    "        min_z: floor for adaptive threshold\n",
    "    \n",
    "    Returns:\n",
    "        dict: {subject_id: {roi_key: {session: {centroid, n_voxels, threshold, ...}}}}\n",
    "    \"\"\"\n",
    "    all_rois = {}\n",
    "    \n",
    "    for sid, info in SUBJECTS.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        if not roi_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        subject_rois = {}\n",
    "        \n",
    "        # Extract BOTH hemispheres for all subjects\n",
    "        for hemi in ['l', 'r']:\n",
    "            for cat, (cope_num, mult) in cope_map.items():\n",
    "                \n",
    "                # Load search mask\n",
    "                mask_file = roi_dir / f'{hemi}_{cat}_searchmask.nii.gz'\n",
    "                if not mask_file.exists():\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    mask_img = nib.load(mask_file)\n",
    "                    search_mask = mask_img.get_fdata() > 0\n",
    "                    affine = mask_img.affine\n",
    "                    shape = mask_img.shape\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "                roi_key = f'{hemi}_{cat}'\n",
    "                subject_rois[roi_key] = {}\n",
    "                \n",
    "                # Process each session\n",
    "                for ses in info['sessions']:\n",
    "                    feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                    \n",
    "                    # Handle registration: first session uses native, others registered\n",
    "                    if ses == first_ses:\n",
    "                        z_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "                    else:\n",
    "                        z_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    \n",
    "                    if not z_file.exists():\n",
    "                        continue\n",
    "                    \n",
    "                    try:\n",
    "                        z_data = nib.load(z_file).get_fdata() * mult\n",
    "                        \n",
    "                        # Get positive voxels within search mask\n",
    "                        pos_mask = search_mask & (z_data > 0)\n",
    "                        pos_voxels = z_data[pos_mask]\n",
    "                        \n",
    "                        if len(pos_voxels) < min_cluster:\n",
    "                            continue\n",
    "                        \n",
    "                        # Adaptive threshold: top N% or minimum z\n",
    "                        dynamic_thresh = max(np.percentile(pos_voxels, percentile), min_z)\n",
    "                        \n",
    "                        # Find suprathreshold voxels\n",
    "                        suprathresh = (z_data > dynamic_thresh) & search_mask\n",
    "                        labeled, n_clusters = label(suprathresh)\n",
    "                        \n",
    "                        if n_clusters == 0:\n",
    "                            continue\n",
    "                        \n",
    "                        # Find largest cluster\n",
    "                        cluster_sizes = [(i, np.sum(labeled == i)) for i in range(1, n_clusters + 1)]\n",
    "                        best_idx, best_size = max(cluster_sizes, key=lambda x: x[1])\n",
    "                        \n",
    "                        if best_size < min_cluster:\n",
    "                            continue\n",
    "                        \n",
    "                        # Get cluster mask and centroid\n",
    "                        cluster_mask = (labeled == best_idx)\n",
    "                        centroid_vox = center_of_mass(cluster_mask)\n",
    "                        centroid_mni = nib.affines.apply_affine(affine, centroid_vox)\n",
    "                        \n",
    "                        # Get peak z-value\n",
    "                        peak_idx = np.unravel_index(np.argmax(z_data * cluster_mask), shape)\n",
    "                        peak_z = z_data[peak_idx]\n",
    "                        \n",
    "                        subject_rois[roi_key][ses] = {\n",
    "                            'centroid': centroid_mni,\n",
    "                            'n_voxels': int(best_size),\n",
    "                            'peak_z': float(peak_z),\n",
    "                            'threshold': float(dynamic_thresh),\n",
    "                            'affine': affine,\n",
    "                            'shape': shape\n",
    "                        }\n",
    "                    except Exception as e:\n",
    "                        continue\n",
    "        \n",
    "        if subject_rois:\n",
    "            all_rois[sid] = subject_rois\n",
    "    \n",
    "    return all_rois\n",
    "\n",
    "\n",
    "def compute_rdm(patterns, method='correlation'):\n",
    "    \"\"\"\n",
    "    Compute representational dissimilarity matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        patterns: list of 1D arrays (one per category)\n",
    "        method: 'correlation' (1 - r) or 'euclidean'\n",
    "    \n",
    "    Returns:\n",
    "        n x n dissimilarity matrix\n",
    "    \"\"\"\n",
    "    n = len(patterns)\n",
    "    rdm = np.zeros((n, n))\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i == j:\n",
    "                rdm[i, j] = 0\n",
    "            elif method == 'correlation':\n",
    "                r, _ = pearsonr(patterns[i], patterns[j])\n",
    "                rdm[i, j] = 1 - r\n",
    "            else:  # euclidean\n",
    "                rdm[i, j] = np.linalg.norm(patterns[i] - patterns[j])\n",
    "    \n",
    "    return rdm\n",
    "\n",
    "\n",
    "print(\"✓ Cell 3: Core functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ROIs with top-20% threshold...\n",
      "Using COPE_MAP_DIFFERENTIAL (matches Liu et al. 2018 approach)\n",
      "\n",
      "✓ Extracted ROIs for 24 subjects\n",
      "\n",
      "Sample thresholds (verifying adaptive method):\n",
      "  sub-004 l_face ses-01: z>1.66, n=846\n",
      "  sub-004 l_face ses-02: z>3.27, n=1591\n",
      "  sub-004 l_face ses-03: z>3.67, n=2062\n",
      "  sub-004 l_face ses-05: z>4.04, n=1761\n",
      "  sub-004 l_face ses-06: z>4.32, n=1953\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: Extract ROIs\n",
    "# ====================\n",
    "\n",
    "print(\"Extracting ROIs with top-20% threshold...\")\n",
    "print(\"Using COPE_MAP_DIFFERENTIAL (matches Liu et al. 2018 approach)\\n\")\n",
    "\n",
    "rois = extract_top20_rois(\n",
    "    COPE_MAP_DIFFERENTIAL,\n",
    "    percentile=ROI_PERCENTILE,\n",
    "    min_cluster=MIN_CLUSTER_SIZE,\n",
    "    min_z=MIN_Z_THRESHOLD\n",
    ")\n",
    "\n",
    "print(f\"✓ Extracted ROIs for {len(rois)} subjects\")\n",
    "\n",
    "# Diagnostic: Show sample thresholds\n",
    "print(\"\\nSample thresholds (verifying adaptive method):\")\n",
    "count = 0\n",
    "for sid in list(rois.keys())[:5]:\n",
    "    for roi_key, sessions in rois[sid].items():\n",
    "        for ses, data in sessions.items():\n",
    "            print(f\"  {sid} {roi_key} ses-{ses}: z>{data['threshold']:.2f}, n={data['n_voxels']}\")\n",
    "            count += 1\n",
    "            if count >= 5:\n",
    "                break\n",
    "        if count >= 5:\n",
    "            break\n",
    "    if count >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Geometry Preservation...\n",
      "Using 6mm spheres, COPE_MAP_DIFFERENTIAL\n",
      "\n",
      "✓ Computed 132 ROI measurements\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: Geometry Preservation Analysis\n",
    "# ======================================\n",
    "# \n",
    "# Methodology:\n",
    "# 1. For each ROI, create 6mm sphere at centroid\n",
    "# 2. Extract beta patterns for all 4 categories\n",
    "# 3. Compute 4x4 RDM (1 - correlation)\n",
    "# 4. Correlate RDM upper triangle between first and last session\n",
    "# \n",
    "# Interpretation:\n",
    "# - High correlation (near 1): Stable representational geometry\n",
    "# - Low correlation (near 0): Representational reorganization\n",
    "\n",
    "def compute_geometry_preservation(rois_dict, cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    Compute geometry preservation: RDM stability across sessions.\n",
    "    \n",
    "    CRITICAL: cope_map must match the one used for ROI extraction!\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois_dict.items():\n",
    "        info = SUBJECTS.get(sid)\n",
    "        if not info:\n",
    "            continue\n",
    "        \n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        # Get reference image for affine/shape\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        ref_file = None\n",
    "        for cat in CATEGORIES:\n",
    "            for h in ['l', 'r']:\n",
    "                test = roi_dir / f'{h}_{cat}_searchmask.nii.gz'\n",
    "                if test.exists():\n",
    "                    ref_file = test\n",
    "                    break\n",
    "            if ref_file:\n",
    "                break\n",
    "        \n",
    "        if not ref_file:\n",
    "            continue\n",
    "        \n",
    "        ref_img = nib.load(ref_file)\n",
    "        affine = ref_img.affine\n",
    "        shape = ref_img.shape\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            first_s, last_s = sessions[0], sessions[-1]\n",
    "            \n",
    "            # Create spheres at each session's centroid\n",
    "            sphere_t1 = create_sphere(sessions_data[first_s]['centroid'], affine, shape, radius)\n",
    "            sphere_t2 = create_sphere(sessions_data[last_s]['centroid'], affine, shape, radius)\n",
    "            \n",
    "            rdms = {}\n",
    "            \n",
    "            for ses, sphere in [(first_s, sphere_t1), (last_s, sphere_t2)]:\n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                \n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = cope_map[cat]\n",
    "                    \n",
    "                    # Use z-stats for pattern (consistent with ROI extraction)\n",
    "                    if ses == first_ses:\n",
    "                        cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "                    else:\n",
    "                        cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if not valid or len(patterns) != 4:\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    rdm = compute_rdm(patterns, method='correlation')\n",
    "                    rdms[ses] = rdm\n",
    "                except:\n",
    "                    continue\n",
    "            \n",
    "            # Compute geometry preservation if we have both RDMs\n",
    "            if len(rdms) == 2:\n",
    "                # Extract upper triangle (6 unique pairwise distances)\n",
    "                triu_idx = np.triu_indices(4, k=1)\n",
    "                vec_t1 = rdms[first_s][triu_idx]\n",
    "                vec_t2 = rdms[last_s][triu_idx]\n",
    "                \n",
    "                # Pearson correlation of RDM vectors\n",
    "                r, p = pearsonr(vec_t1, vec_t2)\n",
    "                \n",
    "                hemi = roi_key.split('_')[0]\n",
    "                cat = roi_key.split('_')[1]\n",
    "                \n",
    "                results.append({\n",
    "                    'subject': sid,\n",
    "                    'group': info['group'],\n",
    "                    'roi': roi_key,\n",
    "                    'hemi': hemi,\n",
    "                    'category': cat,\n",
    "                    'category_type': 'Bilateral' if cat in ['object', 'house'] else 'Unilateral',\n",
    "                    'geometry_preservation': r,\n",
    "                    'p_value': p,\n",
    "                    'n_sessions': len(sessions),\n",
    "                    'first_ses': first_s,\n",
    "                    'last_ses': last_s\n",
    "                })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run analysis\n",
    "print(\"Computing Geometry Preservation...\")\n",
    "print(f\"Using {SPHERE_RADIUS}mm spheres, COPE_MAP_DIFFERENTIAL\\n\")\n",
    "\n",
    "geometry_df = compute_geometry_preservation(rois, COPE_MAP_DIFFERENTIAL, radius=SPHERE_RADIUS)\n",
    "\n",
    "print(f\"✓ Computed {len(geometry_df)} ROI measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GEOMETRY PRESERVATION RESULTS\n",
      "Higher values = more stable representational geometry\n",
      "============================================================\n",
      "\n",
      "1. Summary by Group and Category Type:\n",
      "                        mean    std  count\n",
      "group   category_type                     \n",
      "OTC     Bilateral      0.424  0.349     12\n",
      "        Unilateral     0.713  0.197     12\n",
      "control Bilateral      0.659  0.359     36\n",
      "        Unilateral     0.755  0.213     36\n",
      "nonOTC  Bilateral      0.726  0.257     18\n",
      "        Unilateral     0.762  0.196     18\n",
      "\n",
      "2. Statistical Tests (OTC patients):\n",
      "   Bilateral: 0.424 ± 0.349 (n=12)\n",
      "   Unilateral: 0.713 ± 0.197 (n=12)\n",
      "   t-test: t=-2.496, p=0.0205\n",
      "   ✓ SIGNIFICANT: Bilateral categories show different stability than unilateral\n",
      "\n",
      "3. Group Comparisons (Bilateral categories only):\n",
      "   OTC vs nonOTC: t=-2.733, p=0.0107\n",
      "   OTC vs control: t=-1.982, p=0.0534\n",
      "   nonOTC vs control: t=0.700, p=0.4869\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: Geometry Preservation Results\n",
    "# =====================================\n",
    "\n",
    "if len(geometry_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"GEOMETRY PRESERVATION RESULTS\")\n",
    "    print(\"Higher values = more stable representational geometry\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Summary by Group and Category Type\n",
    "    print(\"\\n1. Summary by Group and Category Type:\")\n",
    "    summary = geometry_df.groupby(['group', 'category_type'])['geometry_preservation'].agg(['mean', 'std', 'count'])\n",
    "    print(summary.round(3))\n",
    "    \n",
    "    # Statistical tests: OTC Bilateral vs Unilateral\n",
    "    print(\"\\n2. Statistical Tests (OTC patients):\")\n",
    "    otc_data = geometry_df[geometry_df['group'] == 'OTC']\n",
    "    if len(otc_data) > 0:\n",
    "        bil = otc_data[otc_data['category_type'] == 'Bilateral']['geometry_preservation']\n",
    "        uni = otc_data[otc_data['category_type'] == 'Unilateral']['geometry_preservation']\n",
    "        \n",
    "        if len(bil) > 1 and len(uni) > 1:\n",
    "            t, p = ttest_ind(bil, uni)\n",
    "            print(f\"   Bilateral: {bil.mean():.3f} ± {bil.std():.3f} (n={len(bil)})\")\n",
    "            print(f\"   Unilateral: {uni.mean():.3f} ± {uni.std():.3f} (n={len(uni)})\")\n",
    "            print(f\"   t-test: t={t:.3f}, p={p:.4f}\")\n",
    "            \n",
    "            if p < 0.05:\n",
    "                print(\"   ✓ SIGNIFICANT: Bilateral categories show different stability than unilateral\")\n",
    "    \n",
    "    # Compare OTC vs nonOTC vs Controls\n",
    "    print(\"\\n3. Group Comparisons (Bilateral categories only):\")\n",
    "    bil_data = geometry_df[geometry_df['category_type'] == 'Bilateral']\n",
    "    for g1, g2 in [('OTC', 'nonOTC'), ('OTC', 'control'), ('nonOTC', 'control')]:\n",
    "        d1 = bil_data[bil_data['group'] == g1]['geometry_preservation']\n",
    "        d2 = bil_data[bil_data['group'] == g2]['geometry_preservation']\n",
    "        if len(d1) > 1 and len(d2) > 1:\n",
    "            t, p = ttest_ind(d1, d2)\n",
    "            print(f\"   {g1} vs {g2}: t={t:.3f}, p={p:.4f}\")\n",
    "else:\n",
    "    print(\"No geometry results computed. Check ROI extraction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Distinctiveness...\n",
      "✓ Computed 294 measurements\n"
     ]
    }
   ],
   "source": [
    "# CELL 7: Distinctiveness Analysis\n",
    "# =================================\n",
    "#\n",
    "# Liu et al. (2018) Distinctiveness metric:\n",
    "# Mean Fisher-transformed correlation between preferred and non-preferred categories\n",
    "# Lower values = more distinctive/selective representations\n",
    "\n",
    "def compute_distinctiveness(rois_dict, cope_map, radius=6):\n",
    "    \"\"\"\n",
    "    Compute Liu distinctiveness: mean correlation with non-preferred categories.\n",
    "    \"\"\"\n",
    "    roi_preferred = {\n",
    "        'l_face': 'face', 'r_face': 'face',\n",
    "        'l_word': 'word', 'r_word': 'word',\n",
    "        'l_object': 'object', 'r_object': 'object',\n",
    "        'l_house': 'house', 'r_house': 'house'\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sid, roi_data in rois_dict.items():\n",
    "        info = SUBJECTS.get(sid)\n",
    "        if not info:\n",
    "            continue\n",
    "        \n",
    "        first_ses = info['sessions'][0]\n",
    "        \n",
    "        # Get reference image\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        ref_file = None\n",
    "        for cat in CATEGORIES:\n",
    "            for h in ['l', 'r']:\n",
    "                test = roi_dir / f'{h}_{cat}_searchmask.nii.gz'\n",
    "                if test.exists():\n",
    "                    ref_file = test\n",
    "                    break\n",
    "            if ref_file:\n",
    "                break\n",
    "        \n",
    "        if not ref_file:\n",
    "            continue\n",
    "        \n",
    "        ref_img = nib.load(ref_file)\n",
    "        affine = ref_img.affine\n",
    "        shape = ref_img.shape\n",
    "        \n",
    "        for roi_key, sessions_data in roi_data.items():\n",
    "            if roi_key not in roi_preferred:\n",
    "                continue\n",
    "            \n",
    "            preferred_cat = roi_preferred[roi_key]\n",
    "            pref_idx = CATEGORIES.index(preferred_cat)\n",
    "            nonpref_indices = [i for i, c in enumerate(CATEGORIES) if c != preferred_cat]\n",
    "            \n",
    "            for ses, ses_data in sessions_data.items():\n",
    "                sphere = create_sphere(ses_data['centroid'], affine, shape, radius)\n",
    "                feat_dir = BASE_DIR / sid / f'ses-{ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                \n",
    "                patterns = []\n",
    "                valid = True\n",
    "                \n",
    "                for cat in CATEGORIES:\n",
    "                    cope_num, mult = cope_map[cat]\n",
    "                    \n",
    "                    if ses == first_ses:\n",
    "                        cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "                    else:\n",
    "                        cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / f'zstat1_ses{first_ses}.nii.gz'\n",
    "                    \n",
    "                    if not cope_file.exists():\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    data = nib.load(cope_file).get_fdata() * mult\n",
    "                    pattern = data[sphere]\n",
    "                    \n",
    "                    if len(pattern) == 0 or not np.all(np.isfinite(pattern)):\n",
    "                        valid = False\n",
    "                        break\n",
    "                    \n",
    "                    patterns.append(pattern)\n",
    "                \n",
    "                if not valid or len(patterns) != 4:\n",
    "                    continue\n",
    "                \n",
    "                # Compute correlation matrix\n",
    "                try:\n",
    "                    corr_matrix = np.corrcoef(patterns)\n",
    "                    \n",
    "                    # Fisher transform correlations\n",
    "                    corr_fisher = np.arctanh(np.clip(corr_matrix, -0.999, 0.999))\n",
    "                    \n",
    "                    # Mean correlation with non-preferred categories\n",
    "                    pref_vs_nonpref = [corr_fisher[pref_idx, i] for i in nonpref_indices]\n",
    "                    distinctiveness = np.mean(pref_vs_nonpref)\n",
    "                    \n",
    "                    hemi = roi_key.split('_')[0]\n",
    "                    \n",
    "                    results.append({\n",
    "                        'subject': sid,\n",
    "                        'group': info['group'],\n",
    "                        'roi': roi_key,\n",
    "                        'hemi': hemi,\n",
    "                        'category': preferred_cat,\n",
    "                        'session': ses,\n",
    "                        'distinctiveness': distinctiveness\n",
    "                    })\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "print(\"Computing Distinctiveness...\")\n",
    "distinctiveness_df = compute_distinctiveness(rois, COPE_MAP_DIFFERENTIAL, radius=SPHERE_RADIUS)\n",
    "print(f\"✓ Computed {len(distinctiveness_df)} measurements\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DISTINCTIVENESS RESULTS\n",
      "Lower values = more selective/distinctive representations\n",
      "============================================================\n",
      "\n",
      "Mean Distinctiveness by Group and Category:\n",
      "                   mean    std  count\n",
      "group   category                     \n",
      "OTC     face      0.099  0.252      6\n",
      "        house     0.298  0.126      6\n",
      "        object    0.263  0.220      6\n",
      "        word     -0.081  0.161      6\n",
      "control face      0.225  0.196     18\n",
      "        house     0.377  0.197     18\n",
      "        object    0.351  0.217     18\n",
      "        word     -0.020  0.223     18\n",
      "nonOTC  face     -0.039  0.146      9\n",
      "        house     0.350  0.164      9\n",
      "        object    0.192  0.267      9\n",
      "        word     -0.129  0.085      9\n"
     ]
    }
   ],
   "source": [
    "# CELL 8: Distinctiveness Results\n",
    "# ================================\n",
    "\n",
    "if len(distinctiveness_df) > 0:\n",
    "    print(\"=\"*60)\n",
    "    print(\"DISTINCTIVENESS RESULTS\")\n",
    "    print(\"Lower values = more selective/distinctive representations\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Average across sessions per subject/ROI\n",
    "    avg_dist = distinctiveness_df.groupby(['subject', 'group', 'roi', 'category'])['distinctiveness'].mean().reset_index()\n",
    "    \n",
    "    # Summary by group and category\n",
    "    print(\"\\nMean Distinctiveness by Group and Category:\")\n",
    "    summary = avg_dist.groupby(['group', 'category'])['distinctiveness'].agg(['mean', 'std', 'count'])\n",
    "    print(summary.round(3))\n",
    "else:\n",
    "    print(\"No distinctiveness results computed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIAGNOSTIC: Comparing contrast map effects on RDM\n",
      "\n",
      "Subject: sub-004, ROI: l_face\n",
      "Sphere voxels: 896\n",
      "\n",
      "DIFFERENTIAL:\n",
      "  face: cope10x+1, mean=1.73, std=0.81\n",
      "  word: cope13x-1, mean=-1.40, std=0.75\n",
      "  object: cope3x+1, mean=1.54, std=0.92\n",
      "  house: cope11x+1, mean=0.69, std=0.72\n",
      "  RDM upper triangle: [1.209 1.19  0.863 1.45  1.488 0.749]\n",
      "  RDM range: [0.749, 1.488]\n",
      "\n",
      "SCRAMBLE:\n",
      "  face: cope10x+1, mean=1.73, std=0.81\n",
      "  word: cope12x+1, mean=-0.09, std=1.01\n",
      "  object: cope3x+1, mean=1.54, std=0.92\n",
      "  house: cope11x+1, mean=0.69, std=0.72\n",
      "  RDM upper triangle: [1.187 1.19  0.863 0.711 0.708 0.749]\n",
      "  RDM range: [0.708, 1.190]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# CELL 9: Diagnostic - Compare Contrast Maps\n",
    "# ==========================================\n",
    "#\n",
    "# This cell verifies that DIFFERENTIAL and SCRAMBLE produce valid but different RDMs\n",
    "\n",
    "print(\"DIAGNOSTIC: Comparing contrast map effects on RDM\\n\")\n",
    "\n",
    "# Pick first subject with ROIs\n",
    "test_sid = list(rois.keys())[0]\n",
    "test_info = SUBJECTS[test_sid]\n",
    "first_ses = test_info['sessions'][0]\n",
    "\n",
    "# Get a sphere location\n",
    "roi_key = list(rois[test_sid].keys())[0]\n",
    "centroid = rois[test_sid][roi_key][first_ses]['centroid']\n",
    "\n",
    "# Load reference\n",
    "roi_dir = BASE_DIR / test_sid / f'ses-{first_ses}' / 'ROIs'\n",
    "ref_file = roi_dir / f'{roi_key.split(\"_\")[0]}_face_searchmask.nii.gz'\n",
    "ref_img = nib.load(ref_file)\n",
    "affine = ref_img.affine\n",
    "shape = ref_img.shape\n",
    "\n",
    "sphere = create_sphere(centroid, affine, shape, radius=SPHERE_RADIUS)\n",
    "feat_dir = BASE_DIR / test_sid / f'ses-{first_ses}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "\n",
    "print(f\"Subject: {test_sid}, ROI: {roi_key}\")\n",
    "print(f\"Sphere voxels: {sphere.sum()}\\n\")\n",
    "\n",
    "for map_name, cmap in [('DIFFERENTIAL', COPE_MAP_DIFFERENTIAL), ('SCRAMBLE', COPE_MAP_SCRAMBLE)]:\n",
    "    patterns = []\n",
    "    print(f\"{map_name}:\")\n",
    "    \n",
    "    for cat in CATEGORIES:\n",
    "        cope_num, mult = cmap[cat]\n",
    "        cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / 'zstat1.nii.gz'\n",
    "        \n",
    "        if cope_file.exists():\n",
    "            data = nib.load(cope_file).get_fdata() * mult\n",
    "            pattern = data[sphere]\n",
    "            patterns.append(pattern)\n",
    "            print(f\"  {cat}: cope{cope_num}x{mult:+d}, mean={pattern.mean():.2f}, std={pattern.std():.2f}\")\n",
    "    \n",
    "    if len(patterns) == 4:\n",
    "        rdm = compute_rdm(patterns)\n",
    "        triu = rdm[np.triu_indices(4, k=1)]\n",
    "        print(f\"  RDM upper triangle: {np.round(triu, 3)}\")\n",
    "        print(f\"  RDM range: [{triu.min():.3f}, {triu.max():.3f}]\")\n",
    "        \n",
    "        # Check for invalid values (should be 0-2 for correlation distance)\n",
    "        if triu.max() > 2.0:\n",
    "            print(f\"  ⚠ WARNING: RDM values > 2 indicate negative correlations\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved geometry results to /user_data/csimmon2/git_repos/long_pt/B_analyses/geometry_preservation_differential.csv\n",
      "✓ Saved distinctiveness results to /user_data/csimmon2/git_repos/long_pt/B_analyses/distinctiveness_differential.csv\n",
      "\n",
      "============================================================\n",
      "ANALYSIS COMPLETE\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# CELL 10: Save Results\n",
    "# =====================\n",
    "\n",
    "output_dir = Path('/user_data/csimmon2/git_repos/long_pt/B_analyses')\n",
    "output_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# Save geometry preservation\n",
    "if len(geometry_df) > 0:\n",
    "    geom_file = output_dir / 'geometry_preservation_differential.csv'\n",
    "    geometry_df.to_csv(geom_file, index=False)\n",
    "    print(f\"✓ Saved geometry results to {geom_file}\")\n",
    "\n",
    "# Save distinctiveness\n",
    "if len(distinctiveness_df) > 0:\n",
    "    dist_file = output_dir / 'distinctiveness_differential.csv'\n",
    "    distinctiveness_df.to_csv(dist_file, index=False)\n",
    "    print(f\"✓ Saved distinctiveness results to {dist_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ANALYSIS COMPLETE\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

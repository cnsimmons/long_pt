{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c1bed8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Configuration loaded\n",
      "  Localizer (ROI def): HighLevel zstats {'face': 10, 'word': 12, 'object': 3, 'house': 11}\n",
      "  RSA patterns: HighLevel copes {'face': 10, 'house': 11, 'object': 3, 'word': 12} + cocktail blank removal\n",
      "  Univariate: HighLevel copes {'face': 6, 'house': 7, 'object': 8, 'word': 9}\n",
      "  Threshold: top 10%, Sphere: 6mm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from scipy.ndimage import center_of_mass, label\n",
    "from scipy.stats import pearsonr, mannwhitneyu, ttest_ind\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "OUTPUT_DIR = BASE_DIR / \"analyses\" / \"unified_rsa\"\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "df_info = pd.read_csv(CSV_FILE)\n",
    "\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "SUBJECTS_TO_EXCLUDE = {'sub-108'}\n",
    "\n",
    "# ============================================================\n",
    "# CONTRAST & PE MAPPING — single source of truth\n",
    "# ============================================================\n",
    "#\n",
    "# Run-level design (1stLevel.feat, per run):\n",
    "#   EV1=Face    → pe1 (HRF), pe2 (derivative)\n",
    "#   EV2=House   → pe3 (HRF), pe4 (derivative)\n",
    "#   EV3=Object  → pe5 (HRF), pe6 (derivative)\n",
    "#   EV4=Words   → pe7 (HRF), pe8 (derivative)\n",
    "#   EV5=Scramble→ pe9 (HRF), pe10 (derivative)\n",
    "#   pe11+       = motion + spike regressors\n",
    "#\n",
    "# HighLevel contrasts (across runs):\n",
    "#   cope1:  Face > Object        cope8:  Object > All Others\n",
    "#   cope2:  House > Object       cope9:  Word > All Others\n",
    "#   cope3:  Object > Scramble    cope10: Face > Scramble\n",
    "#   cope4:  Word > Object        cope11: House > Scramble\n",
    "#   cope5:  Scramble > Average   cope12: Word > Scramble\n",
    "#   cope6:  Face > All Others    cope13: Face > Word\n",
    "#   cope7:  House > All Others   cope14: Object > House\n",
    "\n",
    "# For ROI DEFINITION: Category > Scramble zstats from HighLevel\n",
    "LOCALIZER_COPES = {\n",
    "    'face':   10,\n",
    "    'word':   12,\n",
    "    'object':  3,\n",
    "    'house':  11,\n",
    "}\n",
    "\n",
    "# For RSA PATTERN EXTRACTION: Category > Scramble parameter estimates from HighLevel\n",
    "# All share scramble baseline → pairwise distances preserved.\n",
    "# Combined with cocktail blank removal (voxel mean subtraction), the shared\n",
    "# baseline is largely removed, approximating per-condition patterns.\n",
    "# These are variance-weighted fixed-effects estimates, already cross-session registered.\n",
    "RSA_COPES = {\n",
    "    'face':   10,  # Face > Scramble\n",
    "    'house':  11,  # House > Scramble\n",
    "    'object':  3,  # Object > Scramble\n",
    "    'word':   12,  # Word > Scramble\n",
    "}\n",
    "\n",
    "# For UNIVARIATE (Ayzenberg approach): Category > All Others from HighLevel\n",
    "UNIVARIATE_COPES = {\n",
    "    'face':    6,\n",
    "    'house':   7,\n",
    "    'object':  8,\n",
    "    'word':    9,\n",
    "}\n",
    "\n",
    "CATEGORIES = ['face', 'word', 'object', 'house']\n",
    "BILATERAL_CATEGORIES = ['object', 'house']\n",
    "UNILATERAL_CATEGORIES = ['face', 'word']\n",
    "\n",
    "ROI_PERCENTILE = 90\n",
    "SPHERE_RADIUS = 6\n",
    "\n",
    "print(\"✓ Configuration loaded\")\n",
    "print(f\"  Localizer (ROI def): HighLevel zstats {LOCALIZER_COPES}\")\n",
    "print(f\"  RSA patterns: HighLevel copes {RSA_COPES} + cocktail blank removal\")\n",
    "print(f\"  Univariate: HighLevel copes {UNIVARIATE_COPES}\")\n",
    "print(f\"  Threshold: top {100 - ROI_PERCENTILE}%, Sphere: {SPHERE_RADIUS}mm\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5561b64a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 24 subjects (15 patients, 9 controls)\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 2: Load Subjects\n",
    "\n",
    "def load_subjects(patient_only=None):\n",
    "    filtered = df_info.copy()\n",
    "    if patient_only is True:\n",
    "        filtered = filtered[filtered['patient'] == 1]\n",
    "    elif patient_only is False:\n",
    "        filtered = filtered[filtered['patient'] == 0]\n",
    "\n",
    "    subjects = {}\n",
    "    for _, row in filtered.iterrows():\n",
    "        sid = row['sub']\n",
    "        if sid in SUBJECTS_TO_EXCLUDE:\n",
    "            continue\n",
    "        subj_dir = BASE_DIR / sid\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "\n",
    "        sessions = sorted(\n",
    "            [d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()],\n",
    "            key=lambda x: int(x)\n",
    "        )\n",
    "        start = SESSION_START.get(sid, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start]\n",
    "        if not sessions:\n",
    "            continue\n",
    "\n",
    "        hemi_full = row.get('intact_hemi', 'left')\n",
    "        if pd.isna(hemi_full):\n",
    "            hemi_full = 'left'\n",
    "\n",
    "        subjects[sid] = {\n",
    "            'code': f\"{row['group']}{sid.split('-')[1]}\",\n",
    "            'sessions': sessions,\n",
    "            'hemi': 'l' if hemi_full == 'left' else 'r',\n",
    "            'group': row['group'],\n",
    "            'is_patient': row['patient'] == 1,\n",
    "        }\n",
    "    return subjects\n",
    "\n",
    "ALL_PATIENTS = load_subjects(patient_only=True)\n",
    "ALL_CONTROLS = load_subjects(patient_only=False)\n",
    "ALL_SUBJECTS = {**ALL_PATIENTS, **ALL_CONTROLS}\n",
    "\n",
    "print(f\"✓ {len(ALL_SUBJECTS)} subjects \"\n",
    "      f\"({len(ALL_PATIENTS)} patients, {len(ALL_CONTROLS)} controls)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e94173ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 3: Core Utilities\n",
    "\n",
    "def create_sphere(center_mni, affine, shape, radius=6):\n",
    "    \"\"\"Boolean mask for 6mm sphere around MNI coordinate.\"\"\"\n",
    "    grid = np.array(np.meshgrid(\n",
    "        np.arange(shape[0]), np.arange(shape[1]), np.arange(shape[2]),\n",
    "        indexing='ij'\n",
    "    )).reshape(3, -1).T\n",
    "    world = nib.affines.apply_affine(affine, grid)\n",
    "    dists = np.linalg.norm(world - center_mni, axis=1)\n",
    "    mask = np.zeros(shape, dtype=bool)\n",
    "    for c in grid[dists <= radius]:\n",
    "        mask[c[0], c[1], c[2]] = True\n",
    "    return mask\n",
    "\n",
    "\n",
    "def get_highlevel_stat(sid, session, cope_num, first_session, stat='zstat1'):\n",
    "    \"\"\"Path to HighLevel stat file (handles cross-session registration).\"\"\"\n",
    "    feat_dir = (BASE_DIR / sid / f'ses-{session}' / 'derivatives' /\n",
    "                'fsl' / 'loc' / 'HighLevel.gfeat')\n",
    "    fname = f'{stat}.nii.gz' if session == first_session else f'{stat}_ses{first_session}.nii.gz'\n",
    "    return feat_dir / f'cope{cope_num}.feat' / 'stats' / fname\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1b77fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA AVAILABILITY CHECK\n",
      "============================================================\n",
      "  OTC004: ⚠️ missing files\n",
      "  nonOTC007: ✓ all sessions OK\n",
      "  OTC008: ✓ all sessions OK\n",
      "  OTC010: ✓ all sessions OK\n",
      "  OTC017: ✓ all sessions OK\n",
      "  OTC021: ✓ all sessions OK\n",
      "\n",
      "  Summary: 23 complete, 1 incomplete\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 4: Check Data Availability\n",
    "\n",
    "\n",
    "def check_data(subjects_dict, n_show=5):\n",
    "    \"\"\"Verify HighLevel files exist for localizer and RSA.\"\"\"\n",
    "    print(\"DATA AVAILABILITY CHECK\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    ok, missing = 0, 0\n",
    "    shown = 0\n",
    "\n",
    "    for sid, info in subjects_dict.items():\n",
    "        first_ses = info['sessions'][0]\n",
    "        all_ok = True\n",
    "\n",
    "        for ses in info['sessions']:\n",
    "            # Check localizer zstats\n",
    "            for c, cope in LOCALIZER_COPES.items():\n",
    "                if not get_highlevel_stat(sid, ses, cope, first_ses, 'zstat1').exists():\n",
    "                    all_ok = False\n",
    "            # Check RSA copes\n",
    "            for c, cope in RSA_COPES.items():\n",
    "                if not get_highlevel_stat(sid, ses, cope, first_ses, 'cope1').exists():\n",
    "                    all_ok = False\n",
    "\n",
    "        if all_ok:\n",
    "            ok += 1\n",
    "        else:\n",
    "            missing += 1\n",
    "            print(f\"  {info['code']}: ⚠️ missing files\")\n",
    "\n",
    "        if shown < n_show and all_ok:\n",
    "            print(f\"  {info['code']}: ✓ all sessions OK\")\n",
    "            shown += 1\n",
    "\n",
    "    print(f\"\\n  Summary: {ok} complete, {missing} incomplete\")\n",
    "    return missing == 0\n",
    "\n",
    "data_ready = check_data(ALL_SUBJECTS)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b7dbf145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DEFINING ROIs (Category > Scramble, top 10%)\n",
      "============================================================\n",
      "  OTC004: 4 ROI×hemi, hemis=['l']\n",
      "  nonOTC007: 4 ROI×hemi, hemis=['r']\n",
      "  OTC008: 4 ROI×hemi, hemis=['l']\n",
      "  OTC010: 4 ROI×hemi, hemis=['r']\n",
      "  OTC017: 4 ROI×hemi, hemis=['r']\n",
      "  OTC021: 4 ROI×hemi, hemis=['r']\n",
      "  nonOTC045: 4 ROI×hemi, hemis=['r']\n",
      "  nonOTC047: 4 ROI×hemi, hemis=['l']\n",
      "  nonOTC049: 4 ROI×hemi, hemis=['l']\n",
      "  nonOTC070: 4 ROI×hemi, hemis=['r']\n",
      "  nonOTC072: 4 ROI×hemi, hemis=['l']\n",
      "  nonOTC073: 4 ROI×hemi, hemis=['l']\n",
      "  nonOTC081: 4 ROI×hemi, hemis=['r']\n",
      "  nonOTC086: 4 ROI×hemi, hemis=['l']\n",
      "  OTC079: 4 ROI×hemi, hemis=['r']\n",
      "  control018: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control022: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control025: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control027: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control052: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control058: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control062: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control064: 8 ROI×hemi, hemis=['l', 'r']\n",
      "  control068: 8 ROI×hemi, hemis=['l', 'r']\n",
      "\n",
      "✓ ROIs for 24 subjects\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 5: ROI Definition (Localizer — from HighLevel)\n",
    "\n",
    "def define_rois(sid, info, hemispheres, percentile=90, min_voxels=10):\n",
    "    \"\"\"Define ROIs using Category > Scramble from HighLevel (top-percentile).\"\"\"\n",
    "    sessions = info['sessions']\n",
    "    first_ses = sessions[0]\n",
    "    roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "    results = {}\n",
    "\n",
    "    for hemi in hemispheres:\n",
    "        for cat, cope_num in LOCALIZER_COPES.items():\n",
    "            key = f\"{hemi}_{cat}\"\n",
    "            mask_file = roi_dir / f'{hemi}_{cat}_searchmask.nii.gz'\n",
    "            if not mask_file.exists():\n",
    "                continue\n",
    "\n",
    "            mask_img = nib.load(mask_file)\n",
    "            search_mask = mask_img.get_fdata() > 0\n",
    "            affine = mask_img.affine\n",
    "            results[key] = {}\n",
    "\n",
    "            for ses in sessions:\n",
    "                zstat_path = get_highlevel_stat(sid, ses, cope_num, first_ses, stat='zstat1')\n",
    "                if not zstat_path.exists():\n",
    "                    continue\n",
    "\n",
    "                zstat = nib.load(zstat_path).get_fdata()\n",
    "                pos_vals = zstat[search_mask & (zstat > 0)]\n",
    "                if len(pos_vals) < min_voxels:\n",
    "                    continue\n",
    "\n",
    "                thresh = max(np.percentile(pos_vals, percentile), 1.64)\n",
    "                suprathresh = (zstat > thresh) & search_mask\n",
    "                labeled, n_clusters = label(suprathresh)\n",
    "                if n_clusters == 0:\n",
    "                    continue\n",
    "\n",
    "                sizes = [(labeled == i).sum() for i in range(1, n_clusters + 1)]\n",
    "                best_idx = np.argmax(sizes) + 1\n",
    "                if sizes[best_idx - 1] < 5:\n",
    "                    continue\n",
    "\n",
    "                roi_mask = (labeled == best_idx)\n",
    "                centroid = nib.affines.apply_affine(affine, center_of_mass(roi_mask))\n",
    "                peak_idx = np.unravel_index(np.argmax(zstat * roi_mask), zstat.shape)\n",
    "\n",
    "                results[key][ses] = {\n",
    "                    'centroid': centroid,\n",
    "                    'n_voxels': sizes[best_idx - 1],\n",
    "                    'peak_z': zstat[peak_idx],\n",
    "                    'threshold': thresh,\n",
    "                }\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"\\nDEFINING ROIs (Category > Scramble, top 10%)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_rois = {}\n",
    "for sid, info in ALL_SUBJECTS.items():\n",
    "    hemis = [info['hemi']] if info['is_patient'] else ['l', 'r']\n",
    "    rois = define_rois(sid, info, hemis, percentile=ROI_PERCENTILE)\n",
    "    if rois:\n",
    "        all_rois[sid] = rois\n",
    "        n = sum(1 for v in rois.values() if v)\n",
    "        print(f\"  {info['code']}: {n} ROI×hemi, hemis={hemis}\")\n",
    "    else:\n",
    "        print(f\"  {info['code']}: ⚠️ no ROIs\")\n",
    "\n",
    "print(f\"\\n✓ ROIs for {len(all_rois)} subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b7d2774f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXTRACTING RSA PATTERNS (Category > Scramble copes + cocktail blank removal)\n",
      "============================================================\n",
      "  OTC004: 4 ROIs, 20 session×ROI RDMs\n",
      "  nonOTC007: 4 ROIs, 12 session×ROI RDMs\n",
      "  OTC008: 4 ROIs, 8 session×ROI RDMs\n",
      "  OTC010: 4 ROIs, 8 session×ROI RDMs\n",
      "  OTC017: 4 ROIs, 16 session×ROI RDMs\n",
      "  OTC021: 4 ROIs, 12 session×ROI RDMs\n",
      "  nonOTC045: 4 ROIs, 12 session×ROI RDMs\n",
      "  nonOTC047: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC049: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC070: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC072: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC073: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC081: 4 ROIs, 8 session×ROI RDMs\n",
      "  nonOTC086: 4 ROIs, 8 session×ROI RDMs\n",
      "  OTC079: 4 ROIs, 8 session×ROI RDMs\n",
      "  control018: 8 ROIs, 16 session×ROI RDMs\n",
      "  control022: 8 ROIs, 16 session×ROI RDMs\n",
      "  control025: 8 ROIs, 16 session×ROI RDMs\n",
      "  control027: 8 ROIs, 16 session×ROI RDMs\n",
      "  control052: 8 ROIs, 16 session×ROI RDMs\n",
      "  control058: 8 ROIs, 16 session×ROI RDMs\n",
      "  control062: 8 ROIs, 16 session×ROI RDMs\n",
      "  control064: 8 ROIs, 16 session×ROI RDMs\n",
      "  control068: 8 ROIs, 16 session×ROI RDMs\n",
      "\n",
      "✓ RDMs for 24 subjects\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 6: RSA Pattern Extraction (Per-Condition PEs — Liu Approach)\n",
    "\n",
    "def extract_rsa_patterns(sid, info, roi_results, radius=6):\n",
    "    \"\"\"Extract Category > Scramble copes in 6mm sphere, apply cocktail blank\n",
    "    removal, compute RDMs.\n",
    "\n",
    "    Uses HighLevel fixed-effects parameter estimates (cope1 files).\n",
    "    All categories share scramble baseline. Cocktail blank removal\n",
    "    (subtracting each voxel's mean across conditions) removes the shared\n",
    "    baseline component, approximating per-condition patterns.\n",
    "    \"\"\"\n",
    "    sessions = info['sessions']\n",
    "    first_ses = sessions[0]\n",
    "\n",
    "    # Reference geometry\n",
    "    roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "    ref_file = None\n",
    "    for cat in CATEGORIES:\n",
    "        for h in ['l', 'r']:\n",
    "            f = roi_dir / f\"{h}_{cat}_searchmask.nii.gz\"\n",
    "            if f.exists():\n",
    "                ref_file = f\n",
    "                break\n",
    "        if ref_file:\n",
    "            break\n",
    "    if not ref_file:\n",
    "        return {}\n",
    "\n",
    "    ref_img = nib.load(ref_file)\n",
    "    affine = ref_img.affine\n",
    "    brain_shape = ref_img.shape\n",
    "\n",
    "    roi_rdms = {}\n",
    "\n",
    "    for roi_key, sessions_data in roi_results.items():\n",
    "        if not sessions_data:\n",
    "            continue\n",
    "\n",
    "        roi_rdms[roi_key] = {\n",
    "            'rdms': {}, 'fisher_corr': {}, 'patterns': {},\n",
    "            'valid_categories': None, 'centroids': {},\n",
    "        }\n",
    "\n",
    "        for ses in sessions:\n",
    "            if ses not in sessions_data:\n",
    "                continue\n",
    "\n",
    "            centroid = sessions_data[ses]['centroid']\n",
    "            sphere = create_sphere(centroid, affine, brain_shape, radius)\n",
    "            roi_rdms[roi_key]['centroids'][ses] = centroid\n",
    "\n",
    "            # Extract patterns using Category > Scramble copes\n",
    "            patterns = []\n",
    "            valid_cats = []\n",
    "\n",
    "            for cat in CATEGORIES:\n",
    "                cope_path = get_highlevel_stat(\n",
    "                    sid, ses, RSA_COPES[cat], first_ses, stat='cope1'\n",
    "                )\n",
    "                if not cope_path.exists():\n",
    "                    continue\n",
    "\n",
    "                data = nib.load(cope_path).get_fdata()\n",
    "                betas = data[sphere]\n",
    "                betas = betas[np.isfinite(betas)]\n",
    "\n",
    "                if len(betas) > 0:\n",
    "                    patterns.append(betas)\n",
    "                    valid_cats.append(cat)\n",
    "\n",
    "            if len(patterns) < 4:\n",
    "                continue\n",
    "\n",
    "            # Equal voxel count across conditions\n",
    "            min_v = min(len(p) for p in patterns)\n",
    "            patterns = [p[:min_v] for p in patterns]\n",
    "            beta_matrix = np.column_stack(patterns)  # N_voxels × 4\n",
    "\n",
    "            # Cocktail blank removal (Ayzenberg; Walther et al. 2016)\n",
    "            # Subtract each voxel's mean across conditions to remove\n",
    "            # shared visual response, isolating category-specific patterns\n",
    "            voxel_means = beta_matrix.mean(axis=1, keepdims=True)\n",
    "            beta_matrix = beta_matrix - voxel_means\n",
    "\n",
    "            # RDM: 1 - Pearson correlation (Liu et al.)\n",
    "            corr_mat = np.corrcoef(beta_matrix.T)\n",
    "            rdm = 1 - corr_mat\n",
    "            fisher_corr = np.arctanh(np.clip(corr_mat, -0.999, 0.999))\n",
    "\n",
    "            roi_rdms[roi_key]['rdms'][ses] = rdm\n",
    "            roi_rdms[roi_key]['fisher_corr'][ses] = fisher_corr\n",
    "            roi_rdms[roi_key]['patterns'][ses] = beta_matrix\n",
    "            roi_rdms[roi_key]['valid_categories'] = valid_cats\n",
    "\n",
    "    return roi_rdms\n",
    "\n",
    "\n",
    "print(\"\\nEXTRACTING RSA PATTERNS (Category > Scramble copes + cocktail blank removal)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_rdms = {}\n",
    "for sid, info in ALL_SUBJECTS.items():\n",
    "    if sid not in all_rois:\n",
    "        continue\n",
    "    rdms = extract_rsa_patterns(sid, info, all_rois[sid], SPHERE_RADIUS)\n",
    "    if rdms:\n",
    "        all_rdms[sid] = rdms\n",
    "        n_ses = sum(len(v['rdms']) for v in rdms.values())\n",
    "        print(f\"  {info['code']}: {len(rdms)} ROIs, {n_ses} session×ROI RDMs\")\n",
    "\n",
    "print(f\"\\n✓ RDMs for {len(all_rdms)} subjects\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e86d0f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "EXTRACTING UNIVARIATE (Category > All Others, Ayzenberg approach)\n",
      "============================================================\n",
      "  OTC004: 20 session×ROI measurements\n",
      "  nonOTC007: 12 session×ROI measurements\n",
      "  OTC008: 8 session×ROI measurements\n",
      "  OTC010: 8 session×ROI measurements\n",
      "  OTC017: 16 session×ROI measurements\n",
      "  OTC021: 12 session×ROI measurements\n",
      "  nonOTC045: 12 session×ROI measurements\n",
      "  nonOTC047: 8 session×ROI measurements\n",
      "  nonOTC049: 8 session×ROI measurements\n",
      "  nonOTC070: 8 session×ROI measurements\n",
      "  nonOTC072: 8 session×ROI measurements\n",
      "  nonOTC073: 8 session×ROI measurements\n",
      "  nonOTC081: 8 session×ROI measurements\n",
      "  nonOTC086: 8 session×ROI measurements\n",
      "  OTC079: 8 session×ROI measurements\n",
      "  control018: 16 session×ROI measurements\n",
      "  control022: 16 session×ROI measurements\n",
      "  control025: 16 session×ROI measurements\n",
      "  control027: 16 session×ROI measurements\n",
      "  control052: 16 session×ROI measurements\n",
      "  control058: 16 session×ROI measurements\n",
      "  control062: 16 session×ROI measurements\n",
      "  control064: 16 session×ROI measurements\n",
      "  control068: 16 session×ROI measurements\n",
      "\n",
      "✓ Univariate for 24 subjects\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 7: Univariate Extraction (Ayzenberg Approach)\n",
    "\n",
    "def extract_univariate(sid, info, roi_results, radius=6):\n",
    "    \"\"\"Extract Category > All Others activation in 6mm sphere.\n",
    "\n",
    "    Ayzenberg approach: mean univariate activation for preferred category,\n",
    "    compared patient-by-patient against bootstrapped control CIs.\n",
    "    \"\"\"\n",
    "    sessions = info['sessions']\n",
    "    first_ses = sessions[0]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for roi_key, sessions_data in roi_results.items():\n",
    "        if not sessions_data:\n",
    "            continue\n",
    "\n",
    "        hemi = roi_key.split('_')[0]\n",
    "        category = roi_key.split('_')[1]\n",
    "        cope_num = UNIVARIATE_COPES.get(category)\n",
    "        if cope_num is None:\n",
    "            continue\n",
    "\n",
    "        results[roi_key] = {}\n",
    "\n",
    "        # Reference geometry\n",
    "        roi_dir = BASE_DIR / sid / f'ses-{first_ses}' / 'ROIs'\n",
    "        ref_file = roi_dir / f\"{hemi}_{category}_searchmask.nii.gz\"\n",
    "        if not ref_file.exists():\n",
    "            # Try any available mask for geometry\n",
    "            for cat in CATEGORIES:\n",
    "                for h in ['l', 'r']:\n",
    "                    f = roi_dir / f\"{h}_{cat}_searchmask.nii.gz\"\n",
    "                    if f.exists():\n",
    "                        ref_file = f\n",
    "                        break\n",
    "                if ref_file.exists():\n",
    "                    break\n",
    "\n",
    "        ref_img = nib.load(ref_file)\n",
    "        affine = ref_img.affine\n",
    "        brain_shape = ref_img.shape\n",
    "\n",
    "        for ses in sessions:\n",
    "            if ses not in sessions_data:\n",
    "                continue\n",
    "\n",
    "            centroid = sessions_data[ses]['centroid']\n",
    "            sphere = create_sphere(centroid, affine, brain_shape, radius)\n",
    "\n",
    "            # Get Category > All Others cope from HighLevel\n",
    "            cope_path = get_highlevel_stat(sid, ses, cope_num, first_ses, stat='cope1')\n",
    "            if not cope_path.exists():\n",
    "                continue\n",
    "\n",
    "            data = nib.load(cope_path).get_fdata()\n",
    "            vals = data[sphere]\n",
    "            vals = vals[np.isfinite(vals)]\n",
    "\n",
    "            if len(vals) > 0:\n",
    "                results[roi_key][ses] = {\n",
    "                    'mean_activation': np.mean(vals),\n",
    "                    'peak_activation': np.max(vals),\n",
    "                    'n_voxels': len(vals),\n",
    "                }\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "print(\"\\nEXTRACTING UNIVARIATE (Category > All Others, Ayzenberg approach)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "all_univariate = {}\n",
    "for sid, info in ALL_SUBJECTS.items():\n",
    "    if sid not in all_rois:\n",
    "        continue\n",
    "    univ = extract_univariate(sid, info, all_rois[sid], SPHERE_RADIUS)\n",
    "    if univ:\n",
    "        all_univariate[sid] = univ\n",
    "        n = sum(len(v) for v in univ.values())\n",
    "        print(f\"  {info['code']}: {n} session×ROI measurements\")\n",
    "\n",
    "print(f\"\\n✓ Univariate for {len(all_univariate)} subjects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1d33392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPUTING METRICS\n",
      "============================================================\n",
      "\n",
      "✓ 132 ROI measurements\n",
      "  Patients: 60\n",
      "  Controls: 72\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 8: Compute All Metrics\n",
    "\n",
    "def mds_2d(rdm):\n",
    "    \"\"\"Classical MDS to 2D.\"\"\"\n",
    "    n = rdm.shape[0]\n",
    "    H = np.eye(n) - np.ones((n, n)) / n\n",
    "    B = -0.5 * H @ (rdm ** 2) @ H\n",
    "    eigvals, eigvecs = np.linalg.eigh(B)\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    coords = eigvecs[:, idx[:2]] * np.sqrt(np.maximum(eigvals[idx[:2]], 0))\n",
    "    return coords\n",
    "\n",
    "\n",
    "def compute_all_metrics(all_rdms, all_univariate, subjects_dict):\n",
    "    \"\"\"Compute RSA metrics + univariate selectivity.\"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for sid, rois in all_rdms.items():\n",
    "        info = subjects_dict[sid]\n",
    "\n",
    "        for roi_key, roi_data in rois.items():\n",
    "            sessions_with_rdm = sorted(roi_data['rdms'].keys())\n",
    "            if len(sessions_with_rdm) < 2:\n",
    "                continue\n",
    "\n",
    "            valid_cats = roi_data['valid_categories']\n",
    "            if valid_cats is None or len(valid_cats) < 4:\n",
    "                continue\n",
    "\n",
    "            first_ses = sessions_with_rdm[0]\n",
    "            last_ses = sessions_with_rdm[-1]\n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "\n",
    "            # --- Liu Distinctiveness ---\n",
    "            pref_idx = valid_cats.index(category) if category in valid_cats else None\n",
    "            liu_t1, liu_t2 = None, None\n",
    "\n",
    "            if pref_idx is not None:\n",
    "                nonpref = [i for i in range(len(valid_cats)) if i != pref_idx]\n",
    "                if first_ses in roi_data['fisher_corr']:\n",
    "                    liu_t1 = np.mean(roi_data['fisher_corr'][first_ses][pref_idx, nonpref])\n",
    "                if last_ses in roi_data['fisher_corr']:\n",
    "                    liu_t2 = np.mean(roi_data['fisher_corr'][last_ses][pref_idx, nonpref])\n",
    "\n",
    "            liu_change = abs(liu_t2 - liu_t1) if (liu_t1 is not None and liu_t2 is not None) else None\n",
    "\n",
    "            # --- Geometry Preservation ---\n",
    "            rdm_t1 = roi_data['rdms'][first_ses]\n",
    "            rdm_t2 = roi_data['rdms'][last_ses]\n",
    "            triu = np.triu_indices(4, k=1)\n",
    "            geom_r, _ = pearsonr(rdm_t1[triu], rdm_t2[triu])\n",
    "\n",
    "            # --- MDS Shift ---\n",
    "            mds_shifts = {}\n",
    "            try:\n",
    "                coords_t1 = mds_2d(rdm_t1)\n",
    "                coords_t2 = mds_2d(rdm_t2)\n",
    "                R, _ = orthogonal_procrustes(coords_t1, coords_t2)\n",
    "                aligned_t1 = coords_t1 @ R\n",
    "                for i, cat in enumerate(valid_cats):\n",
    "                    mds_shifts[cat] = np.linalg.norm(aligned_t1[i] - coords_t2[i])\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "            # --- Spatial Drift ---\n",
    "            drift_mm = None\n",
    "            if first_ses in roi_data['centroids'] and last_ses in roi_data['centroids']:\n",
    "                drift_mm = np.linalg.norm(\n",
    "                    roi_data['centroids'][last_ses] - roi_data['centroids'][first_ses]\n",
    "                )\n",
    "\n",
    "            # --- Univariate Selectivity (Ayzenberg) ---\n",
    "            univ_t1, univ_t2 = None, None\n",
    "            if sid in all_univariate and roi_key in all_univariate[sid]:\n",
    "                udata = all_univariate[sid][roi_key]\n",
    "                if first_ses in udata:\n",
    "                    univ_t1 = udata[first_ses]['mean_activation']\n",
    "                if last_ses in udata:\n",
    "                    univ_t2 = udata[last_ses]['mean_activation']\n",
    "\n",
    "            univ_change = abs(univ_t2 - univ_t1) if (univ_t1 is not None and univ_t2 is not None) else None\n",
    "\n",
    "            row = {\n",
    "                'subject': sid, 'code': info['code'], 'group': info['group'],\n",
    "                'is_patient': info['is_patient'], 'hemisphere': hemi,\n",
    "                'roi_category': category,\n",
    "                'category_type': 'Bilateral' if category in BILATERAL_CATEGORIES else 'Unilateral',\n",
    "                'n_sessions': len(sessions_with_rdm),\n",
    "                'first_session': first_ses, 'last_session': last_ses,\n",
    "                # RSA metrics\n",
    "                'liu_t1': liu_t1, 'liu_t2': liu_t2, 'liu_change': liu_change,\n",
    "                'geometry_preservation': geom_r,\n",
    "                'spatial_drift_mm': drift_mm,\n",
    "                # Univariate metrics\n",
    "                'selectivity_t1': univ_t1, 'selectivity_t2': univ_t2,\n",
    "                'selectivity_change': univ_change,\n",
    "            }\n",
    "            for cat in CATEGORIES:\n",
    "                row[f'mds_shift_{cat}'] = mds_shifts.get(cat, None)\n",
    "            rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "print(\"\\nCOMPUTING METRICS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results_df = compute_all_metrics(all_rdms, all_univariate, ALL_SUBJECTS)\n",
    "print(f\"\\n✓ {len(results_df)} ROI measurements\")\n",
    "print(f\"  Patients: {results_df[results_df['is_patient']].shape[0]}\")\n",
    "print(f\"  Controls: {results_df[~results_df['is_patient']].shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2bc9e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ANALYSIS TABLE\n",
      "============================================================\n",
      "  OTC: 24 rows\n",
      "  nonOTC: 36 rows\n",
      "  control: 36 rows\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 9: Build Analysis Tables\n",
    "\n",
    "\n",
    "def build_analysis_table(results_df):\n",
    "    \"\"\"Patients: single hemisphere. Controls: average L/R.\"\"\"\n",
    "    patients = results_df[results_df['is_patient']].copy()\n",
    "    controls = results_df[~results_df['is_patient']].copy()\n",
    "\n",
    "    metric_cols = [c for c in results_df.columns if c.startswith(('liu_', 'geometry_',\n",
    "                   'spatial_', 'selectivity_', 'mds_shift_'))]\n",
    "\n",
    "    ctrl_avg = controls.groupby(\n",
    "        ['subject', 'code', 'group', 'roi_category', 'category_type']\n",
    "    ).agg({col: 'mean' for col in metric_cols}).reset_index()\n",
    "    ctrl_avg['is_patient'] = False\n",
    "    ctrl_avg['hemisphere'] = 'avg'\n",
    "\n",
    "    keep = ['subject', 'code', 'group', 'is_patient', 'hemisphere',\n",
    "            'roi_category', 'category_type'] + metric_cols\n",
    "    combined = pd.concat([\n",
    "        patients[[c for c in keep if c in patients.columns]],\n",
    "        ctrl_avg[[c for c in keep if c in ctrl_avg.columns]]\n",
    "    ], ignore_index=True)\n",
    "\n",
    "    return combined, controls\n",
    "\n",
    "analysis_df, controls_raw = build_analysis_table(results_df)\n",
    "\n",
    "print(\"\\nANALYSIS TABLE\")\n",
    "print(\"=\" * 60)\n",
    "for g in ['OTC', 'nonOTC', 'control']:\n",
    "    print(f\"  {g}: {len(analysis_df[analysis_df['group']==g])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a74941ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RSA METRICS (Category > Scramble + cocktail blank removal)\n",
      "======================================================================\n",
      "\n",
      "  Liu Distinctiveness Change |T2-T1|:\n",
      "  Group        Bilateral    Unilateral   Diff       n     \n",
      "  ----------------------------------------------------\n",
      "  OTC          0.157        0.118        0.039      24    \n",
      "  nonOTC       0.081        0.122        -0.041     36    \n",
      "  control      0.113        0.113        -0.000     36    \n",
      "\n",
      "  Geometry Preservation (RDM corr):\n",
      "  Group        Bilateral    Unilateral   Diff       n     \n",
      "  ----------------------------------------------------\n",
      "  OTC          0.500        0.205        0.295      24    \n",
      "  nonOTC       0.877        0.600        0.277      36    \n",
      "  control      0.636        0.515        0.121      36    \n",
      "\n",
      "  Spatial Drift (mm):\n",
      "  Group        Bilateral    Unilateral   Diff       n     \n",
      "  ----------------------------------------------------\n",
      "  OTC          10.053       13.494       -3.441     24    \n",
      "  nonOTC       1.875        5.738        -3.862     36    \n",
      "  control      4.954        6.976        -2.022     36    \n",
      "\n",
      "  MDS Shift (Procrustes-aligned):\n",
      "  Group        Bilateral    Unilateral   Diff      \n",
      "  ----------------------------------------------\n",
      "  OTC          0.470        0.366        0.103     \n",
      "  nonOTC       0.229        0.260        -0.031    \n",
      "  control      0.344        0.302        0.042     \n",
      "\n",
      "======================================================================\n",
      "UNIVARIATE SELECTIVITY (Ayzenberg approach: Category > All Others)\n",
      "======================================================================\n",
      "\n",
      "  Selectivity Change |T2-T1|:\n",
      "  Group        Bilateral    Unilateral   Diff      \n",
      "  ----------------------------------------------\n",
      "  OTC          21.096       12.954       8.142     \n",
      "  nonOTC       12.910       8.060        4.850     \n",
      "  control      20.753       17.412       3.342     \n",
      "\n",
      "======================================================================\n",
      "STATISTICAL TESTS\n",
      "======================================================================\n",
      "\n",
      "  Liu Distinctiveness Change |T2-T1|:\n",
      "    OTC Bil vs Uni: MW U=81, p=0.624\n",
      "    OTC vs Ctrl (Bil): MW U=127, p=0.434\n",
      "\n",
      "  Geometry Preservation (RDM corr):\n",
      "    OTC Bil vs Uni: MW U=95, p=0.194\n",
      "    OTC vs Ctrl (Bil): MW U=91, p=0.485\n",
      "\n",
      "  Spatial Drift (mm):\n",
      "    OTC Bil vs Uni: MW U=66, p=0.751\n",
      "    OTC vs Ctrl (Bil): MW U=139, p=0.197\n",
      "\n",
      "  Univariate Selectivity Change:\n",
      "    OTC Bil vs Uni: MW U=90, p=0.312\n",
      "    OTC vs Ctrl (Bil): MW U=102, p=0.816\n",
      "\n",
      "======================================================================\n",
      "PATIENT-BY-PATIENT vs CONTROL DISTRIBUTION\n",
      "======================================================================\n",
      "\n",
      "  liu_change (Bil - Uni difference):\n",
      "    Control: mean=-0.000, 95% CI=[-0.056, 0.051]\n",
      "    OTC004: +0.215 ** OUTSIDE CI **\n",
      "    OTC008: +0.020\n",
      "    OTC010: -0.053\n",
      "    OTC017: -0.020\n",
      "    OTC021: +0.018\n",
      "    OTC079: +0.051\n",
      "\n",
      "  geometry_preservation (Bil - Uni difference):\n",
      "    Control: mean=0.121, 95% CI=[-0.118, 0.320]\n",
      "    OTC004: +0.440 ** OUTSIDE CI **\n",
      "    OTC008: +0.474 ** OUTSIDE CI **\n",
      "    OTC010: +0.683 ** OUTSIDE CI **\n",
      "    OTC017: +1.011 ** OUTSIDE CI **\n",
      "    OTC021: -0.453 ** OUTSIDE CI **\n",
      "    OTC079: -0.385 ** OUTSIDE CI **\n",
      "\n",
      "  selectivity_change (Bil - Uni difference):\n",
      "    Control: mean=3.342, 95% CI=[-3.644, 10.294]\n",
      "    OTC004: +30.476 ** OUTSIDE CI **\n",
      "    OTC008: +17.384 ** OUTSIDE CI **\n",
      "    OTC010: +5.377\n",
      "    OTC017: +6.316\n",
      "    OTC021: -16.427 ** OUTSIDE CI **\n",
      "    OTC079: +5.728\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 10: Group Analysis + Patient-Level Statistics\n",
    "\n",
    "def run_analysis(analysis_df):\n",
    "    \"\"\"Group comparisons + Ayzenberg patient-by-patient tests.\"\"\"\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"RSA METRICS (Category > Scramble + cocktail blank removal)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    rsa_metrics = [\n",
    "        ('liu_change', 'Liu Distinctiveness Change |T2-T1|'),\n",
    "        ('geometry_preservation', 'Geometry Preservation (RDM corr)'),\n",
    "        ('spatial_drift_mm', 'Spatial Drift (mm)'),\n",
    "    ]\n",
    "\n",
    "    for metric, label in rsa_metrics:\n",
    "        print(f\"\\n  {label}:\")\n",
    "        print(f\"  {'Group':<12} {'Bilateral':<12} {'Unilateral':<12} {'Diff':<10} {'n':<6}\")\n",
    "        print(\"  \" + \"-\" * 52)\n",
    "\n",
    "        for grp in ['OTC', 'nonOTC', 'control']:\n",
    "            g = analysis_df[analysis_df['group'] == grp]\n",
    "            bil = g[g['category_type'] == 'Bilateral'][metric].dropna()\n",
    "            uni = g[g['category_type'] == 'Unilateral'][metric].dropna()\n",
    "            diff = bil.mean() - uni.mean() if len(bil) > 0 and len(uni) > 0 else float('nan')\n",
    "            print(f\"  {grp:<12} {bil.mean():<12.3f} {uni.mean():<12.3f} {diff:<10.3f} {len(bil)+len(uni):<6}\")\n",
    "\n",
    "    # MDS Shift\n",
    "    mds_rows = []\n",
    "    for _, row in analysis_df.iterrows():\n",
    "        for cat in CATEGORIES:\n",
    "            val = row.get(f'mds_shift_{cat}')\n",
    "            if val is not None and not np.isnan(val):\n",
    "                mds_rows.append({\n",
    "                    'subject': row['subject'], 'group': row['group'],\n",
    "                    'roi_category': row['roi_category'],\n",
    "                    'measured_category': cat,\n",
    "                    'measured_type': 'Bilateral' if cat in BILATERAL_CATEGORIES else 'Unilateral',\n",
    "                    'mds_shift': val,\n",
    "                })\n",
    "    mds_df = pd.DataFrame(mds_rows)\n",
    "\n",
    "    if len(mds_df) > 0:\n",
    "        print(f\"\\n  MDS Shift (Procrustes-aligned):\")\n",
    "        print(f\"  {'Group':<12} {'Bilateral':<12} {'Unilateral':<12} {'Diff':<10}\")\n",
    "        print(\"  \" + \"-\" * 46)\n",
    "        for grp in ['OTC', 'nonOTC', 'control']:\n",
    "            g = mds_df[mds_df['group'] == grp]\n",
    "            bil = g[g['measured_type'] == 'Bilateral']['mds_shift']\n",
    "            uni = g[g['measured_type'] == 'Unilateral']['mds_shift']\n",
    "            print(f\"  {grp:<12} {bil.mean():<12.3f} {uni.mean():<12.3f} {bil.mean()-uni.mean():<10.3f}\")\n",
    "\n",
    "    # --- Univariate (Ayzenberg) ---\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"UNIVARIATE SELECTIVITY (Ayzenberg approach: Category > All Others)\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    print(f\"\\n  Selectivity Change |T2-T1|:\")\n",
    "    print(f\"  {'Group':<12} {'Bilateral':<12} {'Unilateral':<12} {'Diff':<10}\")\n",
    "    print(\"  \" + \"-\" * 46)\n",
    "    for grp in ['OTC', 'nonOTC', 'control']:\n",
    "        g = analysis_df[analysis_df['group'] == grp]\n",
    "        bil = g[g['category_type'] == 'Bilateral']['selectivity_change'].dropna()\n",
    "        uni = g[g['category_type'] == 'Unilateral']['selectivity_change'].dropna()\n",
    "        diff = bil.mean() - uni.mean() if len(bil) > 0 and len(uni) > 0 else float('nan')\n",
    "        print(f\"  {grp:<12} {bil.mean():<12.3f} {uni.mean():<12.3f} {diff:<10.3f}\")\n",
    "\n",
    "    # --- Statistical Tests ---\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"STATISTICAL TESTS\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    test_metrics = rsa_metrics + [('selectivity_change', 'Univariate Selectivity Change')]\n",
    "    for metric, label in test_metrics:\n",
    "        print(f\"\\n  {label}:\")\n",
    "        otc = analysis_df[analysis_df['group'] == 'OTC']\n",
    "        ctrl = analysis_df[analysis_df['group'] == 'control']\n",
    "\n",
    "        bil_otc = otc[otc['category_type'] == 'Bilateral'][metric].dropna()\n",
    "        uni_otc = otc[otc['category_type'] == 'Unilateral'][metric].dropna()\n",
    "        bil_ctrl = ctrl[ctrl['category_type'] == 'Bilateral'][metric].dropna()\n",
    "\n",
    "        if len(bil_otc) >= 2 and len(uni_otc) >= 2:\n",
    "            u, p = mannwhitneyu(bil_otc, uni_otc, alternative='two-sided')\n",
    "            print(f\"    OTC Bil vs Uni: MW U={u:.0f}, p={p:.3f}\")\n",
    "        if len(bil_otc) >= 2 and len(bil_ctrl) >= 2:\n",
    "            u, p = mannwhitneyu(bil_otc, bil_ctrl, alternative='two-sided')\n",
    "            print(f\"    OTC vs Ctrl (Bil): MW U={u:.0f}, p={p:.3f}\")\n",
    "\n",
    "    # --- Patient-by-Patient (Ayzenberg bootstrapped CI) ---\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"PATIENT-BY-PATIENT vs CONTROL DISTRIBUTION\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for metric in ['liu_change', 'geometry_preservation', 'selectivity_change']:\n",
    "        print(f\"\\n  {metric} (Bil - Uni difference):\")\n",
    "\n",
    "        # Control distribution\n",
    "        ctrl = analysis_df[analysis_df['group'] == 'control']\n",
    "        ctrl_diffs = []\n",
    "        for subj in ctrl['subject'].unique():\n",
    "            s = ctrl[ctrl['subject'] == subj]\n",
    "            b = s[s['category_type'] == 'Bilateral'][metric].mean()\n",
    "            u = s[s['category_type'] == 'Unilateral'][metric].mean()\n",
    "            if not np.isnan(b) and not np.isnan(u):\n",
    "                ctrl_diffs.append(b - u)\n",
    "\n",
    "        ctrl_diffs = np.array(ctrl_diffs)\n",
    "        if len(ctrl_diffs) < 3:\n",
    "            print(\"    Too few controls\")\n",
    "            continue\n",
    "\n",
    "        # Bootstrapped 95% CI\n",
    "        np.random.seed(42)\n",
    "        boots = [np.mean(np.random.choice(ctrl_diffs, len(ctrl_diffs), replace=True))\n",
    "                 for _ in range(10000)]\n",
    "        ci_lo, ci_hi = np.percentile(boots, [2.5, 97.5])\n",
    "        print(f\"    Control: mean={ctrl_diffs.mean():.3f}, 95% CI=[{ci_lo:.3f}, {ci_hi:.3f}]\")\n",
    "\n",
    "        # Each OTC patient\n",
    "        for sid in sorted(ALL_PATIENTS.keys()):\n",
    "            info = ALL_SUBJECTS[sid]\n",
    "            if info['group'] != 'OTC':\n",
    "                continue\n",
    "            pt = analysis_df[analysis_df['subject'] == sid]\n",
    "            b = pt[pt['category_type'] == 'Bilateral'][metric].mean()\n",
    "            u = pt[pt['category_type'] == 'Unilateral'][metric].mean()\n",
    "            if np.isnan(b) or np.isnan(u):\n",
    "                print(f\"    {info['code']}: insufficient data\")\n",
    "                continue\n",
    "            diff = b - u\n",
    "            flag = \" ** OUTSIDE CI **\" if diff > ci_hi or diff < ci_lo else \"\"\n",
    "            print(f\"    {info['code']}: {diff:+.3f}{flag}\")\n",
    "\n",
    "    return mds_df\n",
    "\n",
    "mds_long = run_analysis(analysis_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cf577a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "SENSITIVITY: CONTROLS BY HEMISPHERE\n",
      "======================================================================\n",
      "\n",
      "  liu_change:\n",
      "  Hemi     Bilateral    Unilateral   Diff      \n",
      "  ------------------------------------------\n",
      "  Left     0.116        0.117        -0.001    \n",
      "  Right    0.111        0.110        0.001     \n",
      "\n",
      "  geometry_preservation:\n",
      "  Hemi     Bilateral    Unilateral   Diff      \n",
      "  ------------------------------------------\n",
      "  Left     0.597        0.535        0.062     \n",
      "  Right    0.676        0.496        0.179     \n",
      "\n",
      "  selectivity_change:\n",
      "  Hemi     Bilateral    Unilateral   Diff      \n",
      "  ------------------------------------------\n",
      "  Left     20.617       19.371       1.246     \n",
      "  Right    20.890       15.452       5.438     \n"
     ]
    }
   ],
   "source": [
    "# %% Cell 11: Sensitivity — Controls by Hemisphere\n",
    "\n",
    "def sensitivity_hemisphere(controls_raw):\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"SENSITIVITY: CONTROLS BY HEMISPHERE\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "    for metric in ['liu_change', 'geometry_preservation', 'selectivity_change']:\n",
    "        print(f\"\\n  {metric}:\")\n",
    "        print(f\"  {'Hemi':<8} {'Bilateral':<12} {'Unilateral':<12} {'Diff':<10}\")\n",
    "        print(\"  \" + \"-\" * 42)\n",
    "        for hemi in ['l', 'r']:\n",
    "            h = controls_raw[controls_raw['hemisphere'] == hemi]\n",
    "            bil = h[h['category_type'] == 'Bilateral'][metric].dropna()\n",
    "            uni = h[h['category_type'] == 'Unilateral'][metric].dropna()\n",
    "            diff = bil.mean() - uni.mean() if len(bil) > 0 and len(uni) > 0 else float('nan')\n",
    "            print(f\"  {'Left' if hemi=='l' else 'Right':<8} {bil.mean():<12.3f} {uni.mean():<12.3f} {diff:<10.3f}\")\n",
    "\n",
    "sensitivity_hemisphere(controls_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8cd4462a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION\n",
      "======================================================================\n",
      "\n",
      "Subjects: 24\n",
      "\n",
      "  OTC: 6 subjects, 24 ROIs\n",
      "    Bilateral: 12 (6 subjects)\n",
      "    Unilateral: 12 (6 subjects)\n",
      "\n",
      "  nonOTC: 9 subjects, 36 ROIs\n",
      "    Bilateral: 18 (9 subjects)\n",
      "    Unilateral: 18 (9 subjects)\n",
      "\n",
      "  control: 9 subjects, 36 ROIs\n",
      "    Bilateral: 18 (9 subjects)\n",
      "    Unilateral: 18 (9 subjects)\n",
      "\n",
      "Per-subject:\n",
      "  OTC004 (OTC): 4 ROIs\n",
      "  OTC008 (OTC): 4 ROIs\n",
      "  OTC010 (OTC): 4 ROIs\n",
      "  OTC017 (OTC): 4 ROIs\n",
      "  OTC021 (OTC): 4 ROIs\n",
      "  OTC079 (OTC): 4 ROIs\n",
      "  control018 (control): 4 ROIs\n",
      "  control022 (control): 4 ROIs\n",
      "  control025 (control): 4 ROIs\n",
      "  control027 (control): 4 ROIs\n",
      "  control052 (control): 4 ROIs\n",
      "  control058 (control): 4 ROIs\n",
      "  control062 (control): 4 ROIs\n",
      "  control064 (control): 4 ROIs\n",
      "  control068 (control): 4 ROIs\n",
      "  nonOTC007 (nonOTC): 4 ROIs\n",
      "  nonOTC045 (nonOTC): 4 ROIs\n",
      "  nonOTC047 (nonOTC): 4 ROIs\n",
      "  nonOTC049 (nonOTC): 4 ROIs\n",
      "  nonOTC070 (nonOTC): 4 ROIs\n",
      "  nonOTC072 (nonOTC): 4 ROIs\n",
      "  nonOTC073 (nonOTC): 4 ROIs\n",
      "  nonOTC081 (nonOTC): 4 ROIs\n",
      "  nonOTC086 (nonOTC): 4 ROIs\n"
     ]
    }
   ],
   "source": [
    "# %% Cell 12: Verification\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"VERIFICATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nSubjects: {analysis_df['subject'].nunique()}\")\n",
    "for grp in ['OTC', 'nonOTC', 'control']:\n",
    "    g = analysis_df[analysis_df['group'] == grp]\n",
    "    print(f\"\\n  {grp}: {g['subject'].nunique()} subjects, {len(g)} ROIs\")\n",
    "    for ct in ['Bilateral', 'Unilateral']:\n",
    "        c = g[g['category_type'] == ct]\n",
    "        print(f\"    {ct}: {len(c)} ({c['subject'].nunique()} subjects)\")\n",
    "\n",
    "print(f\"\\nPer-subject:\")\n",
    "for _, row in analysis_df.groupby(['code', 'group']).size().reset_index(name='n').iterrows():\n",
    "    flag = \" ⚠️\" if row['n'] < 4 else \"\"\n",
    "    print(f\"  {row['code']} ({row['group']}): {row['n']} ROIs{flag}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e6c7fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% Cell 13: Save\n",
    "\n",
    "import pickle\n",
    "\n",
    "save_data = {\n",
    "    'all_rois': all_rois,\n",
    "    'all_rdms': all_rdms,\n",
    "    'all_univariate': all_univariate,\n",
    "    'results_df': results_df,\n",
    "    'analysis_df': analysis_df,\n",
    "    'controls_raw': controls_raw,\n",
    "    'config': {\n",
    "        'localizer_copes': LOCALIZER_COPES,\n",
    "        'rsa_input': 'per-condition PEs (registered_pes/), Liu approach',\n",
    "        'univariate_copes': UNIVARIATE_COPES,\n",
    "        'percentile': ROI_PERCENTILE,\n",
    "        'sphere_radius': SPHERE_RADIUS,\n",
    "        'excluded_subjects': SUBJECTS_TO_EXCLUDE,\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTPUT_DIR / \"unified_rsa_results.pkl\", 'wb') as f:\n",
    "    pickle.dump(save_data, f)\n",
    "\n",
    "analysis_df.to_csv(OUTPUT_DIR / \"analysis_table.csv\", index=False)\n",
    "results_df.to_csv(OUTPUT_DIR / \"full_results.csv\", index=False)\n",
    "\n",
    "print(f\"\\n✓ Saved to {OUTPUT_DIR}\")\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "837b926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cell 1 complete\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 1: Setup and Configuration\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import label, center_of_mass\n",
    "from scipy.stats import pearsonr, ttest_ind, f_oneway, ttest_1samp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Paths\n",
    "CSV_FILE = Path('/user_data/csimmon2/git_repos/long_pt/long_pt_sub_info.csv')\n",
    "BASE_DIR = Path(\"/user_data/csimmon2/long_pt\")\n",
    "\n",
    "# Session adjustments\n",
    "SESSION_START = {'sub-010': 2, 'sub-018': 2, 'sub-068': 2}\n",
    "\n",
    "# Contrast definitions\n",
    "COPE_MAP_DIFFERENTIAL = {\n",
    "    'face': (10, 1),\n",
    "    'word': (13, -1),\n",
    "    'object': (3, 1),\n",
    "    'house': (11, 1)\n",
    "}\n",
    "\n",
    "# Exclusions\n",
    "EXCLUDE_SUBS = ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
    "\n",
    "# Load subject info\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "\n",
    "print(\"✓ Cell 1 complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da45abd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 25 subjects\n",
      "  OTC: 7\n",
      "  nonOTC: 9\n",
      "  control: 9\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 2: Load Subjects by Group\n",
    "# =============================================================================\n",
    "def load_subjects_by_group(group_filter=None, patient_only=True):\n",
    "    filtered_df = df.copy()\n",
    "    \n",
    "    if patient_only is True:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 1]\n",
    "    elif patient_only is False:\n",
    "        filtered_df = filtered_df[filtered_df['patient'] == 0]\n",
    "    \n",
    "    if group_filter:\n",
    "        if isinstance(group_filter, str):\n",
    "            group_filter = [group_filter]\n",
    "        filtered_df = filtered_df[filtered_df['group'].isin(group_filter)]\n",
    "    \n",
    "    subjects = {}\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        subject_id = row['sub']\n",
    "        subj_dir = BASE_DIR / subject_id\n",
    "        if not subj_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        sessions = sorted([d.name.replace('ses-', '') for d in subj_dir.glob('ses-*') if d.is_dir()], key=int)\n",
    "        start_session = SESSION_START.get(subject_id, 1)\n",
    "        sessions = [s for s in sessions if int(s) >= start_session]\n",
    "        if not sessions:\n",
    "            continue\n",
    "        \n",
    "        hemisphere = 'l' if row.get('intact_hemi', 'left') == 'left' else 'r'\n",
    "        \n",
    "        subjects[subject_id] = {\n",
    "            'code': f\"{row['group']}{subject_id.split('-')[1]}\",\n",
    "            'sessions': sessions,\n",
    "            'hemi': hemisphere,\n",
    "            'group': row['group'],\n",
    "            'patient_status': 'patient' if row['patient'] == 1 else 'control',\n",
    "            'surgery_side': row.get('SurgerySide', None)\n",
    "        }\n",
    "    return subjects\n",
    "\n",
    "ALL_PATIENTS = load_subjects_by_group(patient_only=True)\n",
    "ALL_CONTROLS = load_subjects_by_group(patient_only=False)\n",
    "ANALYSIS_SUBJECTS = {**ALL_PATIENTS, **ALL_CONTROLS}\n",
    "\n",
    "print(f\"✓ Loaded {len(ANALYSIS_SUBJECTS)} subjects\")\n",
    "for g in ['OTC', 'nonOTC', 'control']:\n",
    "    n = sum(1 for v in ANALYSIS_SUBJECTS.values() if v['group'] == g)\n",
    "    print(f\"  {g}: {n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9b6e26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Peak Locations (Golarai method)...\n",
      "Computing Peak-Based Drift...\n",
      "\n",
      "✓ 20 subjects, 108 measurements\n",
      "  Excluded: ['sub-025', 'sub-027', 'sub-045', 'sub-072']\n",
      "✓ Saved to drift_peak_golarai.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 3: SPATIAL DRIFT - Peak-Based Extraction (Golarai Method)\n",
    "# =============================================================================\n",
    "# Following Golarai et al. (2015): Track peak voxel location across sessions\n",
    "# Drift = Euclidean distance between T1 and T2 peak coordinates (mm)\n",
    "# =============================================================================\n",
    "\n",
    "def extract_peak_locations(subject_id, cope_map):\n",
    "    \"\"\"Extract peak voxel (max T-value) locations within search mask for each session\"\"\"\n",
    "    \n",
    "    info = ANALYSIS_SUBJECTS[subject_id]\n",
    "    roi_dir = BASE_DIR / subject_id / f'ses-{info[\"sessions\"][0]}' / 'ROIs'\n",
    "    if not roi_dir.exists(): \n",
    "        return {}\n",
    "    \n",
    "    all_results = {}\n",
    "    first_session = info['sessions'][0]\n",
    "\n",
    "    for hemi in ['l', 'r']:\n",
    "        for category, (cope_num, multiplier) in cope_map.items():\n",
    "            \n",
    "            mask_file = roi_dir / f'{hemi}_{category}_searchmask.nii.gz'\n",
    "            if not mask_file.exists(): \n",
    "                continue\n",
    "            \n",
    "            try:\n",
    "                search_mask_img = nib.load(mask_file)\n",
    "                search_mask = search_mask_img.get_fdata() > 0\n",
    "                affine = search_mask_img.affine\n",
    "            except: \n",
    "                continue\n",
    "            \n",
    "            hemi_key = f'{hemi}_{category}'\n",
    "            all_results[hemi_key] = {}\n",
    "            \n",
    "            for session in info['sessions']:\n",
    "                feat_dir = BASE_DIR / subject_id / f'ses-{session}' / 'derivatives' / 'fsl' / 'loc' / 'HighLevel.gfeat'\n",
    "                z_name = 'zstat1.nii.gz' if session == first_session else f'zstat1_ses{first_session}.nii.gz'\n",
    "                cope_file = feat_dir / f'cope{cope_num}.feat' / 'stats' / z_name\n",
    "                \n",
    "                if not cope_file.exists(): \n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    z_data = nib.load(cope_file).get_fdata() * multiplier\n",
    "                    z_masked = np.where(search_mask & (z_data > 0), z_data, -np.inf)\n",
    "                    peak_idx = np.unravel_index(np.argmax(z_masked), z_masked.shape)\n",
    "                    peak_z = z_data[peak_idx]\n",
    "                    \n",
    "                    if peak_z <= 0:\n",
    "                        continue\n",
    "                    \n",
    "                    peak_mni = nib.affines.apply_affine(affine, peak_idx)\n",
    "                    \n",
    "                    all_results[hemi_key][session] = {\n",
    "                        'peak_idx': peak_idx,\n",
    "                        'peak_mni': peak_mni,\n",
    "                        'peak_z': peak_z\n",
    "                    }\n",
    "                except Exception as e:\n",
    "                    print(f\"Error {subject_id} {hemi_key} ses-{session}: {e}\")\n",
    "                    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def compute_peak_drift(peak_results, subjects_dict):\n",
    "    \"\"\"Compute Euclidean distance between T1 and T2 peak locations (mm)\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for sid, rois in peak_results.items():\n",
    "        if sid in EXCLUDE_SUBS:\n",
    "            continue\n",
    "        info = subjects_dict.get(sid, {})\n",
    "        \n",
    "        for roi_key, sessions_data in rois.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            peak_t1 = np.array(sessions_data[sessions[0]]['peak_mni'])\n",
    "            peak_t2 = np.array(sessions_data[sessions[-1]]['peak_mni'])\n",
    "            drift_mm = np.linalg.norm(peak_t2 - peak_t1)\n",
    "            \n",
    "            t1_z = sessions_data[sessions[0]]['peak_z']\n",
    "            hemi = roi_key.split('_')[0]\n",
    "            category = roi_key.split('_')[1]\n",
    "            \n",
    "            results.append({\n",
    "                'subject': sid,\n",
    "                'code': subjects_dict[sid].get('code', sid),\n",
    "                'group': subjects_dict[sid].get('group', 'unknown'),\n",
    "                'hemi': hemi,\n",
    "                'category': category,\n",
    "                'category_type': 'Bilateral' if category in ['object', 'house'] else 'Unilateral',\n",
    "                'peak_drift_mm': drift_mm,\n",
    "                't1_peak_z': t1_z,\n",
    "                't2_peak_z': sessions_data[sessions[-1]]['peak_z'],\n",
    "                'flag': 'WEAK_SIGNAL' if t1_z < 2.3 else ''\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "# Run extraction\n",
    "print(\"Extracting Peak Locations (Golarai method)...\")\n",
    "peak_locations = {}\n",
    "for sub in ANALYSIS_SUBJECTS:\n",
    "    if sub not in EXCLUDE_SUBS:\n",
    "        res = extract_peak_locations(sub, COPE_MAP_DIFFERENTIAL)\n",
    "        if res: \n",
    "            peak_locations[sub] = res\n",
    "\n",
    "print(\"Computing Peak-Based Drift...\")\n",
    "drift_peak = compute_peak_drift(peak_locations, ANALYSIS_SUBJECTS)\n",
    "\n",
    "# Add hemisphere info\n",
    "drift_peak['intact_hemi'] = drift_peak['subject'].map(lambda s: ANALYSIS_SUBJECTS[s]['hemi'])\n",
    "\n",
    "print(f\"\\n✓ {drift_peak['subject'].nunique()} subjects, {len(drift_peak)} measurements\")\n",
    "print(f\"  Excluded: {EXCLUDE_SUBS}\")\n",
    "\n",
    "# Save\n",
    "drift_peak.to_csv('drift_peak_golarai.csv', index=False)\n",
    "print(\"✓ Saved to drift_peak_golarai.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34b5eae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================================================================================\n",
      "SPATIAL DRIFT BY CATEGORY (Euclidean Distance)\n",
      "=====================================================================================\n",
      "\n",
      "Category   Type     OTC-intact             nonOTC-intact          Control               \n",
      "-------------------------------------------------------------------------------------\n",
      "face       Uni      6.6 ± 7.8 [n=6]        2.8 ± 5.0 [n=7]        1.4 ± 1.0 [n=7]       \n",
      "word       Uni      13.7 ± 12.7 [n=6]      10.8 ± 8.1 [n=7]       14.2 ± 10.9 [n=7]     \n",
      "object     Bil      5.2 ± 2.6 [n=6]        5.2 ± 6.8 [n=7]        9.1 ± 8.7 [n=14]      \n",
      "house      Bil      15.4 ± 18.7 [n=6]      3.4 ± 2.3 [n=7]        9.7 ± 12.6 [n=14]     \n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "=====================================================================================\n",
      "SPATIAL DRIFT BY CATEGORY TYPE\n",
      "=====================================================================================\n",
      "\n",
      "Type         OTC-intact             nonOTC-intact          Control               \n",
      "-------------------------------------------------------------------------------------\n",
      "Unilateral   10.1 ± 10.7 [n=12]      6.8 ± 7.7 [n=14]      7.8 ± 10.0 [n=14]\n",
      "Bilateral    10.3 ± 13.8 [n=12]      4.3 ± 5.0 [n=14]      9.4 ± 10.7 [n=28]\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "=====================================================================================\n",
      "STATISTICAL TESTS (OTC vs Control)\n",
      "=====================================================================================\n",
      "face (Uni): t = 1.766, p = 0.1051\n",
      "word (Uni): t = -0.082, p = 0.9364\n",
      "object (Bil): t = -1.050, p = 0.3076\n",
      "house (Bil): t = 0.813, p = 0.4267\n",
      "\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 4: SPATIAL DRIFT - Descriptives and Statistical Tests (Euclidean)\n",
    "# =============================================================================\n",
    "# Hemisphere selection:\n",
    "#   OTC/nonOTC: intact hemisphere only\n",
    "#   Controls: face=R, word=L, object/house=both\n",
    "# =============================================================================\n",
    "\n",
    "df_drift = drift_peak.copy()\n",
    "\n",
    "# Filter by appropriate hemisphere\n",
    "otc = df_drift[(df_drift['group'] == 'OTC') & (df_drift['hemi'] == df_drift['intact_hemi'])]\n",
    "nonotc = df_drift[(df_drift['group'] == 'nonOTC') & (df_drift['hemi'] == df_drift['intact_hemi'])]\n",
    "ctrl = df_drift[df_drift['group'] == 'control']\n",
    "\n",
    "# Control subsets by category\n",
    "ctrl_face = ctrl[(ctrl['category'] == 'face') & (ctrl['hemi'] == 'r')]\n",
    "ctrl_word = ctrl[(ctrl['category'] == 'word') & (ctrl['hemi'] == 'l')]\n",
    "ctrl_object = ctrl[ctrl['category'] == 'object']\n",
    "ctrl_house = ctrl[ctrl['category'] == 'house']\n",
    "\n",
    "ctrl_by_cat = {'face': ctrl_face, 'word': ctrl_word, 'object': ctrl_object, 'house': ctrl_house}\n",
    "\n",
    "# ============================================================\n",
    "# DESCRIPTIVES BY CATEGORY\n",
    "# ============================================================\n",
    "print(\"=\"*85)\n",
    "print(\"SPATIAL DRIFT BY CATEGORY (Euclidean Distance)\")\n",
    "print(\"=\"*85)\n",
    "print(f\"\\n{'Category':<10} {'Type':<8} {'OTC-intact':<22} {'nonOTC-intact':<22} {'Control':<22}\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "for cat in ['face', 'word', 'object', 'house']:\n",
    "    otc_vals = otc[otc['category'] == cat]['peak_drift_mm']\n",
    "    nonotc_vals = nonotc[nonotc['category'] == cat]['peak_drift_mm']\n",
    "    ctrl_vals = ctrl_by_cat[cat]['peak_drift_mm']\n",
    "    \n",
    "    cat_type = \"Uni\" if cat in ['face', 'word'] else \"Bil\"\n",
    "    \n",
    "    otc_str = f\"{otc_vals.mean():.1f} ± {otc_vals.std():.1f} [n={len(otc_vals)}]\"\n",
    "    nonotc_str = f\"{nonotc_vals.mean():.1f} ± {nonotc_vals.std():.1f} [n={len(nonotc_vals)}]\"\n",
    "    ctrl_str = f\"{ctrl_vals.mean():.1f} ± {ctrl_vals.std():.1f} [n={len(ctrl_vals)}]\"\n",
    "    \n",
    "    print(f\"{cat:<10} {cat_type:<8} {otc_str:<22} {nonotc_str:<22} {ctrl_str:<22}\")\n",
    "\n",
    "print(\"-\"*85)\n",
    "\n",
    "# ============================================================\n",
    "# DESCRIPTIVES BY CATEGORY TYPE\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"SPATIAL DRIFT BY CATEGORY TYPE\")\n",
    "print(\"=\"*85)\n",
    "\n",
    "otc_uni = otc[otc['category'].isin(['face', 'word'])]['peak_drift_mm']\n",
    "otc_bil = otc[otc['category'].isin(['object', 'house'])]['peak_drift_mm']\n",
    "nonotc_uni = nonotc[nonotc['category'].isin(['face', 'word'])]['peak_drift_mm']\n",
    "nonotc_bil = nonotc[nonotc['category'].isin(['object', 'house'])]['peak_drift_mm']\n",
    "ctrl_uni = pd.concat([ctrl_face['peak_drift_mm'], ctrl_word['peak_drift_mm']])\n",
    "ctrl_bil = pd.concat([ctrl_object['peak_drift_mm'], ctrl_house['peak_drift_mm']])\n",
    "\n",
    "print(f\"\\n{'Type':<12} {'OTC-intact':<22} {'nonOTC-intact':<22} {'Control':<22}\")\n",
    "print(\"-\"*85)\n",
    "print(f\"{'Unilateral':<12} {otc_uni.mean():.1f} ± {otc_uni.std():.1f} [n={len(otc_uni)}]{'':5} {nonotc_uni.mean():.1f} ± {nonotc_uni.std():.1f} [n={len(nonotc_uni)}]{'':5} {ctrl_uni.mean():.1f} ± {ctrl_uni.std():.1f} [n={len(ctrl_uni)}]\")\n",
    "print(f\"{'Bilateral':<12} {otc_bil.mean():.1f} ± {otc_bil.std():.1f} [n={len(otc_bil)}]{'':5} {nonotc_bil.mean():.1f} ± {nonotc_bil.std():.1f} [n={len(nonotc_bil)}]{'':5} {ctrl_bil.mean():.1f} ± {ctrl_bil.std():.1f} [n={len(ctrl_bil)}]\")\n",
    "print(\"-\"*85)\n",
    "\n",
    "# ============================================================\n",
    "# STATISTICAL TESTS\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*85)\n",
    "print(\"STATISTICAL TESTS (OTC vs Control)\")\n",
    "print(\"=\"*85)\n",
    "\n",
    "for cat in ['face', 'word', 'object', 'house']:\n",
    "    otc_vals = otc[otc['category'] == cat]['peak_drift_mm']\n",
    "    ctrl_vals = ctrl_by_cat[cat]['peak_drift_mm']\n",
    "    cat_type = \"Uni\" if cat in ['face', 'word'] else \"Bil\"\n",
    "    \n",
    "    if len(otc_vals) > 1 and len(ctrl_vals) > 1:\n",
    "        t, p = ttest_ind(otc_vals, ctrl_vals)\n",
    "        print(f\"{cat} ({cat_type}): t = {t:.3f}, p = {p:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "306ffda7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted 108 ROIs with directional drift data\n",
      "  OTC: 24\n",
      "  nonOTC: 28\n",
      "  Control: 56\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>code</th>\n",
       "      <th>group</th>\n",
       "      <th>hemisphere</th>\n",
       "      <th>category</th>\n",
       "      <th>category_type</th>\n",
       "      <th>intact_hemi</th>\n",
       "      <th>x_T1</th>\n",
       "      <th>y_T1</th>\n",
       "      <th>z_T1</th>\n",
       "      <th>...</th>\n",
       "      <th>y_T2</th>\n",
       "      <th>z_T2</th>\n",
       "      <th>delta_x</th>\n",
       "      <th>delta_y</th>\n",
       "      <th>delta_z</th>\n",
       "      <th>euclidean_dist</th>\n",
       "      <th>t1_peak_z</th>\n",
       "      <th>t2_peak_z</th>\n",
       "      <th>T1_session</th>\n",
       "      <th>T2_session</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>OTC004</td>\n",
       "      <td>OTC</td>\n",
       "      <td>l</td>\n",
       "      <td>face</td>\n",
       "      <td>Unilateral</td>\n",
       "      <td>l</td>\n",
       "      <td>-27.5</td>\n",
       "      <td>-32.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-52.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>-20.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.293497</td>\n",
       "      <td>3.500539</td>\n",
       "      <td>13.334448</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>OTC004</td>\n",
       "      <td>OTC</td>\n",
       "      <td>l</td>\n",
       "      <td>word</td>\n",
       "      <td>Unilateral</td>\n",
       "      <td>l</td>\n",
       "      <td>-29.5</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>6.480741</td>\n",
       "      <td>4.249987</td>\n",
       "      <td>2.070664</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>OTC004</td>\n",
       "      <td>OTC</td>\n",
       "      <td>l</td>\n",
       "      <td>object</td>\n",
       "      <td>Bilateral</td>\n",
       "      <td>l</td>\n",
       "      <td>-32.5</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-66.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>9.219544</td>\n",
       "      <td>6.774813</td>\n",
       "      <td>11.288923</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-004</td>\n",
       "      <td>OTC004</td>\n",
       "      <td>OTC</td>\n",
       "      <td>l</td>\n",
       "      <td>house</td>\n",
       "      <td>Bilateral</td>\n",
       "      <td>l</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>-64.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>22.293497</td>\n",
       "      <td>5.253273</td>\n",
       "      <td>12.639606</td>\n",
       "      <td>01</td>\n",
       "      <td>06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-007</td>\n",
       "      <td>nonOTC007</td>\n",
       "      <td>nonOTC</td>\n",
       "      <td>r</td>\n",
       "      <td>face</td>\n",
       "      <td>Unilateral</td>\n",
       "      <td>r</td>\n",
       "      <td>34.5</td>\n",
       "      <td>-41.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-42.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.732051</td>\n",
       "      <td>9.558907</td>\n",
       "      <td>14.582060</td>\n",
       "      <td>01</td>\n",
       "      <td>04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject       code   group hemisphere category category_type intact_hemi  \\\n",
       "0  sub-004     OTC004     OTC          l     face    Unilateral           l   \n",
       "1  sub-004     OTC004     OTC          l     word    Unilateral           l   \n",
       "2  sub-004     OTC004     OTC          l   object     Bilateral           l   \n",
       "3  sub-004     OTC004     OTC          l    house     Bilateral           l   \n",
       "4  sub-007  nonOTC007  nonOTC          r     face    Unilateral           r   \n",
       "\n",
       "   x_T1  y_T1  z_T1  ...  y_T2  z_T2  delta_x  delta_y  delta_z  \\\n",
       "0 -27.5 -32.0  -9.0  ... -52.0   0.0     -4.0    -20.0      9.0   \n",
       "1 -29.5 -19.0   6.0  ... -18.0   1.0      4.0      1.0     -5.0   \n",
       "2 -32.5 -75.0  13.0  ... -66.0  11.0      0.0      9.0     -2.0   \n",
       "3 -19.5 -64.0   8.0  ... -42.0  10.0     -3.0     22.0      2.0   \n",
       "4  34.5 -41.0   4.0  ... -42.0   5.0      1.0     -1.0      1.0   \n",
       "\n",
       "   euclidean_dist  t1_peak_z  t2_peak_z  T1_session T2_session  \n",
       "0       22.293497   3.500539  13.334448          01         06  \n",
       "1        6.480741   4.249987   2.070664          01         06  \n",
       "2        9.219544   6.774813  11.288923          01         06  \n",
       "3       22.293497   5.253273  12.639606          01         06  \n",
       "4        1.732051   9.558907  14.582060          01         04  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 5: DIRECTIONAL DRIFT - Extract Signed Coordinate Differences\n",
    "# =============================================================================\n",
    "# This extracts signed (T2 - T1) differences for each coordinate axis\n",
    "# to test whether drift is SYSTEMATIC (directional) or just NOISE\n",
    "# =============================================================================\n",
    "\n",
    "def extract_directional_drift(peak_results, subjects_dict):\n",
    "    \"\"\"\n",
    "    Extract signed coordinate differences (T2 - T1) for each ROI.\n",
    "    Returns DataFrame with delta_x, delta_y, delta_z (signed) plus euclidean_dist.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for sid, rois in peak_results.items():\n",
    "        if sid in EXCLUDE_SUBS:\n",
    "            continue\n",
    "            \n",
    "        info = subjects_dict.get(sid, {})\n",
    "        group = info.get('group', 'control')\n",
    "        if info.get('patient_status') == 'control': \n",
    "            group = 'Control'\n",
    "        elif group == 'nonOTC':\n",
    "            group = 'nonOTC'\n",
    "        elif group == 'OTC':\n",
    "            group = 'OTC'\n",
    "        \n",
    "        for roi_key, sessions_data in rois.items():\n",
    "            sessions = sorted(sessions_data.keys())\n",
    "            if len(sessions) < 2:\n",
    "                continue\n",
    "            \n",
    "            hemi = roi_key.split('_')[0]\n",
    "            cat = roi_key.split('_')[1]\n",
    "            \n",
    "            peak_t1 = sessions_data[sessions[0]]['peak_mni']\n",
    "            peak_t2 = sessions_data[sessions[-1]]['peak_mni']\n",
    "            \n",
    "            # Signed differences (T2 - T1)\n",
    "            dx = peak_t2[0] - peak_t1[0]  # medial-lateral\n",
    "            dy = peak_t2[1] - peak_t1[1]  # anterior-posterior\n",
    "            dz = peak_t2[2] - peak_t1[2]  # superior-inferior\n",
    "            \n",
    "            # Euclidean distance\n",
    "            euclidean = np.sqrt(dx**2 + dy**2 + dz**2)\n",
    "            \n",
    "            results.append({\n",
    "                'subject': sid,\n",
    "                'code': info.get('code', sid),\n",
    "                'group': group,\n",
    "                'hemisphere': hemi,\n",
    "                'category': cat,\n",
    "                'category_type': 'Bilateral' if cat in ['object', 'house'] else 'Unilateral',\n",
    "                'intact_hemi': info.get('hemi', 'unknown'),\n",
    "                'x_T1': peak_t1[0], 'y_T1': peak_t1[1], 'z_T1': peak_t1[2],\n",
    "                'x_T2': peak_t2[0], 'y_T2': peak_t2[1], 'z_T2': peak_t2[2],\n",
    "                'delta_x': dx,\n",
    "                'delta_y': dy,\n",
    "                'delta_z': dz,\n",
    "                'euclidean_dist': euclidean,\n",
    "                't1_peak_z': sessions_data[sessions[0]]['peak_z'],\n",
    "                't2_peak_z': sessions_data[sessions[-1]]['peak_z'],\n",
    "                'T1_session': sessions[0],\n",
    "                'T2_session': sessions[-1]\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Extract directional drift\n",
    "dir_drift_df = extract_directional_drift(peak_locations, ANALYSIS_SUBJECTS)\n",
    "\n",
    "print(f\"✓ Extracted {len(dir_drift_df)} ROIs with directional drift data\")\n",
    "print(f\"  OTC: {len(dir_drift_df[dir_drift_df['group'] == 'OTC'])}\")\n",
    "print(f\"  nonOTC: {len(dir_drift_df[dir_drift_df['group'] == 'nonOTC'])}\")\n",
    "print(f\"  Control: {len(dir_drift_df[dir_drift_df['group'] == 'Control'])}\")\n",
    "\n",
    "dir_drift_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bdfb832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ After hemisphere filtering: 94 measurements\n",
      "  OTC: 24\n",
      "  nonOTC: 28\n",
      "  Control: 42\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 6: DIRECTIONAL DRIFT - Filter by Appropriate Hemisphere\n",
    "# =============================================================================\n",
    "# Same hemisphere rules as Euclidean analysis\n",
    "\n",
    "# Filter function\n",
    "def filter_by_hemisphere(df):\n",
    "    \"\"\"Apply hemisphere selection rules\"\"\"\n",
    "    # OTC/nonOTC: intact hemisphere only\n",
    "    otc = df[(df['group'] == 'OTC') & (df['hemisphere'] == df['intact_hemi'])]\n",
    "    nonotc = df[(df['group'] == 'nonOTC') & (df['hemisphere'] == df['intact_hemi'])]\n",
    "    \n",
    "    # Controls: face=R, word=L, object/house=both\n",
    "    ctrl = df[df['group'] == 'Control']\n",
    "    ctrl_face = ctrl[(ctrl['category'] == 'face') & (ctrl['hemisphere'] == 'r')]\n",
    "    ctrl_word = ctrl[(ctrl['category'] == 'word') & (ctrl['hemisphere'] == 'l')]\n",
    "    ctrl_bilateral = ctrl[ctrl['category'].isin(['object', 'house'])]\n",
    "    ctrl_filtered = pd.concat([ctrl_face, ctrl_word, ctrl_bilateral])\n",
    "    \n",
    "    return pd.concat([otc, nonotc, ctrl_filtered])\n",
    "\n",
    "# Apply filter\n",
    "dir_drift_filtered = filter_by_hemisphere(dir_drift_df)\n",
    "\n",
    "print(f\"✓ After hemisphere filtering: {len(dir_drift_filtered)} measurements\")\n",
    "print(f\"  OTC: {len(dir_drift_filtered[dir_drift_filtered['group'] == 'OTC'])}\")\n",
    "print(f\"  nonOTC: {len(dir_drift_filtered[dir_drift_filtered['group'] == 'nonOTC'])}\")\n",
    "print(f\"  Control: {len(dir_drift_filtered[dir_drift_filtered['group'] == 'Control'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fae8ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "TEST FOR SYSTEMATIC DRIFT (One-sample t-test: H0 = mean drift is 0)\n",
      "==========================================================================================\n",
      "\n",
      "If p > 0.05: No systematic drift → CONSISTENT with literature\n",
      "If p < 0.05: Systematic drift in that direction\n",
      "\n",
      "  Group               Axis  n  Mean (mm)    SD      95% CI     t      p  Cohen's d Systematic?\n",
      "    OTC     Medial-Lateral 24      -0.36  3.94 [-1.9, 1.2] -0.44 0.6612      -0.09          No\n",
      "    OTC Anterior-Posterior 24       4.15 14.40 [-1.6, 9.9]  1.41 0.1718       0.29          No\n",
      "    OTC  Superior-Inferior 24       0.20  3.81 [-1.3, 1.7]  0.26 0.8009       0.05          No\n",
      " nonOTC     Medial-Lateral 28      -0.75  4.36 [-2.4, 0.9] -0.92 0.3680      -0.17          No\n",
      " nonOTC Anterior-Posterior 28       1.42  6.71 [-1.1, 3.9]  1.12 0.2721       0.21          No\n",
      " nonOTC  Superior-Inferior 28      -0.12  2.71 [-1.1, 0.9] -0.24 0.8121      -0.05          No\n",
      "Control     Medial-Lateral 42       1.44  6.16 [-0.4, 3.3]  1.52 0.1374       0.23          No\n",
      "Control Anterior-Posterior 42      -1.57 10.61 [-4.8, 1.6] -0.96 0.3437      -0.15          No\n",
      "Control  Superior-Inferior 42      -0.10  5.65 [-1.8, 1.6] -0.12 0.9055      -0.02          No\n",
      "\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 7: DIRECTIONAL DRIFT - Statistical Tests for Systematic Drift\n",
    "# =============================================================================\n",
    "# H0: Mean drift = 0 (peaks fluctuate randomly around stable location)\n",
    "# If p > 0.05 → No systematic drift (CONSISTENT with Dehaene-Lambertz)\n",
    "# =============================================================================\n",
    "\n",
    "def test_systematic_drift(df, group_col='group'):\n",
    "    \"\"\"\n",
    "    Test whether drift is systematic (mean ≠ 0) for each group.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    coord_labels = {'delta_x': 'Medial-Lateral', 'delta_y': 'Anterior-Posterior', 'delta_z': 'Superior-Inferior'}\n",
    "    \n",
    "    for group in df[group_col].unique():\n",
    "        group_data = df[df[group_col] == group]\n",
    "        \n",
    "        for coord in ['delta_x', 'delta_y', 'delta_z']:\n",
    "            values = group_data[coord].dropna()\n",
    "            n = len(values)\n",
    "            \n",
    "            if n < 3:\n",
    "                continue\n",
    "            \n",
    "            # One-sample t-test: H0 = mean is 0\n",
    "            t_stat, p_val = ttest_1samp(values, 0)\n",
    "            \n",
    "            # Effect size (Cohen's d)\n",
    "            cohens_d = values.mean() / values.std() if values.std() > 0 else 0\n",
    "            \n",
    "            # 95% CI\n",
    "            sem = values.sem()\n",
    "            ci_low = values.mean() - 1.96 * sem\n",
    "            ci_high = values.mean() + 1.96 * sem\n",
    "            \n",
    "            results.append({\n",
    "                'Group': group,\n",
    "                'Axis': coord_labels[coord],\n",
    "                'n': n,\n",
    "                'Mean (mm)': round(values.mean(), 2),\n",
    "                'SD': round(values.std(), 2),\n",
    "                '95% CI': f\"[{ci_low:.1f}, {ci_high:.1f}]\",\n",
    "                't': round(t_stat, 2),\n",
    "                'p': round(p_val, 4),\n",
    "                \"Cohen's d\": round(cohens_d, 2),\n",
    "                'Systematic?': 'Yes*' if p_val < 0.05 else 'No'\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# Run the test\n",
    "drift_stats = test_systematic_drift(dir_drift_filtered)\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"TEST FOR SYSTEMATIC DRIFT (One-sample t-test: H0 = mean drift is 0)\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\\nIf p > 0.05: No systematic drift → CONSISTENT with literature\")\n",
    "print(\"If p < 0.05: Systematic drift in that direction\\n\")\n",
    "print(drift_stats.to_string(index=False))\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c79b0f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SYSTEMATIC DRIFT BY GROUP × CATEGORY (* = p < 0.05):\n",
      "  Group Category  n Δx mean Δy mean Δz mean\n",
      "    OTC     face  6    -0.3    -2.4     0.8\n",
      "    OTC     word  6     2.6     7.9    -0.2\n",
      "    OTC   object  6     0.2     1.7    -0.9\n",
      "    OTC    house  6    -3.8     9.3    1.0*\n",
      " nonOTC     face  7     1.1     1.7     0.2\n",
      " nonOTC     word  7    -4.0     2.9    -0.4\n",
      " nonOTC   object  7     0.4     2.2    -0.4\n",
      " nonOTC    house  7    -0.6    -1.1     0.0\n",
      "Control     face  7     0.1     0.7     0.1\n",
      "Control     word  7    -0.1    -2.0    -2.9\n",
      "Control   object 14     3.0     0.9    -0.6\n",
      "Control    house 14     1.3    -5.0     1.6\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 8: DIRECTIONAL DRIFT - Test by Category\n",
    "# =============================================================================\n",
    "\n",
    "def test_drift_by_group_category(df):\n",
    "    \"\"\"Test systematic drift for each group × category combination.\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for group in ['OTC', 'nonOTC', 'Control']:\n",
    "        for category in ['face', 'word', 'object', 'house']:\n",
    "            subset = df[(df['group'] == group) & (df['category'] == category)]\n",
    "            \n",
    "            if len(subset) < 3:\n",
    "                continue\n",
    "            \n",
    "            row = {'Group': group, 'Category': category, 'n': len(subset)}\n",
    "            \n",
    "            for coord, label in [('delta_x', 'Δx'), ('delta_y', 'Δy'), ('delta_z', 'Δz')]:\n",
    "                values = subset[coord].dropna()\n",
    "                if len(values) >= 3:\n",
    "                    t_stat, p_val = ttest_1samp(values, 0)\n",
    "                    sig = '*' if p_val < 0.05 else ''\n",
    "                    row[f'{label} mean'] = f\"{values.mean():.1f}{sig}\"\n",
    "                else:\n",
    "                    row[f'{label} mean'] = 'n/a'\n",
    "            \n",
    "            results.append(row)\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "category_drift = test_drift_by_group_category(dir_drift_filtered)\n",
    "print(\"\\nSYSTEMATIC DRIFT BY GROUP × CATEGORY (* = p < 0.05):\")\n",
    "print(category_drift.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d5a65d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ANOVA: Do groups differ in drift DIRECTION?\n",
      "================================================================================\n",
      "\n",
      "Medial-Lateral (Δx):\n",
      "  F = 1.800, p = 0.1711 → No group differences\n",
      "\n",
      "Anterior-Posterior (Δy):\n",
      "  F = 2.211, p = 0.1154 → No group differences\n",
      "\n",
      "Superior-Inferior (Δz):\n",
      "  F = 0.043, p = 0.9583 → No group differences\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 9: DIRECTIONAL DRIFT - ANOVA: Do Groups Differ in Drift Direction?\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANOVA: Do groups differ in drift DIRECTION?\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for coord, label in [('delta_x', 'Medial-Lateral'), \n",
    "                     ('delta_y', 'Anterior-Posterior'), \n",
    "                     ('delta_z', 'Superior-Inferior')]:\n",
    "    \n",
    "    groups_data = []\n",
    "    group_names = []\n",
    "    for g in ['OTC', 'nonOTC', 'Control']:\n",
    "        vals = dir_drift_filtered[dir_drift_filtered['group'] == g][coord].dropna()\n",
    "        if len(vals) > 0:\n",
    "            groups_data.append(vals)\n",
    "            group_names.append(g)\n",
    "    \n",
    "    if len(groups_data) >= 2:\n",
    "        f_stat, p_val = f_oneway(*groups_data)\n",
    "        result = '→ GROUPS DIFFER' if p_val < 0.05 else '→ No group differences'\n",
    "        print(f\"\\n{label} (Δ{coord[-1]}):\")\n",
    "        print(f\"  F = {f_stat:.3f}, p = {p_val:.4f} {result}\")\n",
    "        \n",
    "        # Post-hoc if significant\n",
    "        if p_val < 0.05:\n",
    "            for i, g1 in enumerate(group_names):\n",
    "                for g2 in group_names[i+1:]:\n",
    "                    t, p = ttest_ind(\n",
    "                        dir_drift_filtered[dir_drift_filtered['group'] == g1][coord].dropna(),\n",
    "                        dir_drift_filtered[dir_drift_filtered['group'] == g2][coord].dropna()\n",
    "                    )\n",
    "                    sig = '*' if p < 0.05 else ''\n",
    "                    print(f\"    {g1} vs {g2}: t={t:.2f}, p={p:.4f}{sig}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1ba5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 10: VISUALIZATION - Box Plots of Signed Drift\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "coord_info = [\n",
    "    ('delta_x', 'Δx: Medial ← → Lateral'),\n",
    "    ('delta_y', 'Δy: Posterior ← → Anterior'), \n",
    "    ('delta_z', 'Δz: Inferior ← → Superior')\n",
    "]\n",
    "\n",
    "group_order = ['OTC', 'nonOTC', 'Control']\n",
    "palette = {'OTC': 'coral', 'nonOTC': 'skyblue', 'Control': 'lightgreen'}\n",
    "\n",
    "for ax, (coord, title) in zip(axes, coord_info):\n",
    "    sns.boxplot(data=dir_drift_filtered, x='group', y=coord, \n",
    "                order=group_order, palette=palette, ax=ax)\n",
    "    \n",
    "    sns.stripplot(data=dir_drift_filtered, x='group', y=coord,\n",
    "                  order=group_order, color='black', alpha=0.5, size=4, ax=ax)\n",
    "    \n",
    "    # Reference line at 0 (no systematic drift)\n",
    "    ax.axhline(0, color='red', linestyle='--', linewidth=2, alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('')\n",
    "    ax.set_ylabel(f'{title.split(\":\")[0]} (mm)')\n",
    "    ax.set_title(title)\n",
    "    \n",
    "    # Annotate means\n",
    "    for i, group in enumerate(group_order):\n",
    "        grp_data = dir_drift_filtered[dir_drift_filtered['group'] == group][coord]\n",
    "        if len(grp_data) > 0:\n",
    "            mean = grp_data.mean()\n",
    "            sem = grp_data.sem()\n",
    "            ax.annotate(f'{mean:.1f}±{sem:.1f}', \n",
    "                       xy=(i, ax.get_ylim()[1] * 0.85),\n",
    "                       ha='center', fontsize=9, fontweight='bold')\n",
    "\n",
    "plt.suptitle('Signed Coordinate Drift by Group\\n(Centered on 0 = no systematic directional drift)', \n",
    "             fontsize=12, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.savefig('directional_drift_boxplots.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1bb6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 11: VISUALIZATION - Arrow Plot Showing Drift Directions\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "category_colors = {'face': '#FFB347', 'word': '#6495ED', \n",
    "                   'object': '#40E0D0', 'house': '#B39EB5'}\n",
    "\n",
    "for ax, group in zip(axes, ['OTC', 'nonOTC', 'Control']):\n",
    "    group_data = dir_drift_filtered[dir_drift_filtered['group'] == group]\n",
    "    \n",
    "    # Plot arrows from origin (y=delta_y for A-P, z=delta_z for S-I)\n",
    "    for _, row in group_data.iterrows():\n",
    "        ax.arrow(0, 0, row['delta_y'], row['delta_z'], \n",
    "                head_width=0.8, head_length=0.5, \n",
    "                fc=category_colors.get(row['category'], 'gray'),\n",
    "                ec=category_colors.get(row['category'], 'gray'),\n",
    "                alpha=0.6, linewidth=1.5)\n",
    "    \n",
    "    # Reference circle at 10mm (typical noise level)\n",
    "    circle = plt.Circle((0, 0), 10, fill=False, linestyle='--', \n",
    "                        color='gray', alpha=0.5, linewidth=2)\n",
    "    ax.add_patch(circle)\n",
    "    \n",
    "    ax.axhline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "    ax.axvline(0, color='black', linewidth=0.5, alpha=0.3)\n",
    "    ax.set_xlim(-30, 30)\n",
    "    ax.set_ylim(-30, 30)\n",
    "    ax.set_aspect('equal')\n",
    "    ax.set_xlabel('Δy: Anterior-Posterior (mm)')\n",
    "    ax.set_ylabel('Δz: Superior-Inferior (mm)')\n",
    "    ax.set_title(f'{group} (n={len(group_data)})')\n",
    "\n",
    "# Legend\n",
    "handles = [plt.Line2D([0], [0], color=c, marker='>', linestyle='', \n",
    "                       markersize=10, label=cat.title()) \n",
    "           for cat, c in category_colors.items()]\n",
    "fig.legend(handles=handles, loc='center right', bbox_to_anchor=(1.08, 0.5))\n",
    "\n",
    "plt.suptitle('Drift Direction (Y-Z plane)\\nArrows show T2 - T1 displacement\\n'\n",
    "             '(Random directions = no systematic drift)', fontsize=11, y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.savefig('directional_drift_arrows.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Interpretation: Random arrow directions → measurement noise (matches literature)\")\n",
    "print(\"               Clustered arrows → systematic spatial shift\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# CELL 12: VISUALIZATION - Signed vs Unsigned Comparison\n",
    "# =============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Left: Euclidean (unsigned) - original analysis\n",
    "ax = axes[0]\n",
    "sns.boxplot(data=dir_drift_filtered, x='group', y='euclidean_dist',\n",
    "            order=['OTC', 'nonOTC', 'Control'],\n",
    "            palette=palette, ax=ax)\n",
    "ax.set_ylabel('Euclidean Distance (mm)')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('Unsigned Drift (Euclidean)\\nAlways positive - measures variability')\n",
    "\n",
    "# Right: Mean signed drift (should be ~0 if no systematic drift)\n",
    "ax = axes[1]\n",
    "summary = dir_drift_filtered.groupby('group')[['delta_x', 'delta_y', 'delta_z']].mean()\n",
    "summary = summary.reindex(['OTC', 'nonOTC', 'Control'])\n",
    "summary.plot(kind='bar', ax=ax, width=0.8, \n",
    "             color=['#e74c3c', '#3498db', '#2ecc71'])\n",
    "ax.axhline(0, color='black', linewidth=1.5)\n",
    "ax.set_ylabel('Mean Signed Drift (mm)')\n",
    "ax.set_xlabel('')\n",
    "ax.set_title('Mean Signed Drift by Axis\\nShould be ~0 if no systematic direction')\n",
    "ax.set_xticklabels(['OTC', 'nonOTC', 'Control'], rotation=0)\n",
    "ax.legend(title='Axis', labels=['M-L', 'A-P', 'S-I'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('signed_vs_unsigned_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bd2b8c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SUMMARY: Directional Drift Analysis\n",
      "================================================================================\n",
      "\n",
      "Mean ± SD by Group:\n",
      "        delta_x       delta_y        delta_z       euclidean_dist             \n",
      "           mean   std    mean    std    mean   std           mean    std count\n",
      "group                                                                         \n",
      "Control    1.44  6.16   -1.57  10.61   -0.10  5.65           8.84  10.34    42\n",
      "OTC       -0.36  3.94    4.15  14.40    0.20  3.81          10.24  12.10    24\n",
      "nonOTC    -0.75  4.36    1.42   6.71   -0.12  2.71           5.56   6.48    28\n",
      "\n",
      "================================================================================\n",
      "INTERPRETATION\n",
      "================================================================================\n",
      "\n",
      "1. SIGNED DRIFT (delta_x, delta_y, delta_z):\n",
      "   - If means ≈ 0 with p > 0.05: Peaks fluctuate randomly around stable location\n",
      "   - This matches Dehaene-Lambertz (2018): \"no linear effect of session\" (F < 1)\n",
      "\n",
      "2. UNSIGNED DRIFT (Euclidean distance):\n",
      "   - Your original values (5-15mm) reflect VARIABILITY/noise\n",
      "   - Expected even with perfectly stable peaks due to:\n",
      "     • Voxel resolution (3mm isotropic)\n",
      "     • Registration noise (1-3mm)\n",
      "     • Threshold effects on peak voxel selection\n",
      "\n",
      "3. KEY FINDING:\n",
      "   - If signed means ≈ 0 AND p > 0.05: Results MATCH the literature\n",
      "   - Euclidean distances measure variability, not systematic drift\n",
      "   - Both measures are consistent - just answering different questions\n",
      "\n",
      "4. OTC vs CONTROLS:\n",
      "   - If no group differences in signed drift direction → OTC peaks are as\n",
      "     spatially stable as Controls (reorganization occurs WITHIN stable locations)\n",
      "================================================================================\n",
      "\n",
      "✓ Saved: directional_drift_results.csv, directional_drift_statistics.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# CELL 13: Summary and Interpretation\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SUMMARY: Directional Drift Analysis\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Summary table\n",
    "summary = dir_drift_filtered.groupby('group').agg({\n",
    "    'delta_x': ['mean', 'std'],\n",
    "    'delta_y': ['mean', 'std'],\n",
    "    'delta_z': ['mean', 'std'],\n",
    "    'euclidean_dist': ['mean', 'std', 'count']\n",
    "}).round(2)\n",
    "\n",
    "print(\"\\nMean ± SD by Group:\")\n",
    "print(summary)\n",
    "\n",
    "print(\"\"\"\n",
    "================================================================================\n",
    "INTERPRETATION\n",
    "================================================================================\n",
    "\n",
    "1. SIGNED DRIFT (delta_x, delta_y, delta_z):\n",
    "   - If means ≈ 0 with p > 0.05: Peaks fluctuate randomly around stable location\n",
    "   - This matches Dehaene-Lambertz (2018): \"no linear effect of session\" (F < 1)\n",
    "\n",
    "2. UNSIGNED DRIFT (Euclidean distance):\n",
    "   - Your original values (5-15mm) reflect VARIABILITY/noise\n",
    "   - Expected even with perfectly stable peaks due to:\n",
    "     • Voxel resolution (3mm isotropic)\n",
    "     • Registration noise (1-3mm)\n",
    "     • Threshold effects on peak voxel selection\n",
    "\n",
    "3. KEY FINDING:\n",
    "   - If signed means ≈ 0 AND p > 0.05: Results MATCH the literature\n",
    "   - Euclidean distances measure variability, not systematic drift\n",
    "   - Both measures are consistent - just answering different questions\n",
    "\n",
    "4. OTC vs CONTROLS:\n",
    "   - If no group differences in signed drift direction → OTC peaks are as\n",
    "     spatially stable as Controls (reorganization occurs WITHIN stable locations)\n",
    "================================================================================\n",
    "\"\"\")\n",
    "\n",
    "# Save results\n",
    "dir_drift_filtered.to_csv('directional_drift_results.csv', index=False)\n",
    "drift_stats.to_csv('directional_drift_statistics.csv', index=False)\n",
    "print(\"✓ Saved: directional_drift_results.csv, directional_drift_statistics.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fmri",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
